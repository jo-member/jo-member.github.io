<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Jo Member</title>
    <link>https://jo-member.github.io/</link>
    
    <atom:link href="https://jo-member.github.io/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>ë„ì ë„ì </description>
    <pubDate>Mon, 12 Jul 2021 10:38:23 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>pstage4</title>
      <link>https://jo-member.github.io/2021/07/12/pstage4/</link>
      <guid>https://jo-member.github.io/2021/07/12/pstage4/</guid>
      <pubDate>Mon, 12 Jul 2021 10:30:08 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;Pstage4-ìˆ˜ì‹ì¸ì‹&quot;&gt;&lt;a href=&quot;#Pstage4-ìˆ˜ì‹ì¸ì‹&quot; class=&quot;headerlink&quot; title=&quot;Pstage4_ìˆ˜ì‹ì¸ì‹&quot;&gt;&lt;/a&gt;Pstage4_ìˆ˜ì‹ì¸ì‹&lt;/h1&gt;&lt;h3 id=&quot;Github-Repository&quot;&gt;&lt;a href=&quot;#Github-Repository&quot; class=&quot;headerlink&quot; title=&quot;Github Repository&quot;&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/bcaitech1/p4-ocr-hansarang&quot;&gt;Github Repository&lt;/a&gt;&lt;/h3&gt;</description>
      
      
      
      <content:encoded><![CDATA[<h1 id="Pstage4-ìˆ˜ì‹ì¸ì‹"><a href="#Pstage4-ìˆ˜ì‹ì¸ì‹" class="headerlink" title="Pstage4_ìˆ˜ì‹ì¸ì‹"></a>Pstage4_ìˆ˜ì‹ì¸ì‹</h1><h3 id="Github-Repository"><a href="#Github-Repository" class="headerlink" title="Github Repository"></a><a href="https://github.com/bcaitech1/p4-ocr-hansarang">Github Repository</a></h3><span id="more"></span><p><strong>íŒ€ ì†Œê°œ</strong></p><h2 id="ğŸ¸-ì¡°ì›"><a href="#ğŸ¸-ì¡°ì›" class="headerlink" title="ğŸ¸ ì¡°ì›                                                                                                           "></a>ğŸ¸ ì¡°ì›                                                                                                           <a href="https://github.com/jo-member"><git></a></h2><ul><li><p>SATRN (Locality Feedforward, Shallow CNN) êµ¬í˜„</p></li><li><p>Augmentation (Resize &amp; Noramlization&amp; pixel í‰ê· ì— ë”°ë¥¸ ì´ì§„í™”â€¦) ì œì•ˆ &amp; ì‹¤í—˜</p></li><li><p>Ensemble (soft voting) êµ¬í˜„ &amp; ì‹¤í—˜</p></li><li><p>teacherforcing ratio scheduling ì‹¤í—˜</p></li><li><p>Beam search êµ¬í˜„</p></li><li><p>ë¶€ì¡±í•œ tokenì— ëŒ€í•œì¶”ê°€ Data ìƒì„±</p></li><li><p><a href="http://boostcamp.stages.ai/competitions/43/discussion/post/363">BERTë¥¼ ì‚¬ìš©í•œ misspelledëœ ìˆ˜ì‹ ì¡ì•„ë‚´ê¸° ì œì•ˆ</a></p></li><li><p>CSTR ë…¼ë¬¸ reading &amp; ê³µìœ </p></li></ul><p><strong>í˜‘ì—…</strong></p><ul><li><em><strong>Gitì˜ Discussion, Pull &amp; Request, Wikië¥¼ í™œìš©í•˜ì—¬ í† ë¡ , ìë£Œ, ê²°ê³¼ê³µìœ </strong></em></li><li><em><strong>Wandbë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í—˜ê³µìœ </strong></em></li></ul><p><strong>ìˆ˜ì‹ì¸ì‹ Competition Overall</strong></p><ul><li><p><em><strong>ìƒì„¸ê°œìš”</strong></em></p><p>ìˆ˜ì‹ ì´ë¯¸ì§€ë¥¼ latex í¬ë§·ì˜ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ë¬¸ì œì…ë‹ˆë‹¤. ìˆ˜ì‹ì€ ì—¬ëŸ¬ ìì—°ê³¼í•™ ë¶„ì•¼ì—ì„œ ì–´ë ¤ìš´ ê°œë…ë“¤ì€ ê°„ë‹¨í•˜ê³  ê°„ê²°í•˜ê²Œ í‘œí˜„í•˜ëŠ” ë°©ë²•ìœ¼ë¡œì„œ ë„ë¦¬ ì‚¬ìš©ë˜ì–´ ì™”ìŠµë‹ˆë‹¤. Latex ë˜í•œ ì—¬ëŸ¬ ê³¼í•™ ë¶„ì•¼ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë…¼ë¬¸ ë° ê¸°ìˆ  ë¬¸ì„œ ì‘ì„± í¬ë§·ìœ¼ë¡œì„œ í˜„ì¬ê¹Œì§€ë„ ë„ë¦¬ ì‚¬ìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.</p><p><img src="/images/Untitled%206.png"></p><p>ì¼ë°˜ì ì¸ OCRê³¼ ë‹¬ë¦¬ ë¶„ìˆ˜, ì‹œê·¸ë§ˆ, ê·¹í•œê³¼ ê°™ì€ í‘œí˜„ì„ ì¸ì‹í•˜ê¸° ìœ„í•´ multi line recognitionì„ íŠ¹ì§•ìœ¼ë¡œ ê°€ì§‘ë‹ˆë‹¤.</p></li><li><p><em><strong>Dataset</strong></em></p><p>Scale : ê°ê°ì˜ image scaleì€ ì œê°ê°</p><p>Label : Latex í˜•ì‹ì˜ ìˆ˜ì‹</p><ul><li><p>Train Data</p><ul><li>Hand Written Data : 50000</li><li>Printed Data            : 50000</li></ul></li><li><p>Evaluation Data</p><ul><li>Public : 6000</li><li>Private : 6000</li></ul></li><li><p>Prediction</p><ul><li>241ê°œì˜ token classì¤‘ í•˜ë‚˜ë¥¼ ìƒì„±í•œ ë’¤ ì´ë“¤ì˜ sequence</li></ul></li></ul></li><li><p><em><strong>í‰ê°€ Metric</strong></em></p><h3 id="0-9-x-â€œSentence-Accuracyâ€-0-1-x-1-â€œWERâ€"><a href="#0-9-x-â€œSentence-Accuracyâ€-0-1-x-1-â€œWERâ€" class="headerlink" title="0.9 x â€œSentence Accuracyâ€ + 0.1 x (1-â€œWERâ€)"></a><strong>0.9 x â€œSentence Accuracyâ€ + 0.1 x (1-â€œWERâ€)</strong></h3><ul><li><p>Sentence Accuracy</p><p>ì „ì²´ ì¶”ë¡  ê²°ê³¼(ìˆ˜ì‹) ì¤‘ì—ì„œ ëª‡ ê°œì˜ ìˆ˜ì‹ì´ ì •ë‹µ(ground truth)ê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ì§€</p><p><img src="/images/Untitled%207.png"></p></li><li><p>WER (Word Error Rate)</p><p>ë‹¨ì–´ ë‹¨ìœ„ë¡œ ì‚½ì…(insertion), ì‚­ì œ(deletion), ëŒ€ì²´(substitution)ëœ ê¸€ì ê°œìˆ˜ë¥¼ ê³„ì‚°</p><p><img src="/images/Untitled%208.png"></p></li></ul></li></ul><p><strong>Problem &amp; Solving</strong></p><h2 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h2><ul><li><p><em><strong>ë¶€ì¡±í•œ token data</strong></em></p><p><img src="/images/Untitled%209.png"></p><p>Train dataì— ë“±ì¥í•˜ëŠ” tokenë“¤ì¤‘ ë¹ˆë„ìˆ˜ê°€ ê°€ì¥ì ì€ 50ê°œë¥¼ ë½‘ì•„ë³´ì•˜ë‹¤.</p><p>10íšŒ ë¯¸ë§Œìœ¼ë¡œ ë“±ì¥í•œ tokenë“¤ì— ëŒ€í•œ ì¶”ê°€ì ì¸ dataê°€ í•„ìš”í•˜ë‹¤ê³  íŒë‹¨ë˜ì—ˆë‹¤. </p><p><a href="http://www.hostmath.com/">ì‚¬ì´íŠ¸</a>ë¥¼ í™œìš©í•˜ì—¬ ë¶€ì¡±í•œ tokenë“¤ì„ í¬í•¨í•˜ëŠ” ìˆ˜ì‹ì„ trainíŒŒì¼ì— 50ê°œ ì •ë„ì˜ dataë¥¼ ì¶”ê°€í•´ì£¼ì—ˆë‹¤.</p><p>train_100003.jpg    \ominus \vdots \nexists \rightleftarrows A \supsetneq B</p><p><img src="/images/Untitled%2010.png"></p></li><li><p><em><strong>ì„¸ë¡œí˜•íƒœì˜ ìˆ˜ì‹ ì´ë¯¸ì§€</strong></em></p><p><img src="/images/Untitled%2011.png"></p></li><li><p><em><strong>ë‹¤ì–‘í•œ Aspect Ratio</strong></em></p><p><img src="/images/Untitled%2012.png"></p></li><li><p><em><strong>ì˜ëª»ëœ labeling</strong></em></p><p>P = 1ì´ ì•„ë‹Œ</p><p>P = ìœ¼ë¡œ labeling ë˜ì–´ìˆìŒ</p><p><img src="/images/Untitled%2013.png"></p></li><li><p><em><strong>ì„ ì´ ê·¸ì–´ì ¸ ìˆê±°ë‚˜ í˜•ê´‘íŒ¬ì´ ì¹ í•´ì ¸ ìˆëŠ” case</strong></em></p><p><img src="/images/Untitled%2014.png"></p></li></ul><h2 id="Augmentation"><a href="#Augmentation" class="headerlink" title="Augmentation"></a>Augmentation</h2><ul><li><p><em><strong>Resize</strong></em></p></li><li><p><em><strong>Rotate</strong></em></p><p>OCR taskì—ì„œ ì„¸ë¡œë¡œ ë˜ì–´ì§„ imageë“¤ì€ ëª¨ë‘ noiseë¡œ ì‘ìš©</p><p>EDAì—ì„œ ì ë‹¹í•œ Aspect ratioì˜ thresholdë¥¼ ì°¾ì€ ë’¤, threshold ë¯¸ë§Œì¸ dataë“¤ì— í•œí•˜ì—¬ Rotate</p></li><li><p><em><strong>Normalization</strong></em></p><p>ì´ë¯¸ì§€ì˜ ê° pixel  ê°’ë“¤ì„ 0-1ì˜ ê°’ìœ¼ë¡œ normalize ì‹œì¼œì¤€ë‹¤</p></li><li><p><em><strong>ì´ì§„í™” &amp; ê°€ë¡œì„  ì œê±°</strong></em></p></li></ul><h2 id="Model-SATRN"><a href="#Model-SATRN" class="headerlink" title="Model (SATRN)"></a>Model (SATRN)</h2><ul><li><p><em><strong>Locality-aware feedforward layer</strong></em></p><p><img src="/images/Untitled%2015.png"></p><p>Base-line modelì— êµ¬í˜„ëœ Fully-connected feed forwardì—ì„œ ë…¼ë¬¸ì—ì„œ ì œì‹œí•˜ê³  ìˆëŠ” Convolutuon feed forwardë¡œ êµì²´</p></li><li><p><em><strong>Adaptive 2D Positional Encoding</strong></em></p><p><img src="/images/Untitled%2016.png"></p><p>Baselineì—ì„œ êµ¬í˜„ëœ ì¼ë°˜ì ì¸ 2D positional encodingì—ì„œ ë…¼ë¬¸ì—ì„œ ì œì‹œí•œ í•™ìŠµê°€ëŠ¥í•œ adaptive 2D positional encodingìœ¼ë¡œ ë³€ê²½</p></li><li><p><em><strong>Backbone</strong></em></p><ol><li><a href="https://arxiv.org/pdf/1905.11946.pdf">EfficientNet</a></li><li><a href="https://arxiv.org/pdf/1608.06993.pdf">DenseNet</a></li><li>ShallowCNN</li></ol></li><li><p><em><strong>Mini SATRN for fast experiment</strong></em></p><p>ë‹¤ì–‘í•œ ì‹¤í—˜ì„ ë¹ ë¥´ê²Œ ì§„í–‰í•˜ê¸° ìœ„í•´ SATRNì˜ sizeë¥¼ ì¤„ì—¬ì„œ Mini SATRNìœ¼ë¡œ ë‹¤ì–‘í•œ ì‹¤í—˜ì„ ì§„í–‰</p></li><li><p><em><strong>SATRNì˜ layer parameter ìˆ˜ì •</strong></em></p><ol><li><p>Increase number of Decoder Layer</p><p><img src="/images/2021-06-16__10.07.43.png"></p><p>mini model ê¸°ì¤€, Decoder layerë¥¼ ì¶”ê°€í• ìˆ˜ë¡ ì„±ëŠ¥ì´ í–¥ìƒ</p></li><li><p>Change Activation Function</p><p><img src="/images/2021-06-16__10.14.13.png"></p><p>ShallowCNNì˜ activation functionì„ ReLUëŒ€ì‹  mishë¥¼ ì‚¬ìš©</p></li></ol></li></ul><h2 id="Post-Processing"><a href="#Post-Processing" class="headerlink" title="Post - Processing"></a>Post - Processing</h2><ul><li><p><em><strong>Beam search</strong></em></p><p>Tokenì„ ë½‘ì„ ë•Œ argmaxë¥¼ ì‚¬ìš©í•˜ì—¬ í•˜ë‚˜ì˜ tokenë§Œì„ ë½‘ëŠ”ê²Œ ì•„ë‹Œ ê° stepë§ˆë‹¤ beam size k ë§Œí¼ì˜ tokenì„ ë½‘ì•„ ìµœëŒ€í•œ ì í•©í•œ sequenceë¥¼ ì„ íƒí•˜ë ¤ ì‹œë„í•¨</p></li><li><p><em><strong>Ensemble</strong></em></p><p>ë‹¤ì–‘í•œ augementationì„ ê±°ì¹œ modelë“¤ì„ í•œë²ˆì— ë¶ˆëŸ¬ì™€ì„œ soft votingì„ ì‚¬ìš©í•˜ì—¬ ensemble</p><p>Baselineì—ëŠ” ë¹ ì ¸ìˆëŠ” torch.nogradë¡œ memory ì ˆì•½</p><p><img src="/images/Untitled%2017.png"></p></li><li><p><em><strong>Use Language Model (x)</strong></em></p><p><a href="http://boostcamp.stages.ai/competitions/43/discussion/post/363">ê´€ë ¨ í† ë¡  link</a></p></li></ul><h2 id="OCR-Demo"><a href="#OCR-Demo" class="headerlink" title="OCR Demo"></a>OCR Demo</h2><p>ë°ëª¨í˜ì´ì§€ ì£¼ì†Œ : <a href="http://35.74.99.158:8501/">http://35.74.99.158:8501/</a></p><p><img src="/images/2021-06-16__10.31.11.png"></p><p><strong>Paper Review</strong></p><p>í”„ë¡œì íŠ¸ ì§„í–‰ì„ ìœ„í•´ ì½ì€ ë…¼ë¬¸ì˜ ëª©ë¡ì€ ë‹¤ìŒê³¼ ê°™ìŒ</p><p><a href="/images/CSTR.pdf">CSTR.pdf</a></p><p><a href="/images/Misspelling_Correction_with_Pre-trained_Contextual_Language_Model.pdf">Misspelling Correction with Pre-trained Contextual Language Model.pdf</a></p><p><a href="/images/CRNN__.pdf">CRNN.pdf</a></p><p><a href="/images/An_Attentional_Scene_Text_Recognizer_with_Flexible_Rectification.pdf">An_Attentional_Scene_Text_Recognizer_with_Flexible_Rectification.pdf</a></p><p><a href="/images/CBAM.pdf">CBAM.pdf</a></p><p><a href="/images/Towards_End-to-end_Text_Spotting_with_Convolutional_Recurrent_Neural_Networks.pdf">Towards End-to-end Text Spotting with Convolutional Recurrent Neural Networks.pdf</a></p><p><a href="/images/TextBoxes_A_Fast_Text_Detector_with_a_Single_Deep_Neural_Network.pdf">TextBoxes_A Fast Text Detector with a Single Deep Neural Network.pdf</a></p>]]></content:encoded>
      
      
      <category domain="https://jo-member.github.io/categories/Boostcamp/">Boostcamp</category>
      
      
      <category domain="https://jo-member.github.io/tags/Vision/">Vision</category>
      
      <category domain="https://jo-member.github.io/tags/NLP/">NLP</category>
      
      <category domain="https://jo-member.github.io/tags/OCR/">OCR</category>
      
      
      <comments>https://jo-member.github.io/2021/07/12/pstage4/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>swin_transformer</title>
      <link>https://jo-member.github.io/2021/07/12/swin-transformer/</link>
      <guid>https://jo-member.github.io/2021/07/12/swin-transformer/</guid>
      <pubDate>Mon, 12 Jul 2021 08:50:01 GMT</pubDate>
      
      
      
      
      
      
      <comments>https://jo-member.github.io/2021/07/12/swin-transformer/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>fpn</title>
      <link>https://jo-member.github.io/2021/07/12/fpn/</link>
      <guid>https://jo-member.github.io/2021/07/12/fpn/</guid>
      <pubDate>Mon, 12 Jul 2021 08:49:42 GMT</pubDate>
      
      
      
      
      
      
      <comments>https://jo-member.github.io/2021/07/12/fpn/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>cstr</title>
      <link>https://jo-member.github.io/2021/07/12/cstr/</link>
      <guid>https://jo-member.github.io/2021/07/12/cstr/</guid>
      <pubDate>Mon, 12 Jul 2021 08:49:30 GMT</pubDate>
      
      
      
      
      
      
      <comments>https://jo-member.github.io/2021/07/12/cstr/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>satrn</title>
      <link>https://jo-member.github.io/2021/07/12/satrn/</link>
      <guid>https://jo-member.github.io/2021/07/12/satrn/</guid>
      <pubDate>Mon, 12 Jul 2021 08:49:13 GMT</pubDate>
      
      
      
      
      
      
      <comments>https://jo-member.github.io/2021/07/12/satrn/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>VQA: Visual Question Answering vs Competition Baseline</title>
      <link>https://jo-member.github.io/2021/07/12/vqa_paper1/</link>
      <guid>https://jo-member.github.io/2021/07/12/vqa_paper1/</guid>
      <pubDate>Mon, 12 Jul 2021 05:42:40 GMT</pubDate>
      
      <description>&lt;p&gt;VQA taskì˜ ì‹œì´ˆê²©ì¸ ë…¼ë¬¸ì´ë‹¤.&lt;/p&gt;
&lt;p&gt;VQA challengeì˜ ì „ë°˜ì ì¸ ê°œìš”ì™€ dataset, Base modelë“±ì„ ë‹¤ë£¨ê³  ìˆë‹¤.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>VQA taskì˜ ì‹œì´ˆê²©ì¸ ë…¼ë¬¸ì´ë‹¤.</p><p>VQA challengeì˜ ì „ë°˜ì ì¸ ê°œìš”ì™€ dataset, Base modelë“±ì„ ë‹¤ë£¨ê³  ìˆë‹¤.</p><span id="more"></span><p><img src="/images/image-20210712145742160.png" alt="image-20210712145742160"></p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><ul><li>VQAë€ Vision, NLP, knowledge representationì„ ëª¨ë‘ ì ‘ëª©ì‹œí‚¨ multi-discipline taskì´ë‹¤</li><li><img src="/images/image-20210712150251708.png" alt="image-20210712150251708" style="zoom:50%;" /></li><li>ìœ„ì™€ ê°™ì´ ì–´ë– í•œ imageê°€ ì£¼ì–´ì§€ê³ , imageê°€ ì—†ìœ¼ë©´ ë§ì¶”ê¸° í˜ë“  ì§ˆë¬¸ë“¤ë¡œ êµ¬ì„±ë˜ì–´ìˆë‹¤. </li><li>Answerì˜ ìœ í˜•ì— ë”°ë¼ open-ended questions ê³¼ multiple-choice taskë¡œ ë‚˜ëˆ„ì–´ ì§„ë‹¤.</li><li>Open-ended questionì€ answerê°€ ë‹¤ì–‘í•´ ì§ˆ ìˆ˜ ìˆì§€ë§Œ, multiple-choice taskì˜ ê²½ìš°ì—ëŠ” ë¯¸ë¦¬ ì •í•´ì§„ answer listì¤‘ í•˜ë‚˜ê°€ ë‹µì•ˆì´ì—¬ì•¼ í•œë‹¤.</li><li>ì´ ë…¼ë¬¸ì—ì„œëŠ” ë‘ê°€ì§€ì˜ answerìœ í˜•  ì „ë¶€ ë‹¤ë£¨ê³  ìˆë‹¤. (ìš°ë¦¬ì˜ VQA taskëŠ” multiple-choice task ë§Œì„ ë‹¤ë£¨ê³  ìˆê¸° ë•Œë¬¸ì— open-ended ëŠ”ìƒëµ)</li></ul><h2 id="2-Dataset"><a href="#2-Dataset" class="headerlink" title="2. Dataset"></a>2. Dataset</h2><h3 id="Image-data"><a href="#Image-data" class="headerlink" title="Image data"></a>Image data</h3><ol><li><p>MS COCO dataset</p><ul><li>Object Detectionê³¼ image captioningì—ì„œ ì‚¬ìš©ë˜ëŠ” dataset</li><li>containing multiple objects and rich contextual information</li><li>123,287 training and validation images and 81,434 test images</li></ul></li><li><p>Abstract Scene dataset</p><ul><li>The dataset contains 20 â€œpaperdollâ€ human models [2] spanning genders, races, and ages with 8 different expressions.</li><li>Paperdollë¡œ realí•œ ìƒí™©ì„ í‘œí˜„í•¨</li><li>we create a new abstract scenes dataset containing 50K scenes</li></ul></li></ol><h3 id="Question-data"><a href="#Question-data" class="headerlink" title="Question data"></a>Question data</h3><p>ê°„ë‹¨í•œ questionì´ ì•„ë‹Œ ë³µì¡í•˜ê³  ì–´ë ¤ìš´ questionì„ ë§Œë“¤ì–´ë‚´ê¸° ìœ„í•´ </p><blockquote><p>â€œWe have built a smart robot. It understands a lot about images. It can recognize and name all the objects, it knows where the objects are, it can recognize the scene (e.g., kitchen, beach), peopleâ€™s expressions and poses, and properties of objects (e.g., color of objects, their texture). Your task is to stump this smart robot! Ask a question about this scene that this smart robot probably can not answer, but any human can easily answer while looking at the scene in the image.â€</p></blockquote><p>ì´ëŸ¬í•œ ìš”ì²­ì„ ì£¼ì–´ questionì„ ë§Œë“¤ì–´ ë‚´ë„ë¡ í•˜ì˜€ë‹¤.</p><h3 id="Answer-data"><a href="#Answer-data" class="headerlink" title="Answer data"></a>Answer data</h3><p>18ê°œì˜ ì„ íƒì§€ë¥¼ êµ¬ì„±</p><ul><li><strong>Correct</strong> : The most common (out of ten) correct answer</li><li><strong>Plausible</strong> : To generate incorrect, but still plausible answers we ask three subjects to answer the questions without seeing the image</li><li><strong>Popular</strong> : These are the 10 most popular answers. For instance, these are â€œyesâ€, â€œnoâ€, â€œ2â€, â€œ1â€, â€œwhiteâ€, â€œ3â€, â€œredâ€, â€œblueâ€, â€œ4â€, â€œgreenâ€ for real images</li><li><strong>Random</strong> : Correct answers from random questions in the dataset</li></ul><h2 id="3-Model"><a href="#3-Model" class="headerlink" title="3. Model"></a>3. Model</h2><p><img src="/images/image-20210712153623216.png" alt="image-20210712153623216"></p><p><img src="/images/image-20210712160208777.png" alt="image-20210712160208777"></p><p>VQAë¥¼ ìœ„í•œ Base modelê³¼ Competitionì—ì„œ ì œê³µí•´ì¤€ Baselineì˜ êµ¬ì¡°ë„ì´ë‹¤.</p><ol><li><p>Image channel</p><ul><li>Imageë¡œ ë¶€í„° embedding vectorë¥¼ ë½‘ì•„ë‚´ëŠ” ì—­í• ì„ í•œë‹¤.<br>Pretrainedëœ VGGNetì„ ì‚¬ìš©í•˜ì˜€ìœ¼ë©´ ê¸°ì¡´ VGGNetì˜ ë§ˆì§€ë§‰ Fully-Connected MLPì˜ layerì—ì„œ 4096 dimìœ¼ë¡œ ë½‘ì•„ë‚´ì—ˆë‹¤.</li></ul><ul><li>ì¸ê³µì§€ëŠ¥ ê²½ì§„ëŒ€íšŒì¸¡ì—ì„œ ì œê³µí•œ baselineì—ì„œëŠ” pretrainedëœ Resnet-50ì„ ì‚¬ìš©í•˜ì—¬ ë§ˆì§€ë§‰ Fully-Connected MLPì˜ layerì—ì„œ 768 dimìœ¼ë¡œ ë½‘ì•„ë‚´ê³  ìˆë‹¤. ì´í›„ ë…¼ë¬¸ê³¼ ë‹¤ë¥´ê²Œ ë³„ë„ì˜ Fully-Connected layerë¥¼ í†µê³¼ì‹œì¼œì£¼ì§€ ì•ŠëŠ”ë‹¤. ì• ì´ˆì— question channelê³¼ dimensionì„ ë§ì¶”ì–´ì£¼ì—ˆë‹¤. ë§ˆì§€ë§‰ target dimensionì€ 83ìœ¼ë¡œ train dataì˜ label ê°œìˆ˜ì´ë‹¤.</li></ul></li><li><p>Question channel</p><ul><li>Questionìœ¼ë¡œ ë¶€í„° embedding vectorë¥¼ ë½‘ì•„ë‚´ëŠ” ì—­í• ì„ í•œë‹¤.<br>Each question word is encoded with 300-dim embedding by a fully-connected layer + tanh non-linearity which is then fed to the LSTM. Cell state, hidden state dim = 512<br>Concate last cell state and last hidden state representations ì„ í•˜ì—¬ 1024ì˜ ì°¨ì›ì„ ë§Œë“¤ì–´ì£¼ì—ˆë‹¤.</li><li>ì¸ê³µì§€ëŠ¥ ê²½ì§„ëŒ€íšŒì¸¡ì—ì„œ ì œê³µí•œ baselineì—ì„œëŠ” huggingfaceë¥¼ ì‚¬ìš©í•˜ì—¬ pretrainedëœ RoBERTa-base modelì„ í†µí•´ embedding vectorë¥¼ ë½‘ì•„ ë‚´ì—ˆë‹¤.  ë½‘ì•„ë‚¸ embedding vectorì˜ dimì´ 768ì´ë¼ Image channelì˜ last dimensionë˜í•œ 768ë¡œ ë§ì¶°ì¤€ê²ƒì´ë‹¤. </li></ul></li><li><p>Multi-Layer Perceptron</p><ul><li><p>ì´ë¶€ë¶„ì€ ë‘˜ì˜ êµ¬ì¡°ê°€ ë™ì¼í•˜ë‹¤. ê° channelì—ì„œ ë‚˜ì˜¨ embedding vectorë“¤ì„ element wise multiplicationí•´ì¤€ë‹¤.</p></li><li><p>ì´í›„ layerì„ ì¶”ê°€í•´ì£¼ì–´ ì°¨ì›ì„ ëŠ˜ë ¤ì¤€ë’¤, ë§ˆì§€ë§‰ layerì—ì„œ target labelì˜ ê°œìˆ˜ë§Œí¼ì˜ dimensionì„ ë½‘ì•„ë‚¸ë‹¤.</p></li><li><p>ì´ë¶€ë¶„ì—ì„œ ê¶ê¸ˆí–ˆë˜ì ì€ ê° channelì˜ embedding vectorë¥¼ í•©ì¹˜ëŠ” ë°©ë²•ì— ë”°ë¥¸ ì„±ëŠ¥ì˜ ì°¨ì´ì˜€ë‹¤.</p><ol><li>Concat</li><li>Element-wise Multiplication</li><li>Element-wise Add</li></ol><p>ì´ì™€ ê´€ë ¨ëœ ë…¼ë¬¸ì„ ì°¾ì•„ë³´ì•˜ë‹¤.</p><p>Component Analysis for Visual Question Answering Architectures ì´ë¼ëŠ” ë…¼ë¬¸ì—ì„œ ê° fusion ë°©ì‹ì— ë”°ë¥¸ ì„±ëŠ¥ì„ ì‹¤í—˜í•´ë³´ì•˜ë‹¤.</p><img src="/images/image-20210712161607350.png" alt="image-20210712161607350" style="zoom:50%;" /><p>ìœ„ ë…¼ë¬¸ì˜ ê²°ê³¼ì— ë”°ë¼ 3ê°€ì§€ fusion ë°©ì‹ì¤‘ Multiplication ë°©ì‹ì„ ê³„ì†í•´ì„œ ê³ ìˆ˜í–ˆë‹¤.</p><p>ë˜í•œ ìœ„ë…¼ë¬¸ì—ì„œëŠ” BERTë¥¼ ì‚¬ìš©í•˜ì—¬ questionë¬¸ì¥ì„ embeddingë§Œ í•˜ê³  GRUë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì¢… vectorë¥¼ ë½‘ì•„ë‚´ê³  ìˆë‹¤. ì´ëŸ¬í•œ ë°©ì‹ë„ ì‹œë„í•´ ë³¼ë§Œ í• ê²ƒ ê°™ë‹¤.</p></li></ul></li></ol><h2 id="4-Result"><a href="#4-Result" class="headerlink" title="4. Result"></a>4. Result</h2><img src="/images/image-20210712163712232.png" alt="image-20210712163712232" style="zoom:50%;" />]]></content:encoded>
      
      
      <category domain="https://jo-member.github.io/categories/PaperReview/">PaperReview</category>
      
      
      <category domain="https://jo-member.github.io/tags/Vision/">Vision</category>
      
      <category domain="https://jo-member.github.io/tags/NLP/">NLP</category>
      
      <category domain="https://jo-member.github.io/tags/Multimodal/">Multimodal</category>
      
      <category domain="https://jo-member.github.io/tags/VQA/">VQA</category>
      
      
      <comments>https://jo-member.github.io/2021/07/12/vqa_paper1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>VQA (Visual Question Answering)</title>
      <link>https://jo-member.github.io/2021/07/12/VQA/</link>
      <guid>https://jo-member.github.io/2021/07/12/VQA/</guid>
      <pubDate>Mon, 12 Jul 2021 03:09:10 GMT</pubDate>
      
      <description>&lt;p&gt;Boostcampì—ì„œ ë§Œë‚œ ë™ë£Œë“¤ê³¼ í•¨ê»˜ &lt;a href=&quot;https://www.aiconnect.kr/main/competition/list&quot;&gt;2021 ì¸ê³µì§€ëŠ¥ ì˜¨ë¼ì¸ ê²½ì§„ëŒ€íšŒ&lt;/a&gt;ì— ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤.&lt;br&gt;ì´ 10ê°œì˜ ê³¼ì œì¤‘ ì‹œê°ì¥ì• ì¸ ì‹œìŠ¤í…œ ê°œë°œì„ ìœ„í•œ VQA ëª¨ë¸ì´ë¼ëŠ” Competitionì— ì°¸ì—¬í•˜ì˜€ìŠµë‹ˆë‹¤.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>Boostcampì—ì„œ ë§Œë‚œ ë™ë£Œë“¤ê³¼ í•¨ê»˜ <a href="https://www.aiconnect.kr/main/competition/list">2021 ì¸ê³µì§€ëŠ¥ ì˜¨ë¼ì¸ ê²½ì§„ëŒ€íšŒ</a>ì— ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤.<br>ì´ 10ê°œì˜ ê³¼ì œì¤‘ ì‹œê°ì¥ì• ì¸ ì‹œìŠ¤í…œ ê°œë°œì„ ìœ„í•œ VQA ëª¨ë¸ì´ë¼ëŠ” Competitionì— ì°¸ì—¬í•˜ì˜€ìŠµë‹ˆë‹¤.</p><span id="more"></span><h2 id="ê°œìš”"><a href="#ê°œìš”" class="headerlink" title="ê°œìš”"></a>ê°œìš”</h2><p><strong>ì´ë¯¸ì§€ë¥¼ ë³´ê³  ì£¼ì–´ì§„ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” Visual Question Answering ëª¨ë¸ ê°œë°œ</strong><br>VQAë€ ì‹œê°ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.<br>ì‹¤ë‚´ ë° ì‹¤ì™¸ ìƒí™œ ê±°ì£¼ í™˜ê²½ì—ì„œ ì´¬ì˜ëœ ì´ë¯¸ì§€ì™€ ê·¸ì— ê´€ë ¨ëœ ì§ˆë¬¸, ëŒ€ë‹µì´ ì„¸íŠ¸ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.<br>ì´ 224,464ê°œì˜ ì´ë¯¸ì§€ íŒŒì¼ê³¼ 702,135ê±´ì˜ ì§ˆë¬¸-ë‹µë³€ ìŒì´ train dataë¡œ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤.</p><h2 id="ê´€ë ¨-ë…¼ë¬¸-review"><a href="#ê´€ë ¨-ë…¼ë¬¸-review" class="headerlink" title="ê´€ë ¨ ë…¼ë¬¸ review"></a>ê´€ë ¨ ë…¼ë¬¸ review</h2><ol><li><a href="">VQA: Visual Question Answering</a></li><li>Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering</li><li>Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge</li><li>Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks</li><li>UNITER: UNiversal Image-TExt Representation Learning</li></ol>]]></content:encoded>
      
      
      <category domain="https://jo-member.github.io/categories/Competition/">Competition</category>
      
      
      <category domain="https://jo-member.github.io/tags/Vision/">Vision</category>
      
      <category domain="https://jo-member.github.io/tags/NLP/">NLP</category>
      
      <category domain="https://jo-member.github.io/tags/Multimodal/">Multimodal</category>
      
      <category domain="https://jo-member.github.io/tags/Competition/">Competition</category>
      
      
      <comments>https://jo-member.github.io/2021/07/12/VQA/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Pstage3_Image_Segmentation_Detection</title>
      <link>https://jo-member.github.io/2021/04/25/Pstage3-Image-Segmentation-Detection/</link>
      <guid>https://jo-member.github.io/2021/04/25/Pstage3-Image-Segmentation-Detection/</guid>
      <pubDate>Sun, 25 Apr 2021 11:52:06 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;Image-Segmentation&quot;&gt;&lt;a href=&quot;#Image-Segmentation&quot; class=&quot;headerlink&quot; title=&quot;Image Segmentation&quot;&gt;&lt;/a&gt;Image Segmentation&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/bcaitech1/p3-ims-obd-hansarang&quot;&gt;https://github.com/bcaitech1/p3-ims-obd-hansarang&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Overview&quot;&gt;&lt;a href=&quot;#Overview&quot; class=&quot;headerlink&quot; title=&quot;Overview&quot;&gt;&lt;/a&gt;Overview&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ë¬¸ì œì •ì˜ : ì“°ë ˆê¸°ê°€ ì°íŒ ì‚¬ì§„ì—ì„œ ì“°ë ˆê¸°ë¥¼ Segmentation &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;</description>
      
      
      
      <content:encoded><![CDATA[<h1 id="Image-Segmentation"><a href="#Image-Segmentation" class="headerlink" title="Image Segmentation"></a>Image Segmentation</h1><p><a href="https://github.com/bcaitech1/p3-ims-obd-hansarang">https://github.com/bcaitech1/p3-ims-obd-hansarang</a></p><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ul><li><p>ë¬¸ì œì •ì˜ : ì“°ë ˆê¸°ê°€ ì°íŒ ì‚¬ì§„ì—ì„œ ì“°ë ˆê¸°ë¥¼ Segmentation </p></li><li><span id="more"></span></li><li><p><strong>Input data</strong> :  4109ì¥ì˜ ì“°ë ˆê¸° ì‚¬ì§„ì¤‘, 3287ì¥ (80%)ëŠ” train data, ë‚˜ë¨¸ì§€ 812ì¥(20%)ëŠ” private test data  (512,512)ì˜ ì´ë¯¸ì§€</p><ul><li><p><strong>Annotation</strong> </p><ol><li>train_all.json: trainì— ì“°ì¼ ìˆ˜ ìˆëŠ” ëª¨ë“  image, annotation ì •ë³´ (image: 3272, annotation: 26400)</li><li>train.json: train_all.json ì¤‘ 4/5ì— í•´ë‹¹í•˜ëŠ” ì •ë³´ (image: 2617, annotation: 21116)</li><li>val.json: train_all.json ì¤‘ 1/5ì— í•´ë‹¹í•˜ëŠ” ì •ë³´ (image: 655, annotation: 5284)</li><li>test.json: ì˜ˆì¸¡í•´ì•¼í•  ì´ë¯¸ì§€ë“¤ì˜ ì •ë³´ (image: 837)</li></ol><ul><li>id: íŒŒì¼ ì•ˆì— annotation ê³ ìœ  id, ì´ê±´ í•œ image ì•ˆì— ì—¬ëŸ¬ê°€ì§€ì˜ ê°ì²´ê°€ ìˆê¸° ë–„ë¬¸ì— imageë³„ë¡œ ê°ê°ì˜ ê°ì²´ì˜ annotationë“¤ì´ ìˆë‹¤.</li><li>segmentation: masking ë˜ì–´ ìˆëŠ” ê³ ìœ ì˜ ì¢Œí‘œ</li><li>bbox: ê°ì²´ê°€ ì¡´ì¬í•˜ëŠ” ë°•ìŠ¤ì˜ ì¢Œí‘œ (x_min, y_min, w, h)</li><li>area: ê°ì²´ê°€ ì¡´ì¬í•˜ëŠ” ì˜ì—­ì˜ í¬ê¸°</li><li>category_id: ê°ì²´ê°€ í•´ë‹¹í•˜ëŠ” classì˜ id</li><li>image_id: annotationì´ í‘œì‹œëœ ì´ë¯¸ì§€ ê³ ìœ  id</li></ul></li><li><p>images</p><ul><li>id: íŒŒì¼ ì•ˆì—ì„œ image ê³ ìœ  id, ex) 1</li><li>height: 512</li><li>width: 512</li><li>file_name: ex) batch_01_vt/002.jpg</li></ul></li></ul></li><li><p><strong>Output data</strong> : 11 class = {UNKNOWN, General trash, Paper, Paper pack, Metal, Glass, Plastic, Styrofoam, Plastic bag, Battery, Clothing}</p></li><li><p><strong>í‰ê°€ Metric</strong></p><img src="/images/image-20210426120429513.png" alt="image-20210426120429513" style="zoom:50%;" /><img src="/images/image-20210426120549788.png" alt="image-20210426120549788" style="zoom:50%;" /></li></ul><p>ë²Œì¨ 2ì£¼ì „ì˜ ê¸°ì–µì´ë¼ ê°€ë¬¼ê°€ë¬¼í•˜ì§€ë§Œ ì¼ë ¬ì˜ ê³¼ì •ë“¤ì„ í•˜ë‚˜í•˜ë‚˜ ë˜ì§šì–´ ë³´ë©° ì´ì–´ë‚˜ê°€ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.</p><p>deeplab V3+, efficientnet-b5</p><ol><li>EDA</li></ol><p>ë¨¼ì € EDA ë¶€í„° ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. ìˆ˜ì—…ì—ì„œ ì œê³µí•´ì£¼ì‹  edaë“¤ë¡œ ìš°ë¦¬ dataì˜ labelë¶„í¬ë¥¼ í™•ì¸í•  ìˆ˜ ìˆì—ˆê³ , ë”°ë¡œ ì´ë¯¸ì§€ dataë¥¼ ì‹œê°í™”ë¥¼ í•´ë³´ë©° ì´ì „ì˜ stageì™€ ë§ˆì°¬ê°€ì§€ë¡œ ìƒë‹¹íˆ imbalanceí•˜ë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œê²Œë˜ì—ˆìŠµë‹ˆë‹¤. </p><p>ì´ì— stage 2ë•Œë„ ì ìš©í•˜ì˜€ë˜ focal lossì™€ ë‹¤ì–‘í•œ augmentationì„ ì‚¬ìš©í•˜ì—¬ í•´ê²°í•´ì•¼ê² ë‹¤ëŠ” ìƒê°ì´ ë“¤ì—ˆìŠµë‹ˆë‹¤.</p><ol start="2"><li>Model</li></ol><p>ìœ„ì—ì„œ ì–¸ê¸‰í•œê²ƒ ì²˜ëŸ¼ ì²˜ìŒë¶€í„° sotaì— ê°€ê¹Œìš´ deeplab V3+ë¥¼ ì„ ì •í•˜ì˜€ê³ , íš¨ìœ¨ì ì´ê³  ë‹¤ì–‘í•œ ì‹¤í—˜ê³¼ì •ì„ ìœ„í•´ backboneì€ efficientnet b1ìœ¼ë¡œì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. ì´ì— ì‘ì€ modelì—ì„œì˜ parameterê°€ ê³¼ì—° í° modelì—ì„œë„ ë˜‘ê°™ì´ ì ìš©ë ê¹Œë¼ëŠ” ì˜ë¬¸ì´ ë“¤ì—ˆì§€ë§Œ, ì´ëŠ” lrì´ë‚˜ schedulerì— í•´ë‹¹í•œë‹¤ê³  ìƒê°ì´ ë˜ì–´, augmentationì‹¤í—˜ì—ì„œë§Œ modelì˜ sizeë¥¼ ë‚®ì¶”ì—ˆìŠµë‹ˆë‹¤.</p><p>ê°€ì¥ì²˜ìŒ í•œ ì‹¤í—˜ì€ ì œê¸°ì–µì—ëŠ” ë™ì¼ì¡°ê±´ì—ì„œì˜  backboneì— ë”°ë¥¸ ì„±ëŠ¥ì´ì˜€ìŠµë‹ˆë‹¤.</p><p>ë‹¤ì–‘í•œ í¬ê¸°ì˜ Resnextì™€ efficientNetìœ¼ë¡œ ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ê³ , ê²°ë¡ ì ìœ¼ë¡œ efficientNet-b5ë¥¼ backboneìœ¼ë¡œ ì“´ modelì´ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ìŠµë‹ˆë‹¤.<br>ResnextëŠ” efficientNetì— ë¹„í•´ ìˆ˜ë ´ì†ë„ë„ ë¹ ë¥´ê³  epochë‹¹ ì‹œê°„ë„ ì ê²Œ ê±¸ë ¤, ì´í›„ì˜ ì•™ìƒë¸”ì„ ìœ„í•´ best modelì„ ì €ì¥í•´ ë‘ì—ˆìŠµë‹ˆë‹¤. </p><ol start="3"><li>Augmentation</li></ol><p>ì´ë²ˆ taskì—ì„œ ì“°ê²Œëœ augmentationì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤</p><ol><li>HorizontalFlip(p=0.5)</li><li>Rotate(p=0.5, limit=45)</li><li>Cutout(num_holes=4, max_h_size=20, max_w_size=20),            </li><li>CLAHE(),            </li><li>RandomBrightnessContrast(p=0.5),            </li><li>Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0)</li></ol><p>ì´ë ‡ê²Œ ì¡°í•©í•´ì„œ ì¼ì„ë•Œ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ë‹¤ëŠ” ê²°ë¡ ì„ ì–»ì—ˆì—ˆìŠµë‹ˆë‹¤.<br>ë‹¤ì–‘í•œ ì¡°í•©ê³¼ í™•ë¥  ê°’ë“¤ì„ ì ìš©í•˜ì—¬ ë¹„êµí•˜ì—¬ ì§„í–‰í•˜ëŠ” ì¼ë ¨ì˜ ê³¼ì •ë“¤ì€ ë§¤ìš° ê³ ë˜ê³  ë§ì€ ì‹œê°„ì„ í•„ìš”ë¡œ í•˜ì˜€ìŠµë‹ˆë‹¤.<br>ì—¬ê¸°ì„œ ì§€ê¸ˆì™€ì„œ ìƒê°í•´ë³´ë©´ Auto Augmentationì„ ì ìš©í•´ ë³´ì•˜ìœ¼ë©´ ì¢‹ì•˜ì„ë“¯ ì‹¶ìŠµë‹ˆë‹¤â€¦</p><p>ë˜í•œ ì¶”ê°€ì ìœ¼ë¡œ horizontalflipì„ ì´ìš©í•œ ttaë¥¼ ì ìš©ì‹œì¼œ ë³´ì•˜ì§€ë§Œ, ì„±ëŠ¥ì˜ í•˜ë½ì„ ì•¼ê¸°í–ˆìŠµë‹ˆë‹¤.</p><ol start="4"><li>Loss &amp; Optimizer &amp; Scheduler</li></ol><p>LossëŠ” Focal lossì™€ soft-crossentropy-lossë¥¼ ê°ê° 0.3,0.7ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë‘ì–´ í•™ìŠµí•˜ì˜€ìŠµë‹ˆë‹¤. ì›ë˜ëŠ” Focalë§Œì„ ì‚¬ìš©í•˜ì˜€ì§€ë§Œ, stage1ì—ì„œ multi lossì—ì„œ ì¬ë¯¸ë¥¼ ë§ì´ ë´¤ì—ˆê¸° ë•Œë¬¸ì—, ë§ˆìŠ¤í„°ë‹˜ì˜ ì˜ê²¬ì„ ë“£ê³  sclì„ ì¶”ê°€í•´ ì£¼ì—ˆìŠµë‹ˆë‹¤.</p><p>ì™œì¸ì§€ëŠ” ëª¨ë¥´ê² ì§€ë§Œ  soft-crossentropy-lossë§Œì„ ì‚¬ìš©í•˜ì˜€ì„ë•Œ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•„, ì•™ìƒë¸”ë•Œì˜ ë‹¤ì–‘ì„±ì„ ìœ„í•´ multilossë¡œë„ í•™ìŠµì„ í•´ë‘ì—ˆìŠµë‹ˆë‹¤.</p><p>Optimizerë˜í•œ Adamê³„ì—´ì˜ Adampë¥¼ ì‚¬ìš©í•˜ì˜€ê³ , Adamê³„ì—´ê³¼ ì˜ì–´ìš¸ë¦¬ëŠ” Customizedëœ CosineAnnealingWarmRestartsì˜ schedulerë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. í™•ì‹¤ì´ ì¤‘ê°„ì¤‘ê°„ì— lrì„ ë†’í˜€ì£¼ëŠ”ê²Œ local minimumì„ ì˜ë¹ ì ¸ë‚˜ì˜¤ëŠ” ëª¨ìŠµì„ í™•ì¸ í•  ìˆ˜ìˆì—ˆìŠµë‹ˆë‹¤. ë‚´ë¶€ì— ë‚´ì¥ëœ Cosin schedulerì€ gammaê°€ ì—†ê¸°ë•Œë¬¸ì— customizedëœ schedulerë¥¼ ë¶ˆëŸ¬ë‹¤ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤. Adamì— ì˜ë§ëŠ” cosine ê³„ì—´ì˜ schedulerë¥¼ ì‚¬ìš©í•œ ê²°ê³¼, steplrì„ ì‚¬ìš©í•œ íƒ€ íŒ€ì›ì˜ model ëŒ€ë¹„ ì œ modelì˜ ì„±ëŠ¥ì´ ì˜ë‚˜ì™”ìŒì„ í™•ì¸í•˜ì˜€ìŠµë‹ˆë‹¤.</p><p>wandbì˜ ê·¸ë˜í”„ë¥¼ ë³´ì‹œë©´ ë³´í†µ 18 epochì¯¤ì—ì„œ ìµœê³ ì ì„ ì°ê³  ìˆ˜ë ´í•˜ëŠ” ëª¨ìŠµì„ ê´€ì°°í•˜ì˜€ìŠµë‹ˆë‹¤.</p><ol start="5"><li>K-fold &amp; Pseudo Labeled data</li></ol><p>single modelì˜ ì„±ëŠ¥ì˜ í•œê³„ì— ë¶€ë”›í˜€ 0.63ëŒ€ë¥¼ í—¤ì–´ë‚˜ì˜¤ì§€ ëª»í•˜ê³ ìˆì—ˆë˜ 2ì£¼ì°¨â€¦<br>ê¸°ì¡´ì˜ ìµœê³ ì„±ëŠ¥ parameterë¥¼ ê³ ì •í•˜ê³  Train+allê³¼ pseudo labeledëœ dataë¥¼ í•©ì³ì„œ 2ë°°ì˜ dataë¡œ í•™ìŠµì„ ì§„í–‰í•˜ì˜€ê³  ê²°ê³¼ëŠ” ë§¤ìš° ì„±ê³µì ì´ì˜€ìŠµë‹ˆë‹¤. K-foldë¡œ ì§„í–‰í•˜ê³  ì‹¶ì—ˆì§€ë§Œ, GPUìì›ì˜ ë¶€ì¡±ìœ¼ë¡œ ì¸í•œ ì‹œê°„ì˜ í•œê³„ë•Œë¬¸ì— Train-allë¡œ ì§„í–‰í•˜ì—¬ ì œê°€ ê²½í—˜ì ìœ¼ë¡œ ì²´ë“í•œ 18 epochì—ì„œ ëŠëŠ” ë°©ì‹ì„ ì²´íƒí•˜ì˜€ìŠµë‹ˆë‹¤. ê²°ê³¼ëŠ” ë§¤ìš°ì„±ê³µì ìœ¼ë¡œ single model ê¸°ì¤€ 0.6842ë¼ëŠ” í° ì„±ëŠ¥í–¥ìƒì„ ì–»ì–´ë‚´ì—ˆìŠµë‹ˆë‹¤.</p><p>ë‹¤ë¥¸ íŒ€ì›ë¶„ë“¤ë„ pseudo labelì„ ì ìš©í•˜ì—¬ ì•™ìƒë¸”ì„ í•˜ì˜€ë‹¤ë©´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì–´ë‚¼ ìˆ˜ ìˆì—ˆì„í…ë° ë§¤ìš° ì•„ì‰½ìŠµë‹ˆë‹¤.</p><ol start="6"><li>ì•™ìƒë¸”</li></ol><p>ìµœì¢…ì ìœ¼ë¡œ ì €ì˜ ë‹¤ì–‘í•œ backboneê³¼ lossë¥¼ ê°€ì§€ëŠ” modelë“¤ì„ ì¡°í•©í•˜ì—¬ soft votingì„ í•˜ì˜€ìŠµë‹ˆë‹¤. ê°€ì¤‘ì¹˜ëŠ” LBìƒìœ¼ë¡œ ê°€ì¥ë†’ì€ modelì— 0.4ë¥¼ ì£¼ì—ˆê³  ë‚˜ë¨¸ì§€ì— 0.2ì”©ì„ ì£¼ì–´ ì´ 4ê°œì˜ singel   modelì„ ì•™ìƒë¸” í•˜ì—¬ ì œì¶œì„ í•´ë´¤ëŠ”ë°, 0.6961ì´ë¼ëŠ” ì•„ì£¼ ë†’ì€ ì ìˆ˜ê°€ ë‚˜ì™”ìŠµë‹ˆë‹¤. ì´ modelì— ë‹¤ë¥¸ íŒ€ì›ë¶„ë“¤ì˜ model hard voting í•´ë³´ì•˜ì§€ë§Œ ì„±ëŠ¥ì´ ê³„ì† í•˜ë½í•˜ì—¬ ê²°êµ­ì—ëŠ” ì €ì˜ modelë§Œì„ ì‚¬ìš©í•œ ì ìˆ˜ê°€ ìµœì¢…ì ìˆ˜ê°€ ë˜ëŠ” ì•„ì‰¬ìš´ ìƒí™©ì´ ì—°ì¶œë˜ì—ˆìŠµë‹ˆë‹¤â€¦</p><p>ì–´ëŠì •ë„ íŒ€ì›ë“¤ê°„ì˜ í‰ê· ì ì¸ ì ìˆ˜ëŒ€ê°€ ë¹„ìŠ·í•´ì•¼ ì•™ìƒë¸” í–ˆì„ë•Œ ì¢‹ì€ ì ìˆ˜ë¥¼ ë‚¼ìˆ˜ìˆì—ˆì§€ë§Œ, psudo labelì„ ì €ë§Œ ëŒë ¸ì—ˆê¸° ë•Œë¬¸ì—â€¦<br>ì‹œê°„ì´ 2ì¼ì •ë„ ë”ìˆì—ˆë‹¤ë©´ ë‹¤ë¥¸ íŒ€ì› ë¶„ë“¤ë„ ìˆ˜ë„ë¼ë²¨ë¡œ ì„±ëŠ¥ì„ ì–´ëŠì •ë„ í–¥ìƒì‹œì¼œ ë¹„ìŠ·í•œ ì ìˆ˜ëŒ€ë¡œ ë§ì¶°ì¤„ìˆ˜ ìˆì—ˆì„ í…ë° í•˜ëŠ” ì•„ì‰¬ì›€ì´ ë‚¨ì•˜ìŠµë‹ˆë‹¤â€¦</p><h1 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object Detection"></a>Object Detection</h1><ul><li><strong>í‰ê°€ Metric</strong></li></ul><p><img src="/images/image-20210522134724067.png" alt="image-20210522134724067"></p><p><img src="/images/image-20210522140707268.png" alt="image-20210522140707268"></p><p>ìœ„ì™€ ê°™ì€ PB curveë¥¼ ê·¸ë¦°ë‹¤. ì´ ë•Œ recallê³¼ precisionì€ confidence scoreë³„ë¡œ ì ë“¤ì´ ìƒì„±ë©ë‹ˆë‹¤.<br>ì´í›„ (A+B)ì— í•´ë‹¹í•˜ëŠ” ì˜ì—­ì˜ ë„“ì´ê°€ APê°€ ë˜ê³ , ê°ê°ì˜ classì˜ APì˜ í‰ê· ì´ ì €í¬ê°€ êµ¬í•˜ë ¤ëŠ” mAPì…ë‹ˆë‹¤.</p><p>ì´ë²ˆ object taskì—ì„œëŠ” mmdetectionì´ë¼ëŠ” ê°•ë ¥í•œ toolì„ ê¸°ë°˜ìœ¼ë¡œ ì‹¤í—˜ì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤.<br>mmdetectionì—ì„œëŠ” ì €í¬ê°€ configíŒŒì¼ë§Œì„ ìˆ˜ì •í•˜ì—¬ ì¤€ë‹¤ë©´ ì†ì‰½ê²Œ ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ë‹¤ì–‘í•œ modelë“¤ì„ ì‹¤í—˜í•´ ë³¼ ìˆ˜ìˆì—ˆìŠµë‹ˆë‹¤.</p><ol><li>Model</li></ol><p>ì´ë²ˆ taskì—ì„œë˜í•œ sota modelë¡œ ì•Œë ¤ì§„ swin transformerë¥¼ backboneìœ¼ë¡œ ì“°ê³  detector ë¶€ë¶„ì€ cascade mask rcnnê³¼ htcë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.<br>ë‹¤í–‰ì´ë„ Swin transformerì˜ configíŒŒì¼ì´ gitì— ì „ë¶€ ì˜¬ë¼ì™€ìˆì—ˆê³ , ì €í¬ì˜ ì‹¤í—˜í™˜ê²½ì— ë§ê²Œ ì¡°ê¸ˆ ë³€ê²½í•´ ì£¼ë©´ ë˜ì—ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ mmdetectionì´ë¼ëŠ” íˆ´ìì²´ì— ì ì‘ì„ í•˜ëŠ”ë° ì‹œê°„ì´ ì¢€ ì†Œìš”ê°€ ë˜ì—ˆê³ , í•œ 3-4ì¼ ì •ë„ê°€ ì§€ë‚˜ì„œì•¼ ì–´ëŠì •ë„ ê°€ë‹¥ì´ ì¡íˆë©´ì„œ ì–´ë–»ê²Œ ì¨ì•¼í• ì§€ ê°ì´ ì¡í˜”ë˜ê²ƒ ê°™ìŠµë‹ˆë‹¤.</p><p>backboneì„ ê³ ì •í•œ í›„ neckì„ ë³€ê²½ì‹œì¼œì„œ ë‹¤ì–‘í•œ ì‹¤í—˜ì„ í•´ë³´ì•˜ìŠµë‹ˆë‹¤.</p><ol><li>FPN</li><li>PAFPN </li><li>NAS-FPN</li><li>BiFPN</li></ol><p>ì´ë ‡ê²Œ 4ê°€ì§€ì˜ ì„ íƒì§€ê°€ ìˆì—ˆëŠ”ë° ì´ì¤‘ ê°€ì¥ ì˜¤ë˜ëœ FPNì„ ì„ íƒí•œ ì´ìœ ëŠ” í•œê°€ì§€ ì…ë‹ˆë‹¤. ì™œëƒí•˜ë©´ pretrainedëœ pthíŒŒì¼ì„ githubì—ì„œ ì œê³µí•´ì£¼ê³  ìˆëŠ”ë°, ì´ modelì—ì„œ FPNì„ ì“°ê³ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.</p><p>ì²˜ìŒì—ëŠ” backboneë§Œì„ pretrainedëœê±¸ ê°€ì ¸ì™€ì„œ ì“°ë‹¤ê°€, ì „ì²´ê°€ trainedëœ modelì´ ìˆëŠ”ê²ƒì„ ë°œê²¬í•˜ê³  ì‹¤í—˜í•´ë³´ì•˜ëŠ”ë° ì „ì²´ê°€ pretrainedëœê±¸ ê°€ì ¸ì™€ì„œ ì €í¬ taskì— fine tuning? transfer learningí•˜ëŠ” ë°©ì‹ì´ ë”ìš± ì„±ëŠ¥ì´ ì¢‹ì•˜ìŠµë‹ˆë‹¤. </p><p>FPNìœ¼ë¡œ trainedëœ ì „ì²´ modelì„ ê°€ì ¸ë‹¤ê°€ NAS-FPNìœ¼ë¡œ ë°”ê¾¸ì–´ì¤€ modelì— ì ìš©ì„ ì‹œì¼œì¤„ì‹œ neckìª½ì˜ weightë“¤ì—ëŠ” ê°’ì´ ë“¤ì–´ê°€ì§€ ì•Šê²Œë©ë‹ˆë‹¤. ì´ê²ƒì´ ì„±ëŠ¥ì´ ë” ì¢‹ì„ ìˆ˜ë„ ìˆê¸°ë•Œë¬¸ì— ì´ëŸ¬í•œ ë°©ë²•ë„ ì‹œë„í•´ ë³´ì•˜ì§€ë§Œ, ë°”ê¾¸ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ FPNì„ ì‚¬ìš©í•˜ëŠ”ê²ƒì´ ë” ì¢‹ì•˜ìŠµë‹ˆë‹¤.</p><p>í•œê°€ì§€ ì•„ì‰¬ì› ë˜ ê²ƒì€ pretrainedëœ Swin transformerë¥¼ backboneìœ¼ë¡œ ì“°ë©´ì„œ swinì— ëŒ€í•œ ì–´ëŠì •ë„ ì „ë°˜ì ì¸ ì´í•´ë§Œì„ ê°€ì§€ê³  ìˆì—ˆì„ë¿, ì„¸ì„¸í•œ modelì˜ êµ¬ì¡°ëŠ” ì•Œì§€ ëª»í•œì±„ ì‘ì„±ë˜ì–´ì§„ config íŒŒì¼ë§Œì„ ê°€ì§€ê³  ì‹¤í—˜ì—ë§Œ ì§‘ì¤‘í•  ìˆ˜ ë°–ì— ì—†ì—ˆë˜ ìƒí™©ì´ì˜€ìŠµë‹ˆë‹¤.</p><p>ì•½ê°„ì”© parameterë“¤ì„ ìˆ˜ì •í•´ ì£¼ë©´ì„œ, ê·¼ë³¸ì ì¸ ì´í•´ì—†ì´ ì§ê´€ì— ì˜í•´ ì‹¤í—˜ì„ ë°˜ë³µí•˜ê³  ìˆëŠ” ì œ ìì‹ ì„ ë°œê²¬í•œ í›„ competitionì— ëŒ€í•œ ì•½ê°„ì˜ íšŒì˜ê°ì´ ë“¤ì—ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë©˜í† ë‹˜ê»˜ì„œ libraryë¥¼ ì˜ë‹¤ë£¨ëŠ” ê²ƒë„ í•˜ë‚˜ì˜ ëŠ¥ë ¥ì´ë¼ê³  ë§ì”€í•´ì£¼ì…”ì„œ ë‹¤ì‹œ í•œë²ˆ ìƒê°í•´ ë³´ì•˜ë˜ê²ƒ ê°™ìŠµë‹ˆë‹¤.</p><ol start="2"><li>Augmentation</li></ol><p>Augmentationì—ëŠ” Flipê³¼ Autoaugmentation, Normalizeë“±ì„ ì ìš©í•´ë³´ì•˜ìŠµë‹ˆë‹¤.<br>ê°€ì¥ criticalí•˜ê²Œ ì‘ìš©í–ˆë˜ augementationì´ ë°”ë¡œ autoaugë¡œ, ì—¬ê¸°ì„œ resizeì™€ crop sizeë¥¼ ì–´ë–»ê²Œ ì£¼ëŠëƒì— ë”°ë¼ ì„±ëŠ¥ì°¨ì´ê°€ ì¡°ê¸ˆì”© ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì´ì „ stageë“¤ì—ì„œì˜ ê²½í—˜ìœ¼ë¡œ, image taskì—ì„œ high scaleì˜ image trainingì€ ì˜¤ëœ ì‹œê°„ì„ ìš”êµ¬í•˜ì§€ë§Œ ê·¸ë§Œí¼ ì„±ëŠ¥ì´ ì˜ë‚˜ì™”ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ resizeì˜ listì—ëŠ” upscaleëœ ì •ì‚¬ê°í˜•ê³¼ ê°€ë¡œê°€ ê¸´ ì§ì‚¬ê°í˜•, ì„¸ë¡œê°€ ê¸´ ì§ì‚¬ê°í˜•ë“±ì„ ê³ ë£¨ ì„ì–´ autoaugì•ˆì— ì¸ìë¡œ ë„£ì–´ì£¼ì—ˆìŠµë‹ˆë‹¤.</p><p>ì´ëŸ¬í•œ ë³€ê²½ì ì€ ì •ì‚¬ê°í˜•ë§Œì„ ë„£ì–´ì¤¬ì„ë•Œ, low scaleing í•´ì£¼ì—ˆì„ë•Œì— ë¹„í•´ì„œ ì ìˆ˜ì˜ í° í–¥ìƒì„ ì•¼ê¸°í–ˆìŠµë‹ˆë‹¤.</p><ol start="3"><li>Loss Optimizer Scheduler</li></ol><p><strong>Loss</strong></p><p>ì €í¬ê°€ ë°”ê¾¸ì–´ ì¤„ ìˆ˜ìˆì—ˆë˜ lossëŠ” bbox lossë¡œ 3ê°€ì§€ ì •ë„ì˜ ì„ íƒì§€ê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ê·¸ì¤‘ DIoU Lossë¥¼ ì±„íƒí•˜ì˜€ì„ë•Œ ì„±ëŠ¥ì´ ì•½ê°„ ìƒìŠ¹í–ˆê³ , classification lossìª½ì˜ cross entropy lossëŠ” ê±´ë“œë¦¬ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.  </p><p><strong>Optimizer</strong> </p><p>Optimizerì€ AdamWë¥¼ ì‚¬ìš©í•˜ì˜€ê³ , ì´ˆê¸° lrê°’ì€ 1e-4ìœ¼ë¡œ ê³ ì •ì‹œì¼œ ì£¼ì—ˆìŠµë‹ˆë‹¤.</p><p><strong>Scheduler</strong></p><p>Schedulerì€ modelì— ë”°ë¼ ë‹¤ë¥´ê²Œ ì ìš©ì‹œì¼œ ì£¼ì—ˆìŠµë‹ˆë‹¤.</p><p>HTCë¥¼ ì´ìš©í•œ modelì—ëŠ” cosineannealingì„ cascade mask rcnnì„ ì ìš©í•œ modelì—ëŠ” steplrì„ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.</p><p>StepLRì„ ì‚¬ìš©ì‹œ ì–´ë– í•œ epochì—ì„œ lrê°’ì„ ê°ì†Œì‹œì¼œì¤„ì§€ë¥¼ ì •í•  ìˆ˜ ìˆì—ˆëŠ”ë°, í‰ê· ì ìœ¼ë¡œ 8,11 epochì—ì„œ map50ê°’ì´ ìˆ˜ë ´í•˜ê¸° ì‹œì‘í•˜ëŠ”ê²ƒì„ í™•ì¸í•˜ê³  ì´ì¯¤ì—ì„œ gamma=0.1ì˜ factorë¡œ lrê°’ì„ ê°ì†Œì‹œì¼œì£¼ì—ˆìŠµë‹ˆë‹¤.</p><ol start="4"><li>Pseudo-labeling</li></ol><p>ì´ì „ segementationì—ì„œ pseudo labelingìœ¼ë¡œ í° ì¬ë¯¸ë¥¼ ë³´ì•˜ì—ˆê¸° ë•Œë¬¸ì— ì´ë²ˆ taskì—ì„œëŠ” ì¢€ ì¼ì° ìµœê³ ì„±ëŠ¥ì˜ modelë¡œ pseudo dataë¥¼ ë§Œë“¤ì–´ ë¹ ë¥´ê²Œ ì‹¤í—˜í•´ ë³´ì•˜ìŠµë‹ˆë‹¤. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./train_all.json&#x27;</span>) <span class="keyword">as</span> json_file1:</span><br><span class="line">    train_data = json.load(json_file1)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./test.json&#x27;</span>) <span class="keyword">as</span> json_file2:</span><br><span class="line">    test_data = json.load(json_file2)</span><br><span class="line"></span><br><span class="line">start = <span class="built_in">len</span>(train_data[<span class="string">&#x27;images&#x27;</span>])</span><br><span class="line">train_id = train_data[<span class="string">&#x27;images&#x27;</span>]</span><br><span class="line">test_id = test_data[<span class="string">&#x27;images&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> test_id:</span><br><span class="line">    idx[<span class="string">&#x27;id&#x27;</span>] = start</span><br><span class="line">    start+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">PredictionString = pd.read_csv(<span class="string">&#x27;./output1.csv&#x27;</span>)[<span class="string">&#x27;PredictionString&#x27;</span>]</span><br><span class="line">annotation = []</span><br><span class="line">ids = <span class="number">26402</span></span><br><span class="line">image_id = start</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> bboxs <span class="keyword">in</span> PredictionString:</span><br><span class="line">    bboxs = bboxs.strip().split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    bboxs = [<span class="built_in">float</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> bboxs]</span><br><span class="line">    bboxs = [bboxs[i:i + <span class="number">6</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(bboxs), <span class="number">6</span>)]</span><br><span class="line">    <span class="keyword">for</span> bbox <span class="keyword">in</span> bboxs:</span><br><span class="line">        prob = bbox[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> prob&lt;<span class="number">0.8</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        temp = <span class="built_in">dict</span>()</span><br><span class="line">        temp[<span class="string">&#x27;id&#x27;</span>] = ids</span><br><span class="line">        temp[<span class="string">&#x27;image_id&#x27;</span>] = image_id</span><br><span class="line">        temp[<span class="string">&#x27;category_id&#x27;</span>] = <span class="built_in">int</span>(bbox[<span class="number">0</span>])</span><br><span class="line">        temp[<span class="string">&#x27;segmentation&#x27;</span>] = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]]</span><br><span class="line">        temp[<span class="string">&#x27;area&#x27;</span>] = <span class="number">1</span></span><br><span class="line">        bbox = bbox[<span class="number">2</span>:]</span><br><span class="line">        new = [bbox[<span class="number">0</span>],bbox[<span class="number">3</span>],bbox[<span class="number">2</span>]-bbox[<span class="number">0</span>],bbox[<span class="number">3</span>]-bbox[<span class="number">1</span>]]</span><br><span class="line">        new = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">list</span>(np.<span class="built_in">round</span>(new, <span class="number">1</span>))]</span><br><span class="line">        temp[<span class="string">&#x27;bbox&#x27;</span>] = new</span><br><span class="line">        temp[<span class="string">&#x27;iscrowd&#x27;</span>] = <span class="number">0</span></span><br><span class="line">        annotation.append(temp)</span><br><span class="line">        ids+=<span class="number">1</span></span><br><span class="line">    image_id+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;images&#x27;</span>] += test_id</span><br><span class="line">train_data[<span class="string">&#x27;annotations&#x27;</span>] += annotation</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./train+pseudo.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> outfile:</span><br><span class="line">    json.dump(json_data1, outfile,indent=<span class="number">4</span>)</span><br><span class="line">    </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>ìœ„ì˜ ì½”ë“œë¡œ pseudo dataë¥¼ cocoí˜•íƒœë¡œ ë°”ê¾¸ì–´ì¤€ë’¤ í†µí•©ëœ json íŒŒì¼ë¡œ trainì„ ì§„í–‰í•˜ì˜€ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ thresholdê°’ì„ ì„¤ì •í•´ì£¼ëŠ”ê²Œ ë§¤ìš° ì• ë§¤í–ˆë‹¤.<br>ì´ì— ë”°ë¼ ì„±ëŠ¥ì´ ë„ˆë¬´ í•˜ë½í•˜ëŠ” í˜„ìƒì´ ë°œìƒí•˜ì˜€ê³  ê²°êµ­ pseudo labelëœ dataëŠ” ì“°ì§€ ëª»í•˜ì˜€ìŠµë‹ˆë‹¤â€¦</p><p>segementationì—ì„œ ì˜ë¨¹íˆë˜ pseudo labelì´ detectionì—ì„œëŠ” ë¶€ì •í™•í•œ labelê°’ë“¤ë¡œ í•™ìŠµì´ ì–´ë ¤ìš´ê°€ ë´…ë‹ˆë‹¤.</p><ol start="5"><li>WBF</li></ol><p>ë§ˆì§€ë§‰ìœ¼ë¡œ ìµœê³  single model ê¸°ì¤€ htcì™€ cascade ëª¨ë‘ 0.5572ì˜ ì ìˆ˜ë¥¼ ì–»ì–´ëƒˆê³  ì´ 4ê°œì˜ modelì„ ì•™ìƒë¸”í•œ ê²°ê³¼ 0.5824ì˜ ê²°ê³¼ë¥¼ ì–»ì–´ëƒˆìŠµë‹ˆë‹¤.<br>ì´í›„ ëª¨ë“  íŒ€ì›ë“¤ì˜ csv íŒŒì¼ì„ WBFí•˜ì—¬ ìµœì¢…ì ì¸ score 0.5884ë¥¼ ì–»ì–´ë‚´ì—ˆìŠµë‹ˆë‹¤.</p><p>Conclusion</p><p>í•œê°€ì§€ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ëŠë‚€ì ì€ ì´ë ‡ê²Œ competitionì„ ë§ˆì¹œì´í›„ì— ê´€ë ¨ ë…¼ë¬¸ë“¤ê³¼ kaggle notebookë“¤ì„ ìì„¸íˆ ì •ë…í•˜ë©° ì“°ì˜€ë˜ ë°©ë²•ë¡ ë“¤ê³¼ modelë“¤ì„ ìƒì„¸í•˜ê²Œ ê³µë¶€í•´ì•¼ ê² ë‹¤ëŠ” í•„ìš”ì„±ì…ë‹ˆë‹¤.</p><p>competition ì§„í–‰ì¤‘ì— ê°œì„ í•´ì•¼ í•  ì‚¬í•­ì€ ì¤‘ê°„ì¤‘ê°„ íŒ€ì›ë“¤ê°„ì˜ í‰ê· ì ì¸ ì ìˆ˜ëŒ€ë¥¼ ë§ì¶”ì–´ ë†“ì•„ì•¼ ìµœì¢… ì•™ìƒë¸” ê³¼ì •ì—ì„œ í° ì„±ëŠ¥ í–¥ìƒì„ ì´ë£°ìˆ˜ ìˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤. </p><p>êµ‰ì¥íˆ ì—´ì •ì ì¸ 4ì£¼ë¥¼ ë³´ëƒˆìŠµë‹ˆë‹¤â€¦ ì•„ì‰¬ì›€ë„ ë‚¨ê³  í›„ë ¨í•˜ê¸°ë„ í•©ë‹ˆë‹¤â€¦<br>ì§„í–‰í–ˆë˜ ë§ì€ ì‹¤í—˜ ë‚´ìš©ë“¤ì„ ëª¨ë‘ ë©ì—…ë ˆí¬íŠ¸ì— ë‹´ì§€ ëª»í–ˆë‹¤â€¦. ì¶”í›„ì— ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬í•´ì„œ gitì— ì˜¬ë ¤ë‘¬ì•¼ê² ìŠµë‹ˆë‹¤.</p>]]></content:encoded>
      
      
      <category domain="https://jo-member.github.io/categories/Boostcamp/">Boostcamp</category>
      
      
      <category domain="https://jo-member.github.io/tags/Summary/">Summary</category>
      
      <category domain="https://jo-member.github.io/tags/CV/">CV</category>
      
      
      <comments>https://jo-member.github.io/2021/04/25/Pstage3-Image-Segmentation-Detection/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Pstage2_KLUE</title>
      <link>https://jo-member.github.io/2021/04/22/Pstage2-KLUE/</link>
      <guid>https://jo-member.github.io/2021/04/22/Pstage2-KLUE/</guid>
      <pubDate>Thu, 22 Apr 2021 06:29:38 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;ë¬¸ì¥ë‚´-ê°œì²´ê´€-ê´€ê³„-ì¶”ì¶œ&quot;&gt;&lt;a href=&quot;#ë¬¸ì¥ë‚´-ê°œì²´ê´€-ê´€ê³„-ì¶”ì¶œ&quot; class=&quot;headerlink&quot; title=&quot;ë¬¸ì¥ë‚´ ê°œì²´ê´€ ê´€ê³„ ì¶”ì¶œ&quot;&gt;&lt;/a&gt;ë¬¸ì¥ë‚´ ê°œì²´ê´€ ê´€ê³„ ì¶”ì¶œ&lt;/h1&gt;&lt;p&gt;ë­”ê°€ ì•„ì‰¬ì› ë˜ P-stage 2 KLUEê°€ ëì´ ë‚¬ë‹¤.&lt;/p&gt;
&lt;p&gt;ì´ë²ˆ stageì—ì„œëŠ” ë¦¬ë”ë³´ë“œ ìˆœìœ„ë¥¼ ì˜¬ë¦¬ëŠ”ë°ì—ë§Œ ì§‘ì¤‘í•˜ê¸° ë³´ë‹¤ëŠ” ë‹¤ì–‘í•œ taskë¥¼ ì¨ë³´ê³  ì›ë¦¬ë¥¼ ì´í•´í•˜ê³  ê²°ê³¼ë¥¼ í† ë¡ ê³„ì‹œíŒì— ê¼­ ì¡°ê¸ˆì´ë¼ë„ ê³µìœ í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í•˜ê¸°ë¡œ ë§ˆìŒë¨¹ì—ˆì—ˆë‹¤.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<h1 id="ë¬¸ì¥ë‚´-ê°œì²´ê´€-ê´€ê³„-ì¶”ì¶œ"><a href="#ë¬¸ì¥ë‚´-ê°œì²´ê´€-ê´€ê³„-ì¶”ì¶œ" class="headerlink" title="ë¬¸ì¥ë‚´ ê°œì²´ê´€ ê´€ê³„ ì¶”ì¶œ"></a>ë¬¸ì¥ë‚´ ê°œì²´ê´€ ê´€ê³„ ì¶”ì¶œ</h1><p>ë­”ê°€ ì•„ì‰¬ì› ë˜ P-stage 2 KLUEê°€ ëì´ ë‚¬ë‹¤.</p><p>ì´ë²ˆ stageì—ì„œëŠ” ë¦¬ë”ë³´ë“œ ìˆœìœ„ë¥¼ ì˜¬ë¦¬ëŠ”ë°ì—ë§Œ ì§‘ì¤‘í•˜ê¸° ë³´ë‹¤ëŠ” ë‹¤ì–‘í•œ taskë¥¼ ì¨ë³´ê³  ì›ë¦¬ë¥¼ ì´í•´í•˜ê³  ê²°ê³¼ë¥¼ í† ë¡ ê³„ì‹œíŒì— ê¼­ ì¡°ê¸ˆì´ë¼ë„ ê³µìœ í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í•˜ê¸°ë¡œ ë§ˆìŒë¨¹ì—ˆì—ˆë‹¤.</p><span id="more"></span><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ul><li><p><strong>ë¬¸ì œì •ì˜</strong> : ë¬¸ì¥ì˜ ë‹¨ì–´(Entity)ì— ëŒ€í•œ ì†ì„±ê³¼ ê´€ê³„ë¥¼ ì˜ˆì¸¡í•˜ë¼. </p></li><li><p>Input data : 9000ê°œì˜ train data, 1000ê°œì˜ test data</p><p><img src="/images/image-20210423130448198.png"></p><p>ìš°ë¦¬ê°€ ë¹¼ë‚´ì•¼ í•  column : sentence, entities, place of entities</p></li><li><p><strong>Output</strong></p><p>ì´ 42ê°œì˜ classë¥¼ ì˜ˆì¸¡ </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">&#x27;ê´€ê³„_ì—†ìŒ&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;ì¸ë¬¼:ë°°ìš°ì&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;ì¸ë¬¼:ì§ì—…/ì§í•¨&#x27;</span>: <span class="number">2</span>, <span class="string">&#x27;ë‹¨ì²´:ëª¨íšŒì‚¬&#x27;</span>: <span class="number">3</span>, <span class="string">&#x27;ì¸ë¬¼:ì†Œì†ë‹¨ì²´&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;ì¸ë¬¼:ë™ë£Œ&#x27;</span>: <span class="number">5</span>, <span class="string">&#x27;ë‹¨ì²´:ë³„ì¹­&#x27;</span>: <span class="number">6</span>, <span class="string">&#x27;ì¸ë¬¼:ì¶œì‹ ì„±ë¶„/êµ­ì &#x27;</span>: <span class="number">7</span>, <span class="string">&#x27;ì¸ë¬¼:ë¶€ëª¨ë‹˜&#x27;</span>: <span class="number">8</span>, <span class="string">&#x27;ë‹¨ì²´:ë³¸ì‚¬_êµ­ê°€&#x27;</span>: <span class="number">9</span>, <span class="string">&#x27;ë‹¨ì²´:êµ¬ì„±ì›&#x27;</span>: <span class="number">10</span>, <span class="string">&#x27;ì¸ë¬¼:ê¸°íƒ€_ì¹œì¡±&#x27;</span>: <span class="number">11</span>, <span class="string">&#x27;ë‹¨ì²´:ì°½ë¦½ì&#x27;</span>: <span class="number">12</span>, <span class="string">&#x27;ë‹¨ì²´:ì£¼ì£¼&#x27;</span>: <span class="number">13</span>, <span class="string">&#x27;ì¸ë¬¼:ì‚¬ë§_ì¼ì‹œ&#x27;</span>: <span class="number">14</span>, <span class="string">&#x27;ë‹¨ì²´:ìƒìœ„_ë‹¨ì²´&#x27;</span>: <span class="number">15</span>, <span class="string">&#x27;ë‹¨ì²´:ë³¸ì‚¬_ì£¼(ë„)&#x27;</span>: <span class="number">16</span>, <span class="string">&#x27;ë‹¨ì²´:ì œì‘&#x27;</span>: <span class="number">17</span>, <span class="string">&#x27;ì¸ë¬¼:ì‚¬ë§_ì›ì¸&#x27;</span>: <span class="number">18</span>, <span class="string">&#x27;ì¸ë¬¼:ì¶œìƒ_ë„ì‹œ&#x27;</span>: <span class="number">19</span>, <span class="string">&#x27;ë‹¨ì²´:ë³¸ì‚¬_ë„ì‹œ&#x27;</span>: <span class="number">20</span>, <span class="string">&#x27;ì¸ë¬¼:ìë…€&#x27;</span>: <span class="number">21</span>, <span class="string">&#x27;ì¸ë¬¼:ì œì‘&#x27;</span>: <span class="number">22</span>, <span class="string">&#x27;ë‹¨ì²´:í•˜ìœ„_ë‹¨ì²´&#x27;</span>: <span class="number">23</span>, <span class="string">&#x27;ì¸ë¬¼:ë³„ì¹­&#x27;</span>: <span class="number">24</span>, <span class="string">&#x27;ì¸ë¬¼:í˜•ì œ/ìë§¤/ë‚¨ë§¤&#x27;</span>: <span class="number">25</span>, <span class="string">&#x27;ì¸ë¬¼:ì¶œìƒ_êµ­ê°€&#x27;</span>: <span class="number">26</span>, <span class="string">&#x27;ì¸ë¬¼:ì¶œìƒ_ì¼ì‹œ&#x27;</span>: <span class="number">27</span>, <span class="string">&#x27;ë‹¨ì²´:êµ¬ì„±ì›_ìˆ˜&#x27;</span>: <span class="number">28</span>, <span class="string">&#x27;ë‹¨ì²´:ìíšŒì‚¬&#x27;</span>: <span class="number">29</span>, <span class="string">&#x27;ì¸ë¬¼:ê±°ì£¼_ì£¼(ë„)&#x27;</span>: <span class="number">30</span>, <span class="string">&#x27;ë‹¨ì²´:í•´ì‚°ì¼&#x27;</span>: <span class="number">31</span>, <span class="string">&#x27;ì¸ë¬¼:ê±°ì£¼_ë„ì‹œ&#x27;</span>: <span class="number">32</span>, <span class="string">&#x27;ë‹¨ì²´:ì°½ë¦½ì¼&#x27;</span>: <span class="number">33</span>, <span class="string">&#x27;ì¸ë¬¼:ì¢…êµ&#x27;</span>: <span class="number">34</span>, <span class="string">&#x27;ì¸ë¬¼:ê±°ì£¼_êµ­ê°€&#x27;</span>: <span class="number">35</span>, <span class="string">&#x27;ì¸ë¬¼:ìš©ì˜ì&#x27;</span>: <span class="number">36</span>, <span class="string">&#x27;ì¸ë¬¼:ì‚¬ë§_ë„ì‹œ&#x27;</span>: <span class="number">37</span>, <span class="string">&#x27;ë‹¨ì²´:ì •ì¹˜/ì¢…êµì„±í–¥&#x27;</span>: <span class="number">38</span>, <span class="string">&#x27;ì¸ë¬¼:í•™êµ&#x27;</span>: <span class="number">39</span>, <span class="string">&#x27;ì¸ë¬¼:ì‚¬ë§_êµ­ê°€&#x27;</span>: <span class="number">40</span>, <span class="string">&#x27;ì¸ë¬¼:ë‚˜ì´&#x27;</span>: <span class="number">41</span>&#125; </span><br></pre></td></tr></table></figure></li></ul><br/><h2 id="EDA"><a href="#EDA" class="headerlink" title="EDA"></a>EDA</h2><p>ì´ë²ˆ ìì—°ì–´ taskì˜ ê²½ìš°ì—ëŠ” ë°ì´í„°ë„ ì ê³  image taskì— ë¹„í•´ ë³µì¡í•œ edaê°€ í•„ìš”í•œê²ƒ ê°™ì§€ëŠ” ì•Šì•˜ë‹¤.</p><p>ë”°ë¼ì„œ ê°€ì¥ ì¤‘ìš”í•œ labelë“¤ì˜ ê°¯ìˆ˜ë§Œì„ í™•ì¸í•˜ê³  ë¹ ë¥´ê²Œ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°”ë‹¤. (í† ë¡ ê¸€ì—ë„ í•˜ë‚˜ ì‘ì„±í•˜ê¸´ í–ˆì§€ë§Œ, ê±°ê¸°ì„œ ì‘ì„±í–ˆë˜ labelë“¤ê°„ì˜ ìœ ì‚¬ì„±ìœ¼ë¡œ class imbalnaceë¥¼ í•´ê²°í•˜ê¸° ë³´ë‹¤ëŠ” focal lossë¥¼ ì‚¬ìš©í•˜ëŠ”ê²Œ ì§ê´€ì ìœ¼ë¡œ ë” ì‰¬ì›Œ ë³´ì—¬ì„œ focal lossë¥¼ ì‚¬ìš©í•˜ê¸°ë¡œ í•˜ì˜€ë‹¤.</p><ol><li>labelë“¤ì˜ ë¶„í¬</li></ol><p>ì£¼í”¼í„° ë…¸íŠ¸ë¶ì„ í†µí•´ ë¹ ë¥´ê²Œ dataë¥¼ ë¶ˆëŸ¬ì™€ì„œ labelë“¤ì˜ ë¶„í¬ë¥¼ í™•ì¸í•˜ì—¬ ë³´ë‹ˆ. labelë“¤ê°„ì˜ ë¶ˆê· í˜•ì´ ë§¤ìš° ë§¤ìš° ì‹¬í–ˆë‹¤. ì‹¬ì§€ì–´ ì¸ë¬¼ : ì‚¬ë§êµ­ê°€ì˜ labelì„ ê°€ì§€ëŠ” dataëŠ” 1ê°œ ë¿ ì´ì˜€ë‹¤. ì´ 1ê°œë¡œ ê³¼ì—° test dataì˜ í•´ë‹¹ labelì„ ì˜ ë§ì¶œìˆ˜ ìˆì„ê¹Œ? ì•„ë‹ê²ƒ ê°™ë‹¤.</p><p>ì´ëŸ¬í•œ imbalnaceë¬¸ì œì— íš¨ê³¼ì ìœ¼ë¡œ ëŒ€ì²˜í•˜ëŠ” ë°©ë²•ì€ ì´ì „ p-stageì—ì„œë„ ë°°ì› ì—ˆë‹¤.  ë°”ì•„ì•„ì•„ë¡œ focal loss</p><p>focal lossì— ëŒ€í•´ì„œ ê°„ëµí•˜ê²Œ ì•Œì•„ë³´ì</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FocalLoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, weight=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 gamma=<span class="number">2.</span>, reduction=<span class="string">&#x27;mean&#x27;</span></span>):</span></span><br><span class="line">        nn.Module.__init__(self)</span><br><span class="line">        self.weight = weight</span><br><span class="line">        self.gamma = gamma</span><br><span class="line">        self.reduction = reduction</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, input_tensor, target_tensor</span>):</span></span><br><span class="line">        log_prob = F.log_softmax(input_tensor, dim=-<span class="number">1</span>)</span><br><span class="line">        prob = torch.exp(log_prob)</span><br><span class="line">        <span class="keyword">return</span> F.nll_loss(</span><br><span class="line">            ((<span class="number">1</span> - prob) ** self.gamma) * log_prob,</span><br><span class="line">            target_tensor,</span><br><span class="line">            weight=self.weight,</span><br><span class="line">            reduction=self.reduction</span><br><span class="line">        )</span><br></pre></td></tr></table></figure><p>Focal lossëŠ” í˜ì´ìŠ¤ë¶ì˜ Lin et alì´ ì œì•ˆí•œ loss functionì´ë‹¤</p><p>ê°„ë‹¨í•˜ê²Œ ë§í•˜ë©´ ë¶„ë¥˜ ì—ëŸ¬ì— ê·¼ê±°í•˜ì—¬ ë§ì¶˜ í™•ë¥ ì´ ë†’ì€ ClassëŠ” ì¡°ê¸ˆì˜ lossë¥¼, ë§ì¶˜ í™•ë¥ ì´ ë‚®ì€ ClassëŠ” Lossë¥¼ í›¨ì”¬ ë†’ê²Œ ë¶€ì—¬í•´ì£¼ëŠ” ê°€ì¤‘ì¹˜ë¥¼ ì£¼ì–´ì„œ class imbalanceì— ë”ìš± íš¨ìœ¨ì ìœ¼ë¡œ ëŒ€ì²˜í•˜ëŠ” loss funtionì´ë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤.</p><p>loss í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ê²Œ ë˜ë©´ input tensorë“¤ì— ëŒ€í•œ í™•ë¥ ë¡œ í‘œí˜„ëœ tensorë¥¼ ì–»ì€ë’¤ F.nll_lossë¥¼ í˜¸ì¶œí•œë‹¤.</p><p><code>F.nll_loss(((1-prob) ** self.gamma) * log_prob,target_tensor,weight=self.weight,reduction=self.reduction)</code></p><p>Weight ê°’ì„ ìš°ë¦¬ê°€ ê°€ì§€ê³  ìˆëŠ” label ë¶„í¬ì— ëŒ€í•œ 1-d tensorë¡œ ë„£ì–´ì¤€ë‹¤.</p><p>Ex) ìš°ë¦¬ê°€ ê°€ì§€ê³  ìˆëŠ” labelë“¤ì€ 42ê°œë‹ˆê¹Œ 42 lengthë¥¼ ê°€ì§€ëŠ” 1-d tensor ê°’ì€ labelì˜ ë¶„í¬ì— ë§ê²Œ</p><p>ì´ë ‡ê²Œ loss í•¨ìˆ˜ë¥¼ ë¶ˆëŸ¬ë‹¤ê°€ ì§œì£¼ë©´ ë„ì</p><h2 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h2><p>ëª¨ë¸ì„ êµ‰ì¥íˆ ì—¬ëŸ¬ê°œ ë¶ˆëŸ¬ë‹¤ê°€ì²˜ìŒì—” ëŒë ¤ë³´ì•˜ë‹¤. ì‚¬ìš©í•´ë³¸ model ëª©ë¡</p><ol><li>bert-base-multilingual-cased</li><li>xlm-roberta-large</li><li>koelectra-base-v3-discriminator</li><li>kobert</li></ol><p>ì´ë ‡ê²Œ 4ê°œì •ë„ ì‹¤í—˜í•´ ë³´ì•˜ë˜ê²ƒ ê°™ì•˜ë‹¤. ê²°êµ­ ê²°ë¡ ë§Œ ë§í•´ë³´ìë©´ RoBERTa-largeë¥¼ ì‚¬ìš©í–ˆë‹¤.<br>hevitz ë‹˜ì˜ í† ë¡ ê³„ì‹œíŒ ê¸€ì„ ë³´ë‹ˆ, bertë„ largeë¥¼ ì‚¬ìš©í•˜ë©´ ì¢‹ê² ì§€ë§Œ?????? ì•„ì§ Huggingfaceì—  modelì´ ê³µê°œëœê²ƒ ê°™ì§€ ì•Šë‹¤.</p><p>ê·¸ë¦¬ê³  </p><blockquote><p>This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a wide range of cross-lingual transfer tasks.</p></blockquote><p>ë¼ëŠ” RoBERTaì˜ ë…¼ë¬¸ì„ ë³´ë©´ ì´ significant performance gains ë¼ëŠ” ë¬¸êµ¬ëŠ” ì´ê²Œ ë§ë‹¤ë¼ëŠ” í™•ì‹ ì„ ê°€ì ¸ë‹¤ ì£¼ì—ˆë‹¤. (ë¬¼ë¡  ë…¼ë¬¸ì—ì„œëŠ” ë‹¤ë“¤ ìê¸°ê°€ ì§±ì´ë¼ê³ í•˜ê¸´í•˜ì§€)</p><p>ë˜í•œ 4ê°œë¥¼ ê°ê° ì ë‹¹í•œ hyperparameterë¡œ ëŒë ¤ë³¸ ê²°ê³¼ í‰ê· ì ì¸ ì •í™•ë„ê°€ roberta-largeë¥¼ ì‚¬ìš©í•˜ë©´ ëŒ€í­ ì¦ê°€í•¨ì„ í™•ì¸í•˜ì˜€ë‹¤.<br>RoBERTaëŠ” bertì™€ ìœ ì‚¬í•˜ì§€ë§Œ BERTì— ë‹¤ì–‘í•œ ë°©ë²•ì„ ì ìš©ì‹œì¼œ ì„±ëŠ¥ì„ í–¥ìƒí•œ modelì´ë‹¤. Modelì˜ êµ¬ì¡°ëŠ” bertì™€ í¡ì‚¬í•˜ë‹ˆ ìƒëµí•˜ê² ë‹¤.</p><p>ë‹¨ì§€ hyperparameterë¥¼ ìµœì í™”í•˜ê³  NSPë¥¼ ì—†ì• ê³  ìµœëŒ€í•œ max_lengthì— ë§ì¶°ì„œ ë¬¸ì¥ì„ ë„£ì–´ì£¼ê³ , maskingì„ ë” ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ í•´ì£¼ì—ˆë‹¤ê³  í•œë‹¤.</p><h2 id="train-ë°©ë²•"><a href="#train-ë°©ë²•" class="headerlink" title="train ë°©ë²•?"></a>train ë°©ë²•?</h2><ol><li>loss</li><li>optimizer</li><li>Train-set, validation-set ë‚˜ëˆ„ê¸°</li></ol><p>ì´ë²ˆ KLUEì—ì„œ Huggingfaceì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì§ˆë¦¬ë„ë¡ ë‹¤ë£¬ê²ƒ ê°™ë‹¤. ë¬¼ë¡  ì•„ì§ ëª¨ìë¥´ì§€ë§Œ ã…ã…<br>ì´ì „ P-stageì—ì„œëŠ” training ê³¼ì •ì„ ìš°ë¦¬ê°€ ë‹¤ pytorch ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ train í•¨ìˆ˜ë¥¼ ë§Œë“¤ê³  ì¼ë¼ì¼ë¼ í•´ì„œ êµ¬í˜„í–ˆì—ˆëŠ”ë°!!!!</p><p>ì´ëŸ° í¸ë¦¬í•œ trainerë¼ëŠ”ê²Œ ìˆëŠ” hugging face ì•„ì£¼ ì¹­ì°¬í•´ ^^</p><p>í•˜ì§€ë§Œ ë‹¨ìˆœíˆ trainerë¥¼ ì‚¬ìš©í•˜ëŠ”ê²ƒì€ ì‹¤ë ¥ ì¦ì§„ì— ë³„ë¡œ ì˜ë¯¸ê°€ ì—†ë‹¤ê³  ìƒê°í–ˆë‹¤. (ë¬¼ë¡  ë§ˆìŠ¤í„°ë‹˜ ë§ì”€ì²˜ëŸ¼ Hugging faceë§Œ ì˜ ì‚¬ìš©í•˜ë”ë¼ë„ ê·¸ë§Œí¼ ì¥ì ì´ ìˆë‹¤ê³  í•œë‹¤!!!)</p><p>ê·¸ë˜ì„œ huggingface í™ˆí˜ì´ì§€ì— ë“¤ì–´ê°€ì„œ trainerë¥¼ ìì„¸íˆ ì‚´í´ë³´ì•˜ë‹¤.</p><p>ì²˜ìŒì— ì •í–ˆë˜ focal lossë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” trainer classë¥¼ ìƒì†ë°›ì•„ì„œ ë‚˜ë§Œì˜ trainer classë¥¼ êµ¬í˜„í•´ì£¼ì–´ì•¼ í–ˆë‹¤. í™ˆí˜ì´ì§€ë¥¼ ë³´ë©´ ê´€ë ¨ ì˜ˆì œê°€ ìˆì–´ ì‰½ê²Œ ë°”ê¿”ì¤„ìˆ˜ ìˆì—ˆë‹¤. (í˜„ê·œë‹˜ì˜ ë„ì›€ê³¼ í•¨ê»˜ë¼ë©´ ã…ã…)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FocalLossTrainer</span>(<span class="params">Trainer</span>) :</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_loss</span>(<span class="params">self, model, inputs, return_outputs=<span class="literal">False</span></span>) :</span></span><br><span class="line">        labels = inputs.pop(<span class="string">&#x27;labels&#x27;</span>)</span><br><span class="line">        outputs = model(**inputs)</span><br><span class="line">        logits = outputs.logits</span><br><span class="line">        loss_fn = FocalLoss(weight=weight)</span><br><span class="line">        loss = loss_fn(logits, labels)</span><br><span class="line">        <span class="keyword">return</span> (loss, outputs) <span class="keyword">if</span> return_outputs <span class="keyword">else</span> los</span><br></pre></td></tr></table></figure><p>ì—¬ê¸°ì„œ <code>loss_fn</code>ë§Œ ìœ„ì—ì„œ ì •ì˜í•œ FocalLoss()ë¥¼ ë¶ˆëŸ¬ë‹¤ê°€ ì‚¬ìš©í•˜ë©´ ë„ì! easy</p><p>Optimizerê´€ë ¨í•´ì„œëŠ” trainer ì•ˆì—ì„œ ì‚¬ìš©í•˜ëŠ” AdamWë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ ë ê±° ê°™ì•˜ê³  ìˆ˜ì •í•´ì£¼ì–´ì•¼ í•  ê²ƒì€</p><ul><li>lr_scheduler</li><li>lr</li></ul><p>ì´ì •ë„? ì¸ê²ƒ ê°™ë‹¤. default ë¡œ ì„¤ì •ëœ lr_schedulerì€ stepì— ë”°ë¼ linear í•˜ê²Œ lr ì´ ê°ì†Œí•˜ëŠ” schedulerë¥¼ ì“´ê±° ê°™ì€ë°<br>ì €ë²ˆì— ì‚¬ìš©í–ˆë˜ <strong>CosineAnnealingWarmRestarts</strong> ìœ¼ë¡œ ë°”ê¾¸ì–´ì„œ ì‚¬ìš©í•´ë³´ë©´ ì–´ë–¨ê¹Œ? ìƒê°ì„ í•´ë³´ì•˜ë‹¤.</p><p>ì €ë²ˆ stageì—ì„œ AdamPì™€ CosineAnnealingWarmRestartsì˜ ì¡°í•©ìœ¼ë¡œ ê½¤ë‚˜ ì ì í•œ ì¬ë¯¸ë¥¼ ë³´ì•˜ê¸° ë•Œë¬¸ì— ã…ã…</p><p>ì„¸ì„¸í•œ parameterì€ seedë¥¼ ê³ ì •ì‹œí‚¨ ì´í›„ validation scoreë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •í•´ì£¼ë©´ ë ë“¯ ì‹¶ë‹¤.<br>validation ê³¼ trainì€ 2:8 ë¡œ ë‚˜ëˆ„ì—ˆê³  ì œì¶œì „ì—ëŠ” dataëª¨ë‘ë¥¼ ì‚¬ìš©í•´ì„œ train í•œ modelë¡œ inference í•˜ì˜€ë‹¤.</p><p><strong>ì ì´ì œ ê°€ì¥í¬ê²Œ ê³ ë¯¼ì„ í•´ì¤€ ë¶€ë¶„ì´ë‹¤</strong></p><h2 id="Input-í˜•ì‹ì—-ë”°ë¥¸-ì„±ëŠ¥"><a href="#Input-í˜•ì‹ì—-ë”°ë¥¸-ì„±ëŠ¥" class="headerlink" title="Input í˜•ì‹ì— ë”°ë¥¸ ì„±ëŠ¥"></a>Input í˜•ì‹ì— ë”°ë¥¸ ì„±ëŠ¥</h2><p>ì´ë²ˆ stageì—ì„œ ì œê³µëœ baseline codeëŠ” ê½¤ë‚˜ simpleí•˜ê³  ê°„ê²°í•˜ì§€ë§Œ ìˆì„ê±°ëŠ” ë‹¤ìˆë‹¤.</p><p>ê°€ì¥ ì˜ë¬¸ì ì´ ë“¤ì—ˆë˜ ê²ƒì€ tokenizerì— ë„£ì–´ì£¼ëŠ” data ì˜ í˜•ì‹ì´ì˜€ë‹¤.</p><p>ent01 : ì´ìˆœì‹ </p><p>ent02 : ë¬´ì‹ </p><p>sentence : ì´ìˆœì‹ ì€ ì¡°ì„ ì¤‘ê¸°ì˜ ë¬´ì‹ ì´ë‹¤.</p><p># RoBERTa tokenizer ê¸°ì¤€ special token</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#39;bos_token&#39;: &#39;&lt;s&gt;&#39;,</span><br><span class="line"> &#39;eos_token&#39;: &#39;&lt;&#x2F;s&gt;&#39;,</span><br><span class="line"> &#39;unk_token&#39;: &#39;&lt;unk&gt;&#39;,</span><br><span class="line"> &#39;sep_token&#39;: &#39;&lt;&#x2F;s&gt;&#39;,</span><br><span class="line"> &#39;pad_token&#39;: &#39;&lt;pad&gt;&#39;,</span><br><span class="line"> &#39;cls_token&#39;: &#39;&lt;s&gt;&#39;,</span><br><span class="line"> &#39;mask_token&#39;: &#39;&lt;mask&gt;&#39;&#125;</span><br><span class="line"> </span><br><span class="line"> &lt;s&gt; ì´ìˆœì‹  &lt;&#x2F;s&gt; ë¬´ì‹  &lt;&#x2F;s&gt;&lt;s&gt; ë¬¸ì¥ &lt;&#x2F;s&gt;</span><br></pre></td></tr></table></figure><p> ì´ëŸ¬í•œ í˜•ì‹ìœ¼ë¡œ ë“¤ì–´ê°”ë‹¤.<br>ì˜¤í”¼ìŠ¤ì•„ì›Œì—ì„œ ì—¬ì­ˆì–´ ë³´ë‹ˆê¹Œ, ë³„ë‹¤ë¥¸ ì´ìœ  ì—†ì´ ê°„ë‹¨í•˜ê²Œ ì •í•´ì¤€ í˜•ì‹ì´ë¼ê³  í–ˆë‹¤.</p><p>ë”°ë¼ì„œ ì´ˆì½”ì†¡ì´ë‹˜ê»˜ì„œ ì˜¬ë ¤ì£¼ì‹  nerì„ entitiyì‚¬ì´ì— ë„£ì–´ì£¼ëŠ” ë…¼ë¬¸ê¸€ì„ ì½ê³  pororo libraryë¥¼ ì´ìš©í•˜ì—¬ nerì„ ì–»ì–´ë‚¸ë’¤ ì´ë¥¼ entityì–‘ì˜†ì— ì‚½ì…í•˜ì—¬ ì£¼ì—ˆë‹¤. </p><p><img src="../images/image-20210429181250424.png" alt="image-20210429181250424"></p><p>ì´ì™€ê°™ì€ í˜•ì‹ì´ë‹¤.</p><p>ì²˜ìŒì—ëŠ” ì € ê¸°í˜¸ë“¤ì„ special tokenì— ì¶”ê°€í•´ì¤€ë’¤, modelì— ë„£ì–´ì£¼ì—ˆì§€ë§Œ!!</p><p>í˜œë¦°ë‹˜ì˜ ì§ˆë¬¸ê³¼ í”¼ë“œë°±ìœ¼ë¡œ ë…¼ë¬¸ì—ì„œëŠ” special í† í°ìœ¼ë¡œ ì§€ì •í•˜ì§€ ì•Šê³ , ì›ë˜ vocabì— ìˆëŠ” ê¸°í˜¸ë“¤ì„ ì‚¬ìš©í•˜ì˜€ë‹¤ê³  í•œë‹¤â€¦â€¦<br>ì´ë¯¸ í† ë¡ ê¸€ì— ì˜¬ë ¸ëŠ”ë°â€¦â€¦â€¦ ì˜¬ë¦¬ê¸° ì˜í–ˆë‹¤ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. ì˜¬ë¦¬ì§€ ì•Šì•˜ë‹¤ë©´ ì´ ë¬¸ì œë¥¼ í‰ìƒ ëª¨ë¥´ê³  ì˜ëª»ëœ ì§€ì‹ì„ ê°€ì§„ì±„ë¡œ ì‹¤í—˜í•˜ì˜€ì„ê²ƒì´ë‹¤.</p><p>ë§ˆìŠ¤í„°ì´ë‚˜ ì¡°êµë‹˜ë“¤ ë§ì”€ëŒ€ë¡œ ì¼ë‹¨ ë‚˜ëŒ€ëŠ”ê²Œ ì¢‹ì€ê²ƒ ê°™ë‹¤. ë‚¨ë“¤ì—ê²Œ ë°°ìš¸ì ë„ ë§ê³ , ë‚˜ëŒ€ë©´ì„œ ìŠ¤ìŠ¤ë¡œ ì¢€ë” ì°¾ì•„ë³´ê³  í•™ìŠµí•˜ê²Œ ë˜ëŠ”ê²ƒ ê°™ë‹¤.</p><p>ì´ëŸ¬í•œ input í˜•ì‹ì€ ë™ì¼ seed model hyperparamterìœ¼ë¡œ ì•½ 1.5í¼ ì •ë„ leaderboard accì˜ ìƒìŠ¹ì„ ì´ëŒì–´ëƒˆë‹¤.</p><p>autotokenizerë¡œ ë¶ˆëŸ¬ì˜¨ tokenizerì€ ëŒ€ë¶€ë¶„ì˜ vocabë“¤ì„ í¬í•¨í•˜ê³  ìˆì–´, unknownìœ¼ë¡œ ë‚˜ì˜¤ëŠ” tokenë“¤ì´ ì ì€ê²ƒì„ í™•ì¸í•˜ì˜€ë‹¤.<br>íŠ¹íˆ entityê°€ unkë¡œ ë‚˜ì˜¤ê²Œë˜ë©´ í° ë¬¸ì œì„ìœ¼ë¡œ ì´ë¥¼ ì²´í¬í•˜ì˜€ëŠ”ë°, ëª¨ë‘ ì˜ tokenizeëœê²ƒì„ í™•ì¸í•˜ì˜€ë‹¤.</p><p>optimzerì€ trainerì—ì„œ ì‚¬ìš©í–ˆë˜ê±¸ë¡œ ë™ì¼í•˜ê²Œ ì‚¬ìš©í•˜ì˜€ê³ <br>lrê³¼ schedulerë¥¼ ë°”ê¾¸ì–´ ê°€ë©° RoBERTaì— ë§ëŠ” hyperparameterë¥¼ ì°¾ê¸°ìœ„í•´ ë…¸ë ¸í–ˆë‹¤.;)</p><p>ì´ë²ˆ stageì—ëŠ” ë”°ë¡œ í•˜ê³ ìˆëŠ” ROS ì‹¤ìŠµê³¼ ê²¹ì³ í•˜ê³ ì‹¶ì€ê²Œ 3ê°€ì§€ ìˆì—ˆëŠ”ë° ëª»í•´ë´¤ë‹¤ã… ã… </p><ol><li><p>wandbë¡œ ì‹¤í—˜ ê´€ë¦¬í•˜ê¸°, sweep ì‚¬ìš©í•´ì„œ automlê¹Œì§€ í•´ë³´ê¸°</p></li><li><p>inputì— ë¬´ì‘ìœ„ë¡œ masking ì ìš©í•´ë³´ê¸°</p></li><li><p>augmentationìœ¼ë¡œ data ì¦ê°•í•´ë³´ê¸°</p></li></ol><p>í•˜ì§€ë§Œ ì´ë²ˆ stageë¡œ ê´€ì‹¬ì´ ì—†ì—ˆë˜ NLPì— ëŒ€í•´ ë‹¤ì‹œí•œë²ˆ ìƒê°í•´ë³´ê²Œ ë˜ì—ˆë‹¤. ìƒê°ë³´ë‹¤ ì¬ë¯¸ìˆëŠ” ì•„ì´ë””ì–´ë“¤ì´ ë§ì•˜ê³ , íŠ¹íˆ ì˜¤í”¼ìŠ¤ì•„ì›Œë‚˜ ë§ˆìŠ¤í„° í´ë˜ìŠ¤ì—ì„œ ë©˜í† ë‹˜ê³¼ ë§ˆìŠ¤í„°ë‹˜ì˜ ì—´ì •ì„ ë³´ê³  êµ‰ì¥íˆ í° ì˜ê°ê³¼ ìê·¹ì„ ë°›ì•˜ë‹¤. ì•„ì§ í•œêµ­ì–´ ê´€ë ¨ NLP taskë“¤ì´ ë§ì´ ë¶€ì¡±í•˜ë‹¤ëŠ” ê±¸ ë“£ê³  í™•ì‹¤íˆ ê³ ë ¤í•´ë³´ê²Œ ë˜ì—ˆë‹¤. Hugging face ë¥¼ ë§ì´ ë‹¤ë£¨ì–´ ë³¸ì ë„ ë§¤ìš° ë“ì´ë˜ì—ˆë˜ stageì˜€ë‹¤.</p>]]></content:encoded>
      
      
      <category domain="https://jo-member.github.io/categories/Boostcamp/">Boostcamp</category>
      
      
      <category domain="https://jo-member.github.io/tags/nlp/">nlp</category>
      
      <category domain="https://jo-member.github.io/tags/hugging-face/">hugging_face</category>
      
      <category domain="https://jo-member.github.io/tags/ner/">ner</category>
      
      
      <comments>https://jo-member.github.io/2021/04/22/Pstage2-KLUE/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Image Classification</title>
      <link>https://jo-member.github.io/2021/03/08/2021-03-08-Boostcamp31.1/</link>
      <guid>https://jo-member.github.io/2021/03/08/2021-03-08-Boostcamp31.1/</guid>
      <pubDate>Sun, 07 Mar 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;br/&gt;



&lt;p&gt;K Nearest Neighbors (k-NN)&lt;/p&gt;
&lt;p&gt;ê¸°ì¡´ì˜ dataê°€ ê°€ì§€ê³ ìˆëŠ” labelì„ í™œìš©í•´ì„œ ìƒˆë¡œìš´ dataì˜ labelì„ ë¶„ë¥˜í•˜ëŠ” ë¬¸ì œê°€ ëœë‹¤. ì´ë ‡ê²Œ ëœë‹¤ë©´ ë¯¸ë¦¬ ìœ ì‚¬ë„ë¥¼ ì •ì˜í•´ì•¼ í•œë‹¤. ê·¸ë¦¬ê³  system ë³µì¡ë„ê°€ ë„ˆë¬´ ë†’ë‹¤. ë”°ë¼ì„œ dataë¥¼ NNì˜ parameterì— ë…¹ì—¬ë„£ëŠ” ê²ƒì´ë‹¤.&lt;/p&gt;
&lt;p&gt;Yann Lecunì˜ CNN ê°œë°œ : ìš°í¸ë²ˆí˜¸ì¸ì‹ì— í˜ì‹ ì„ ì´ë£¨ì–´ëƒ„&lt;/p&gt;
&lt;p&gt;Using better activation function   &lt;/p&gt;
&lt;p&gt;annotation dataì˜ íš¨ìœ¨ì ì¸ í•™ìŠµ ê¸°ë²• &lt;/p&gt;
&lt;p&gt;data ë¶€ì¡±ë¬¸ì œì˜ ì™„í™” : ëŒ€í‘œì ì¸ ë°©ë²•ë“¤&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Data augmentation&lt;/li&gt;
&lt;li&gt;Leveraging pre-trained information&lt;/li&gt;
&lt;li&gt;Leveraging unlabeled dataset for training&lt;/li&gt;
&lt;/ol&gt;</description>
      
      
      
      <content:encoded><![CDATA[<br/><p>K Nearest Neighbors (k-NN)</p><p>ê¸°ì¡´ì˜ dataê°€ ê°€ì§€ê³ ìˆëŠ” labelì„ í™œìš©í•´ì„œ ìƒˆë¡œìš´ dataì˜ labelì„ ë¶„ë¥˜í•˜ëŠ” ë¬¸ì œê°€ ëœë‹¤. ì´ë ‡ê²Œ ëœë‹¤ë©´ ë¯¸ë¦¬ ìœ ì‚¬ë„ë¥¼ ì •ì˜í•´ì•¼ í•œë‹¤. ê·¸ë¦¬ê³  system ë³µì¡ë„ê°€ ë„ˆë¬´ ë†’ë‹¤. ë”°ë¼ì„œ dataë¥¼ NNì˜ parameterì— ë…¹ì—¬ë„£ëŠ” ê²ƒì´ë‹¤.</p><p>Yann Lecunì˜ CNN ê°œë°œ : ìš°í¸ë²ˆí˜¸ì¸ì‹ì— í˜ì‹ ì„ ì´ë£¨ì–´ëƒ„</p><p>Using better activation function   </p><p>annotation dataì˜ íš¨ìœ¨ì ì¸ í•™ìŠµ ê¸°ë²• </p><p>data ë¶€ì¡±ë¬¸ì œì˜ ì™„í™” : ëŒ€í‘œì ì¸ ë°©ë²•ë“¤</p><ol><li>Data augmentation</li><li>Leveraging pre-trained information</li><li>Leveraging unlabeled dataset for training</li></ol><span id="more"></span><p>Data augmentation</p><p>Dataë¥¼ í†µí•œ patternì˜ ë¶„ì„</p><p>Dataset is almost biased != real data<br>ê²°êµ­ ìš°ë¦¬ê°€ ì‚¬ìš©í•˜ëŠ”  dataë“¤ì€ ì‚¬ëŒì´ biasí•´ì„œ ì°ì€ ì‚¬ì§„ë“¤ì´ ëŒ€ë¶€ë¶„ì´ê¸° ë•Œë¬¸ì— ìš°ë¦¬ê°€ ì–»ì–´ë†“ì€ training dataê¹Œì§€ ëª¨ë‘ í‘œí˜„í•˜ì§€ ëª»í•˜ëŠ” dataë“¤ì´ë‹¤.</p><p>ex) crop, rotate, Brightness, â€¦</p><p>Affine transformation</p><p>ë³€í™˜ì „í›„ì— ì„ ìœ¼ë¡œ ìœ ì§€ê°€ ë˜ê³ , ê¸¸ì´ì˜ ë¹„ìœ¨ê³¼ í‰í–‰ê´€ê³„ê°€ ìœ ì§€ê°€ ë˜ì§€ë§Œ ê°ë„ê°€ ë‹¬ë¼ì§€ëŠ”. </p><p>ê¸°ë³¸ì ì¸ í‹€ì„ ë§ì¶˜ attine transofrmation</p><p>mixing both images and labels</p><p>RandAugment</p><p>randomí•˜ê²Œ augmentation ë°©ë²•ì„ ìˆ˜í–‰í›„ ì˜ë‚˜ì˜¨ê²ƒì„ ê°€ì ¸ë‹¤ ì“°ì. ì–´ë–¤ê±¸ ì ìš©í• ê¹Œ, ì–´ë–¤ ê°•ë„ë¡œ augmentationì„ í• ê¹Œ?</p><p>ì´ê±¸ policyë¦¬ê³  í•œë‹¤. Random samplingì‹œ</p><p>datasetì„ ë§Œë“¤ì–´ì•¼ í•˜ëŠ”ë° ì´ëŸ¬í•œ dataë¥¼ ëª¨ì„ë•Œ labelì´ í•„ìš”í•˜ê¸° ë–„ë¬¸ì— ì´ëŸ¬í•œ dataë¥¼  ë‹¨ê¸°ê°„ì— ìˆ˜ì§‘í•˜ê¸°ê°€ ì‰½ì§€ê°€ ì•Šë‹¤.</p><p><strong>Transfer learning</strong></p><p>ê¸°ì¡´ì— í•™ìŠµì‹œí‚¨ modelì— ì¡°ê¸ˆ ë°”ê¿”ì„œ ì ìš©. í•œë°ì´í„°setì—ì„œ ë°°ìš´ ì§€ì‹ì„ ë‹¤ë¥¸ taskì— ì ìš©</p><p>í•œ datasetì— ì ìš©ëœ ê²½ìš°ì— ë‹¤ë¥¸ê³³ì—ë„ ì ìš©í•  ìˆ˜ ìˆì§€ ì•Šì„ê¹Œ?<br>Freeze ê¸°ì¡´ì˜ CNN layerâ€™s parameter<br>ì ì€ dataë¡œ ë¶€í„°</p><p><img src="/images/image-20210308112418434.png" alt="image-20210308112418434"></p><p>Pseudo-labelingì´ ì¢€ ì‹ ê¸°í•˜ë‹¤.</p><p>Knowledge distillation</p><p><img src="/images/image-20210308113809064.png" alt="image-20210308113809064"></p><p>ë” ê¹Šì€ network -&gt; ë” ë†’ì€ ì„±ëŠ¥</p><p>ê¹Šê²Œ ìŒ“ì„ìˆ˜ë¡ gradient explosionì´ë‚˜ vanishing gradientê°€ ë°œìƒí•˜ì˜€ë‹¤, ê³„ì‚°ë³µì¡ë„ê°€ ì˜¬ë¼ê°€ì„œ ì†ë„ì˜ ì €í•˜, overfittingë¬¸ì œê°€ ì•„ë‹ˆë¼ degradation problemì´ë¼ëŠ”ê²Œ ë°í˜€ì¡Œë‹¤.</p><p>ë„¤íŠ¸ì›Œí¬ë¥¼ ê¹Šê²Œ ìŒ“ê¸°ìœ„í•œ network</p><ol><li>GoogLeNet</li></ol><p>í•˜ë‚˜ì˜ layerì—ì„œ ë‹¤ì–‘í•œ í¬ê¸°ì˜ cnn filterë¥¼ ì‚¬ìš©í•˜ì„œ ì—¬ëŸ¬ì¸¡ë©´ìœ¼ë¡œ imageë¥¼ ê´€ì°°í•˜ê² ë‹¤. í•œì¸µì— ì´ë ‡ê²Œ ì—¬ëŸ¬ filterë¥¼ ì‚¬ìš©í•˜ê²Œ ë˜ë©´ ê³„ì‚°ë³µì¡ë„ê°€ ì˜¬ë¼ê°€ê³ , parameterìˆ«ìê°€ ëŠ˜ì–´ë‚˜ê¸° ë•Œë¬¸ì—, 1x1 filterë¥¼ ì¶”ê°€í•´ ì£¼ì—ˆë‹¤. 1x1 layer as bottle neck architecture</p><ul><li>ê³µê°„í¬ê¸°ëŠ” ë³€í•˜ì§€ ì•Šê³ , channel ìˆ˜ë§Œ ë³€í™”ì‹œì¼œì¤€ë‹¤.</li></ul><p>Overall architecture</p><ul><li>inception moduleì„ ê¹Šê²Œ ìŒ“ì•„ì„œ ì „ì²´ network í˜•ì„±</li><li>Auxiliary classifiers : gradient vanising ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì¶”ê°€í•´ì¤€ classifiers. ì¤‘ê°„ì¤‘ê°„ì— gradientë¥¼ ê¼½ìì£¼ëŠ” ì—­í• ì„ í•œë‹¤.</li><li>lossê°€ ì¤‘ê°„ì—ì„œ ë¶€í„° í˜ëŸ¬ë“¤ì–´ê°€ê¸° ë•Œë¬¸ì— ë©€ë¦¬ìˆëŠ” ë‹¨ê¹Œì§€ gradient ì „ë‹¬ì´ ê°€ëŠ¥í•˜ë‹¤.</li></ul><p>Auxiliary classifier</p><p><img src="/images/image-20210309113004104.png" alt="image-20210309113004104"></p><h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><p>ì•„ì§ë„ í° ì˜í–¥ë ¥ì„ ë°œíœ˜í•˜ê³  ìˆëŠ” networkì´ë‹¤.</p><p>ìµœì´ˆë¡œ 100ê°œ ì´ìƒì˜ layerë¥¼ ìŒ“ì•˜ë‹¤. ìµœì´ˆë¡œ ì¸ê°„ levelì˜ ì„±ëŠ¥ì„ ë›°ì–´ë„˜ì—ˆë‹¤.</p><p>ì´ëŸ¬í•œ ì„±ê³¼ë¡œ cvpr best paperë¥¼ ë°›ì•˜ë‹¤. ê¸°ì¡´ì—°êµ¬ìë“¤ì˜ layerë¥¼ ê¹Šê²Œ ìŒ“ëŠ”ë° ë¬¸ì œì </p><p><img src="/images/image-20210309113203089.png" alt="image-20210309113203089"></p><p>ì›ë˜ëŠ” model parameterê°€ ë§ìœ¼ë©´ errorê°€ ì¤„ì–´ë“¤ ê²ƒì´ë¼ê³  ìƒê°í–ˆëŠ”ë°, 56 layerì˜ errorê°€ ë” í¬ë‹¤ëŠ” ê²°ê³¼ê°€ ë‚˜ì™”ê¸° ë•Œë¬¸ì—, over fittingë•Œë¬¸ì´ ì•„ë‹ˆë¼ëŠ” ê²°ë¡ ì´ ë‚˜ì˜´.</p><p>ëŒ€ì‹ ì— ìµœì í™” ë¬¸ì œì— ëŒ€í•´ì„œ 56 layerì´ ìµœì í™” ë˜ì§€ ì•Šì€ ê²°ê³¼ì´ë‹¤.</p><p>Ã<img src="/images/image-20210309113447823.png" alt="image-20210309113447823"></p><p>ì´ë ‡ê²Œ ë§Œë“¤ì–´ ë²„ë¦¬ë©´ í•™ìŠµì˜ ë¶€ë‹´ê°ì´ ëœì–´ì§€ê³  ë¶„í• ì •ë³µì´ ê°€ëŠ¥í•œ ë¬¸ì œê°€ ë˜ì§€ ì•Šì•˜ëŠ”ê°€?</p><p>ì´ë¥¼ í•´ê²°í•´ ì£¼ê¸° ìœ„í•´ã…</p><p>shortcut connectionì„ í†µí•´ back propê³¼ì •ì—ì„œ ê¸¸ì´ í•˜ë‚˜ê°€ ë”ìƒê¸°ëŠ” ê²ƒì´ë‹¤.gradient. vanishing ë¬¸ì œê°€ í•´ê²°ì´ ë˜ì—ˆë‹¤. ì™œì„±ëŠ¥ì´ ì˜ë‚˜ì˜¬ê¹Œ?</p><p>residual connectionì„ í•˜ë‚˜ ì¶”ê°€í• ë•Œë§ˆë‹¤ 2ë°°ì”© pathê°€ ëŠ˜ì–´ë‚œë‹¤. ë‹¤ì–‘í•œ ê²½ë¡œë¥¼ í†µí•´ì„œ êµ‰ì¥íˆ ë³µì¡í•œ mappingì˜ í•™ìŠµì´ ê°€ëŠ¥í–ˆë‹¤.</p><p>initializationìœ¼ë¡œ He initializationì„ ì‚¬ìš©í–ˆë‹¤. Reason ? -&gt; initializeë¥¼ ì‘ê²Œ í•´ì£¼ì–´ì•¼ ì´í›„ì— ë”í•´ì¤„ë•Œ ê· í˜•ì´ ë§ëŠ”ë‹¤.</p><p>3x3 conv layerë¡œ ëª¨ë‘ ì´ë£¨ì–´ì ¸ ìˆë‹¤.</p><p>Only a single FC layer at final output</p><h2 id="DenseNet"><a href="#DenseNet" class="headerlink" title="DenseNet"></a>DenseNet</h2><p>channel ì¶•ìœ¼ë¡œ concatnateí•œë‹¤. í›¨ì”¬ì´ì „ì˜ layerì— ëŒ€í•œ ì •ë³´ë“¤ë„ ëª¨ë‘ ì´ì–´ì¤€ë‹¤. ìƒìœ„ layerì—ì„œë„ ëª¨ë“  í•˜ìœ„ layerì˜ íŠ¹ì§•ì„ ì°¸ì¡°í•  ìˆ˜ ìˆë„ë¡ í•´ì£¼ì—ˆë‹¤.</p><p>ë”í•˜ê¸° ë‘ ì‹ í˜¸ë¥¼ í•©ì³ë²„ë¦°ë‹¤</p><p>concatnate chanelì€ ëŠ˜ì–´ë‚˜ì§€ë§Œ featureë¥¼ ë”ìš± ì˜ ë³´ì¡´</p><p>fixëœ 3x3 ë§Œí¼ì˜ weight paramterê°€ ì´ë¯¸ ì¡´ì¬ë¥¼ í•˜ê³  2d offsetì„ ìœ„í•œ branchê°€ ë”°ë¡œ ì¡´ì¬ í•œë‹¤. ê°ê°ì˜ weightë“¤ì„ ë²Œë ¤ì¤€ë‹¤?</p><h1 id="Semantic-segmentation"><a href="#Semantic-segmentation" class="headerlink" title="Semantic segmentation"></a>Semantic segmentation</h1><p>í”½ì…€ë‹¨ìœ„ë¡œ ë¶„ë¥˜í•´ë³´ì</p><p>ì˜ìƒì†ì˜ maskë¥¼ ìƒì„±í•˜ê²Œ ë˜ëŠ”ë° ê°™ì€ classì´ì§€ë§Œ ì„œë¡œë‹¤ë¥¸ ë¬¼ì²´ë¥¼ êµ¬ë¶„í•˜ì§€ëŠ” ì•ŠëŠ”ë‹¤.</p><p>ì˜ìƒì†ì— ìë™ì°¨ê°€ ì—¬ëŸ¬ëŒ€ ìˆì–´ë„ë‹¤ ê°™ì€ class (ìƒ‰) ìœ¼ë¡œ êµ¬ë¶„í•œë‹¤.</p><p>ì˜ìƒë‚´ì˜ ì¥ë©´ contentë¥¼ ì´í•´í•˜ëŠ”ë° ì‚¬ìš©í•˜ëŠ” í•„ìˆ˜ì ì¸ ê¸°ìˆ ì´ë‹¤. objectë“¤ì´ êµ¬ë¶„ë˜ëŠ” íŠ¹ì§•ì„ ì´í•´ë¥¼ í•˜ì—¬ </p><h2 id="Fully-Convolutional-Networks"><a href="#Fully-Convolutional-Networks" class="headerlink" title="Fully Convolutional Networks"></a>Fully Convolutional Networks</h2><p>ì…ë ¥ì—ì„œ ë¶€í„° ëê¹Œì§€ NNìœ¼ë¡œ êµ¬ì„±í•œë‹¤.<br>ì…ë ¥ìœ¼ë¡œ ì„ì˜ì˜ í•´ìƒë„ ì¶œë ¥ë„ ì…ë ¥ì— ë§ì¶˜ í•´ìƒë„, ì¤‘ê°„ì˜ layerë“¤ë„ ëª¨ë‘ ë¯¸ë¶„ê°€ëŠ¥í•œ layerë“¤ì´ë‹¤.</p><p>ê°ìœ„ì¹˜ë‹¤ channelì¶•ìœ¼ë¡œ flatteningì´í›„ ê°ê°ì˜ vectorë¥¼ ìŒ“ì•„ì„œ ê° ìœ„ì¹˜ë§ˆë‹¤ vectorê°€ í•˜ë‚˜ì”© ë‚˜ì˜¤ê²Œ ëœë‹¤. </p><p>Upsampling</p><p>receptive fieldê°€ ì‘ê¸° ë•Œë¬¸ì— upsamplingì„ í†µí•´ì„œ ê°•ì œë¡œ resolutionì„ ë§ì¶”ì–´ì¤€ë‹¤.</p><p>ì¼ë‹¨ì€ ì‘ê²Œ ë§Œë“¤ì–´ì„œ receptive fieldë¥¼ ìµœëŒ€í•œ í‚¤ìš´ë‹¤ìŒì— upsamplingí•œë‹¤.</p><ol><li>Transpose Convolution</li></ol><p>ê²°ê³¼ë¥¼ ì´ë ‡ê²Œ ê·¸ëƒ¥ ë”í•´ë„ ë˜ëŠ”ê±´ê°€?<br>cnnê³¼ stride ì‚¬ì´ì¦ˆë¥¼ ì¡°ì ˆí•´ì„œ ê²¹ì¹˜ëŠ”ë¶€ë¶„ì´ ì—†ê²Œë” ì¡°ì ˆí•´ì£¼ì–´ì•¼ í•œë‹¤. (overlap problem)</p><ol start="2"><li>Upsampling Convolution</li></ol><p>í•™ìŠµê°€ëŠ¥í•œ upsamplingì„ í•™ìŠµê°€ëŠ¥í•œ í•˜ë‚˜ì˜ layerë¡œ ë§Œë“¤ì–´ì£¼ì—ˆë‹¤. </p><p>í•´ìƒë„ê°€ ë‚®ì•„ì§€ì§€ë§Œ semanticí•˜ê³  Holistic </p><p>ì¤‘ê°„ì¸µì˜ mapì„ upsamplingí•œ ì´í›„ì— </p><p>ë†’ì€ layerì— ìˆëŠ” feature mapì„ upsamplingì„ í†µí•´ í•´ìƒë„ë¥¼ ì˜¬ë¦¬ê³  ì´ì— ë§ì¶°ì„œ ì¤‘ê°„ì¸µì˜ mapë“¤ë˜í•œ upsamplingí•œë‹¤. ì´ë“¤ì„ concatnateí•˜ì—¬ì„œ ê°í”½ì…€ë§ˆë‹¤ classì˜ scoreë¥¼ ë±‰ì–´ì£¼ê²Œ ëœë‹¤. </p><p>ìµœëŒ€í•œ ë§ì€ layerë“¤ì„ í•©ì¹œê²ƒì´ í° ë„ì›€ì´ ëœë‹¤.</p><p>FCNì€ end to endë¡œ ì†ìœ¼ë¡œ ë§Œë“ ê²Œ ì•„ë‹ˆë¼ ëª¨ë‘ NNì´ë¼ ë³‘ë ¬ì²˜ë¦¬ë„ ê°€ëŠ¥í•˜ê³  ì„±ëŠ¥ë„ ì¢‹ìœ¼ë©°, low high featureëª¨ë‘ ì˜ í¬í•¨í•œë‹¤.</p><p>U-Net</p><p>built upon fully convolutional networks</p><p>with  <strong>skip connections</strong></p><p>channel sizeê°€ ì¤„ê³  í•´ìƒë„ê°€ ëŠëŠ” expanding path</p><p>fusion - concatnationì„ ì‚¬ìš©í•œë‹¤.</p><h2 id="DeepLab"><a href="#DeepLab" class="headerlink" title="DeepLab"></a>DeepLab</h2><p>pixelê³¼ pixelì‚¬ì´ì˜ ê´€ê³„ë¥¼ ì´ì–´ì¤€í›„ pixelê°„ì˜ ê±°ë¦¬ë¥¼ ëª¨ë¸ë§í•˜ì˜€ë‹¤.<br>í™•ì‚°ì˜ ë°˜ë³µìœ¼ë¡œ ë¬¼ì²´ì˜ ê²½ê³„ì— ì˜ë§ëŠ” segmetationì„</p><ul><li>Dilated convolution</li><li>parameterìˆ˜ëŠ” ëŠ˜ì–´ë‚˜ì§€ë§Œ </li></ul><p>depthwise convolution</p><p>channelë³„ë¡œ convì—°ì‚°ì„ í•´ì„œ ê°’ì„ ê°ê° ë½‘ì€í›„, ê° channelë³„ë¡œ pointwise convolutionì„ í†µí•˜ì—¬ í•˜ë‚˜ë¡œ í•©ì³ì¤€ë‹¤. </p><p><img src="/images/image-20210309140019684.png" alt="image-20210309140019684"></p><p>Instance segmentationìœ¼ë¡œ ë¹ ë¥´ê²Œ ë°œì „ì„ í•˜ê³ ìˆë‹¤.</p><p>Instance segmantation : ê°™ì€ ì‚¬ëŒì´ì—¬ë„ ê°™ì€ìƒ‰ì´ ì•„ë‹Œ ë”°ë¡œë”°ë¡œ segmentationì´ ê°€ëŠ¥í•œ ê¸°ëŠ¥</p><p>panoptic segmentation</p><p>Instance segmentationì„ í¬í•¨í•˜ëŠ” ê¸°ìˆ </p><p>ê°ì²´ë“¤ì„ êµ¬ë¶„í•˜ëŠ” ê¸°ìˆ  : object detection</p><p>scene understandingì„ ìœ„í•œ ê¸°ìˆ </p><p>bounding obì™€ classificationì„ ë™ì‹œì— ì¶”ì •í•˜ëŠ” ê¸°ìˆ ì´ë‹¤.</p><p>í•´ë‹¹í•˜ëŠ” boxì˜ ë¬¼ì²´ì˜ categoryê¹Œì§€ ì¶”ì •í•œë‹¤.<br>2ê°œì˜ ì¢Œí‘œë¡œ bounging boxë¥¼ ê²°ì •í•œë‹¤. ë‚˜ë¨¸ì§€ëŠ” classì—ëŒ€í•œ probabilityë¥¼ ê²°ì •í•´ ì¤€ë‹¤. Bounding box localization</p><p><strong>selective search</strong></p><p>oversegmentation ì´í›„ ë¹„ìŠ·í•œ ìƒ‰ê¹”ë¼ë¦¬ í•©ì³ì¤€ë‹¤.</p><h1 id="Two-stage-detector"><a href="#Two-stage-detector" class="headerlink" title="Two-stage detector"></a>Two-stage detector</h1><ol><li>R-CNN</li></ol><p>ê¸°ì¡´ì˜ image classificationì„ í™œìš©</p><p>selective serch ë¡œ region proposalì„ êµ¬í•˜ê³ <br>ì ì ˆí•œ í¬ê¸°ë¡œ warpingì„ í•´ì„œ CNN (pretrained)ì— ë„£ì–´ì¤€í›„ categoryë¥¼ êµ¬í•´ì¤€ë‹¤.<br>ë§ˆì§€ë§‰ classifierì€ SVMì„ ì¼ë‹¤.<br>ë‹¨ì  : model í•˜ë‚˜í•˜ë‚˜ë§ˆë‹¤ ëª¨ë‘ cnnì„ ëŒë ¤ì•¼í•˜ê³  selective searchë¥¼ ì‚¬ìš©í•´ì„œ í•™ìŠµì„ í†µí•œ ì„±ëŠ¥í–¥ìƒì— ì œí•œì´ìˆë‹¤.</p><ol start="2"><li>Fast R-CNN</li></ol><p>recycle a pre-computed feature for multiple object detection</p><p>ì˜ìƒì „ì²´ì— ëŒ€í•œ featureì„ ì¶”ì¶œí›„ ì´ë¥¼ ì¬í™œìš©</p><ul><li>CNNì—ì„œ Convolutional feature mapì„ ë½‘ì•„ì£¼ê³ (warping x)</li><li>ROI pooling layerë¡œ feature mapìœ¼ë¡œ ë¶€í„° ROI featureë¥¼ ë½‘ì•„ë‚¸ë‹¤</li><li>feature poolingì´í›„ classì™€ bbox regressionì„ ì‚¬ìš©í•œë‹¤. </li></ul><p><img src="/images/image-20210311105154100.png" alt="image-20210311105154100"></p><p>ì—¬ì „íˆ roië¥¼ ì°¾ê¸° ìœ„í•´ selective searchë¥¼ ì“°ê³ ìˆë‹¤</p><ol start="3"><li>Faster R-CNN</li></ol><p>ìµœì´ˆì˜ endtoend object detection</p><p>IoU = Area overlap/Area of Union, ë†’ì„ìˆ˜ë¡ ë‘ì˜ì—­ì´ ë§ì´ ê²¹ì¹œë‹¤</p><ul><li>Anchor boxes- 9ê°œì˜ actor boxë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤. ë¯¸ë¦¬ ì •í•´ë†“ì€ bboxì˜ í¬ê¸°</li></ul><p>Selective searchë¥¼ ëŒ€ì²´í•˜ëŠ” RPNì„ ì œì•ˆí•˜ì˜€ë‹¤.</p><p>ê·¸ëŸ´ë“¯í•œ bboxë§Œ ë‚¨ê¸°ê¸° ìœ„í•´ non maximum suppressionì„ ì‚¬ìš©í•˜ì˜€ë‹¤.</p><h1 id="Single-stage-detector"><a href="#Single-stage-detector" class="headerlink" title="Single stage detector"></a>Single stage detector</h1><p>ì •í™•ë„ ë³´ë‹¤ ì†ë„ë¥¼ ì„ íƒí•œ ê²ƒì´ë‹¤</p><p>imageë¥¼ girdë¡œ ë‚˜ëˆ„ì–´ì„œ 4ê°œì˜ ì¢Œí‘œì™€ confidence scoreë¥¼ ì˜ˆì¸¡í•œë‹¤.</p><p>ê°ê°ì˜ taskë³´ë‹¤ Instance segmentationê³¼ Panoptic segmentation</p><h1 id="Instance-Segmentation"><a href="#Instance-Segmentation" class="headerlink" title="Instance Segmentation"></a>Instance Segmentation</h1><p>Instance segmentation = Sementic segmentation + distuguishing instances</p><h2 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h2><ol><li><p>RPN</p><p>ê¸°ì¡´ì˜ ROI í’€ë§ì€ ì •ìˆ˜ì¢Œí‘œë§Œ ì§€ì›ì„ í–ˆì—ˆëŠ”ë°, interpolationì„ ìœ„í•´ì„œ ì†Œìˆ˜ì  pixel levelì„ ì§€ì›í•˜ì˜€ë‹¤. </p></li></ol><h1 id="Panoptic-Segmentation"><a href="#Panoptic-Segmentation" class="headerlink" title="Panoptic Segmentation"></a>Panoptic Segmentation</h1><h2 id="UPSNet"><a href="#UPSNet" class="headerlink" title="UPSNet"></a>UPSNet</h2><p>FPNêµ¬ì¡°ë¡œ ê³ í•´ìƒë„ featureë¥¼ ë½‘ì€ ì´í›„ Semantic Head ì™€ Instance Headë¡œ ë‚˜ëˆ„ì–´ predictë¥¼ í•˜ê²Œ ëœë‹¤.</p><h1 id="Landmark-localization"><a href="#Landmark-localization" class="headerlink" title="Landmark localization"></a>Landmark localization</h1><p>Facial landmark localizaiton</p><p>Human pose estimation</p><p>ë‹¤ì–‘í•œ dataë¥¼ ì‚¬ìš©í•œ í•™ìŠµ</p><h1 id="Multi-model-learning"><a href="#Multi-model-learning" class="headerlink" title="Multi-model learning"></a>Multi-model learning</h1><p>Challenges</p><ol><li>ê°ê°ì˜ ê°ê°ì˜ ë°ì´í„°ê°€ ëª¨ë‘ ë‹¤ë¥¸ representationì„ ëˆë‹¤</li><li>Feature spaceì— ëŒ€í•˜ì—¬ balanceê°€ ë§ì§€ ì•ŠëŠ”ë‹¤.</li><li>ì—¬ëŸ¬ modelityë¥¼ ì‚¬ìš©í•  ê²½ìš° íŠ¹ì • modelì— biasë ìˆ˜ ìˆë‹¤.</li></ol><p>ëŒ€í‘œì ì¸ êµ¬ì¡°</p><ol><li>Matching</li><li>Translating</li><li>Referencing</li></ol><h2 id="Visual-data-amp-Text"><a href="#Visual-data-amp-Text" class="headerlink" title="Visual data &amp; Text"></a>Visual data &amp; Text</h2><p>Joint embedding</p><ol><li>Image tagging</li></ol><p>íƒœê·¸ -&gt; ì´ë¯¸ì§€, ì´ë¯¸ì§€ -&gt; íƒœê·¸</p><p>ê° featureë“¤ì€ ì°¨ì›ì„ ë§ì¶°ì£¼ê³  ì´ë‘˜ì˜ Joint embeddingì„ ë§Œë“¤ì–´ì¤€ë‹¤.</p><p>ê°™ì€ spaceì— ì´ë¯¸ì§€ì™€ textë¥¼ embeddingí•´ì£¼ê³  matchingë˜ëŠ” imageì™€ text ë¼ë¦¬ ê±°ë¦¬ê°€ ê°€ê¹Œì›Œ ì§€ê²Œë” í•™ìŠµì„ ì§„í–‰í•œë‹¤.</p><p>Metric Learning</p><p><img src="/images/image-20210312111734568.png" alt="image-20210312111734568"></p><p><img src="/images/image-20210312144707419.png" alt="image-20210312144707419"></p><p>ì°½ - í”„ë¡œì„¸ìŠ¤ (í˜„ì¬ ì§„í–‰ì¤‘)<br>íƒ­ - ì“°ë ˆë“œ (ê·¸ëƒ¥ ë„ì›Œì§„ ì°½) </p><ol><li>ì“°ë ˆë“œë§ˆë‹¤ ê°–ëŠ” ë©”ëª¨ë¦¬ ê³µê°„ / í”„ë¡œì„¸ìŠ¤ê°€ ê³µìœ í•˜ëŠ” ë©”ëª¨ë¦¬ ê³µê°„ì´ ìˆë‹¤.</li><li>í”„ë¡œì„¸ìŠ¤ê°€ ëŠ˜ì–´ë‚˜ë©´ ì“°ë ˆë“œ ê³µìœ  ê³µê°„ì´ ëŠ˜ì–´ë‚˜ê²Œ ëœë‹¤.</li></ol><p>process: ì½”ì–´ìˆ˜ì— ë”°ë¼ ë³‘ë ¬ì²˜ë¦¬ ê°€ëŠ¥<br>thread: í”„ë¡œì„¸ìŠ¤ ìœ„ì— ì˜¬ë¼ê°€ìˆëŠ” task<br><del>ë³´í†µ 1ê°œì˜ processë¡œ concurrentë¡œ ì²˜ë¦¬í•˜ëŠ” ê²ƒ ë³´ë‹¤, max coreì˜ 50</del>70%ì •ë„ë¡œ processë¥¼ ë‚˜ëˆ ì„œ ì²˜ë¦¬í•´ì£¼ëŠ” ê²Œ í›¨ì”¬ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¸ë‹¤.</p><p>â€”- ps. íŒŒì´ì¬ì€ ë©€í‹°í”„ë¡œì„¸ì‹± &gt;&gt; ë©€í‹°ì“°ë ˆë”©<br>search keyword: multi threading/processing, python global interpreter lock(GIL)</p><p>mini task) [ë©€í‹° í”„ë¡œì„¸ì‹±/ì“°ë ˆë”©] ìœ¼ë¡œ 10ë§Œê¹Œì§€ì˜ ì†Œìˆ˜ ì°¾ê³  ì„±ëŠ¥ ë¹„êµ í›„ githubì— ì˜¬ë¦¬ê¸° (~3.15 ì›”)</p><p>â€”- <em>point</em> â€”-<br> í”¼ì–´ì„¸ì…˜ ë¿ë§Œ ì•„ë‹ˆë¼, ì•ìœ¼ë¡œ ê³µë¶€ë°©í–¥ì— ìˆì–´ ìˆ˜ì—… ë‚´ìš© ì™¸ì ìœ¼ë¡œ ì „ì²´ì ì¸ ê·¸ë¦¼ì„ ê·¸ë¦¬ë©° ê³µë¶€ë¥¼ ì´ì–´ë‚˜ê°ˆ ê²ƒ! (cs, ml pipeline ë“±â€¦)</p><p> Q) ml ì—”ì§€ë‹ˆì–´ë¼ë©´, ê²€ìƒ‰ì„ í–ˆì„ ë•Œ ê°€ì¥ ì¢‹ì€ ê²°ê³¼ë¥¼ ë‚´ê¸° ìœ„í•´ì„œëŠ” ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œìš”?<br> A) ì–´ë–¤ ê²ƒì´ë‘ ì–´ë–¤ ê²ƒì„ ì—°ê²°ì‹œí‚¬ ê±´ì§€â€¦ë“±ë“± ì˜ ìƒê°í•´ë³´ì! ^_^</p>]]></content:encoded>
      
      
      <category domain="https://jo-member.github.io/categories/Boostcamp/">Boostcamp</category>
      
      
      <category domain="https://jo-member.github.io/tags/CNN/">CNN</category>
      
      <category domain="https://jo-member.github.io/tags/Vision/">Vision</category>
      
      
      <comments>https://jo-member.github.io/2021/03/08/2021-03-08-Boostcamp31.1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Graph2</title>
      <link>https://jo-member.github.io/2021/02/23/2021-02-23-Boostcamp22/</link>
      <guid>https://jo-member.github.io/2021/02/23/2021-02-23-Boostcamp22/</guid>
      <pubDate>Mon, 22 Feb 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;ê²€ìƒ‰ì—”ì§„ì—ì„œì˜-ê·¸ë˜í”„&quot;&gt;&lt;a href=&quot;#ê²€ìƒ‰ì—”ì§„ì—ì„œì˜-ê·¸ë˜í”„&quot; class=&quot;headerlink&quot; title=&quot;ê²€ìƒ‰ì—”ì§„ì—ì„œì˜ ê·¸ë˜í”„&quot;&gt;&lt;/a&gt;ê²€ìƒ‰ì—”ì§„ì—ì„œì˜ ê·¸ë˜í”„&lt;/h1&gt;&lt;br/&gt;

&lt;h1 id=&quot;í˜ì´ì§€ë­í¬ì˜-ë°°ê²½&quot;&gt;&lt;a href=&quot;#í˜ì´ì§€ë­í¬ì˜-ë°°ê²½&quot; class=&quot;headerlink&quot; title=&quot;í˜ì´ì§€ë­í¬ì˜ ë°°ê²½&quot;&gt;&lt;/a&gt;í˜ì´ì§€ë­í¬ì˜ ë°°ê²½&lt;/h1&gt;&lt;h3 id=&quot;1-1-ì›¹ê³¼-ê·¸ë˜í”„&quot;&gt;&lt;a href=&quot;#1-1-ì›¹ê³¼-ê·¸ë˜í”„&quot; class=&quot;headerlink&quot; title=&quot;1.1 ì›¹ê³¼ ê·¸ë˜í”„&quot;&gt;&lt;/a&gt;1.1 ì›¹ê³¼ ê·¸ë˜í”„&lt;/h3&gt;&lt;p&gt;ì›¹(ë°©í–¥ì„±ì´ ìˆëŠ” ê·¸ë˜í”„) = ì›¹í˜ì´ì§€(node) + í•˜ì´í¼ë§í¬(edge)&lt;/p&gt;
&lt;p&gt;ì›¹í˜ì´ì§€ëŠ” ì¶”ê°€ì ìœ¼ë¡œ í‚¤ì›Œë“œ ì •ë³´ë¥¼ í¬í•¨í•˜ê³ ìˆë‹¤.&lt;/p&gt;
&lt;h3 id=&quot;2-2-êµ¬ê¸€ì´ì „ì˜-ê²€ìƒ‰ì—”ì§„&quot;&gt;&lt;a href=&quot;#2-2-êµ¬ê¸€ì´ì „ì˜-ê²€ìƒ‰ì—”ì§„&quot; class=&quot;headerlink&quot; title=&quot;2.2 êµ¬ê¸€ì´ì „ì˜ ê²€ìƒ‰ì—”ì§„&quot;&gt;&lt;/a&gt;2.2 êµ¬ê¸€ì´ì „ì˜ ê²€ìƒ‰ì—”ì§„&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;ì›¹ì„ ê±°ëŒ€í•œ ë””ë ‰í† ë¦¬ë¡œ ì •ë¦¬&lt;/p&gt;
&lt;p&gt;ì›¹í˜ì´ì§€ì˜ ìˆ˜ê°€ ì¦ê°€í•¨ì— ë”°ë¼ ì¹´í…Œê³ ë¦¬ ìˆ˜ë„ ë¬´í•œì • ì»¤ì§€ëŠ” ë¬¸ì œê°€ ìˆë‹¤&lt;/p&gt;
&lt;p&gt;ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ê°€ ëª¨í˜¸í• ìˆ˜ê°€ ìˆë‹¤.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;í‚¤ì›Œë“œì— ì˜ì¡´í•œ ê²€ìƒ‰ì—”ì§„&lt;/p&gt;
&lt;p&gt;ì•…ì˜ì ì¸ ì›¹í”¼ì´ì§€ì— ì·¨ì•½í•˜ë‹¤&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;</description>
      
      
      
      <content:encoded><![CDATA[<h1 id="ê²€ìƒ‰ì—”ì§„ì—ì„œì˜-ê·¸ë˜í”„"><a href="#ê²€ìƒ‰ì—”ì§„ì—ì„œì˜-ê·¸ë˜í”„" class="headerlink" title="ê²€ìƒ‰ì—”ì§„ì—ì„œì˜ ê·¸ë˜í”„"></a>ê²€ìƒ‰ì—”ì§„ì—ì„œì˜ ê·¸ë˜í”„</h1><br/><h1 id="í˜ì´ì§€ë­í¬ì˜-ë°°ê²½"><a href="#í˜ì´ì§€ë­í¬ì˜-ë°°ê²½" class="headerlink" title="í˜ì´ì§€ë­í¬ì˜ ë°°ê²½"></a>í˜ì´ì§€ë­í¬ì˜ ë°°ê²½</h1><h3 id="1-1-ì›¹ê³¼-ê·¸ë˜í”„"><a href="#1-1-ì›¹ê³¼-ê·¸ë˜í”„" class="headerlink" title="1.1 ì›¹ê³¼ ê·¸ë˜í”„"></a>1.1 ì›¹ê³¼ ê·¸ë˜í”„</h3><p>ì›¹(ë°©í–¥ì„±ì´ ìˆëŠ” ê·¸ë˜í”„) = ì›¹í˜ì´ì§€(node) + í•˜ì´í¼ë§í¬(edge)</p><p>ì›¹í˜ì´ì§€ëŠ” ì¶”ê°€ì ìœ¼ë¡œ í‚¤ì›Œë“œ ì •ë³´ë¥¼ í¬í•¨í•˜ê³ ìˆë‹¤.</p><h3 id="2-2-êµ¬ê¸€ì´ì „ì˜-ê²€ìƒ‰ì—”ì§„"><a href="#2-2-êµ¬ê¸€ì´ì „ì˜-ê²€ìƒ‰ì—”ì§„" class="headerlink" title="2.2 êµ¬ê¸€ì´ì „ì˜ ê²€ìƒ‰ì—”ì§„"></a>2.2 êµ¬ê¸€ì´ì „ì˜ ê²€ìƒ‰ì—”ì§„</h3><ol><li><p>ì›¹ì„ ê±°ëŒ€í•œ ë””ë ‰í† ë¦¬ë¡œ ì •ë¦¬</p><p>ì›¹í˜ì´ì§€ì˜ ìˆ˜ê°€ ì¦ê°€í•¨ì— ë”°ë¼ ì¹´í…Œê³ ë¦¬ ìˆ˜ë„ ë¬´í•œì • ì»¤ì§€ëŠ” ë¬¸ì œê°€ ìˆë‹¤</p><p>ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ê°€ ëª¨í˜¸í• ìˆ˜ê°€ ìˆë‹¤.</p></li><li><p>í‚¤ì›Œë“œì— ì˜ì¡´í•œ ê²€ìƒ‰ì—”ì§„</p><p>ì•…ì˜ì ì¸ ì›¹í”¼ì´ì§€ì— ì·¨ì•½í•˜ë‹¤</p></li></ol><span id="more"></span><p>ë”°ë¼ì„œ page rankë¼ëŠ” í•˜ë‚˜ì˜ ì•Œê³ ë¦¬ì¦˜ì„ êµ¬ê¸€ì´ ë§Œë“¤ì—ˆë‹¤</p><p>í˜ì´ì§€ë­í¬ì˜ í•µì‹¬ì€ íˆ¬í‘œì´ë‹¤.</p><p>ì›¹í˜ì´ì§€ëŠ” í•˜ì´í¼ ë§í¬ë¥¼ í†µí•´ íˆ¬í‘œë¥¼í•˜ê²Œ ëœë‹¤.</p><p>ì‚¬ìš©ìê°€ ì…ë ¥í•œ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ì›¹í˜ì´ì§€ì—ì„œ uê°€ vì— ì—°ê²°ë˜ì–´ìˆë‹¤ë©´ vëŠ” ì‹ ë¢°ê°€ëŠ¥</p><p>ë§ì´ ì¸ìš©ëœ ë…¼ë¬¸ì„ ì‹ ë¢°í•˜ëŠ”ê²ƒê³¼ ë¹„ìŠ·í•œ ì•Œê³ ë¦¬ì¦˜</p><p>ì›¹í˜ì´ì§€ë¥¼ ì—¬ëŸ¬ê°œ ë§Œë“¤ì–´ì„œ ê°„ì„œì˜ ìˆ˜ë¥¼ ë¶€í’€ë¦´ìˆ˜ ìˆë‹¤.</p><p>ì´ëŸ°ì‹ì˜ ì•…ìš©ì€ ì˜¨ë¼ì¸ snsì—ì„œë„ í”íˆ ë°œê²¬ì´ ëœë‹¤.</p><p>ì´ëŸ¬í•œ ì•…ìš©ì„ ë§‰ê¸°ìœ„í•´ ê°€ì¤‘íˆ¬í‘œë¥¼ ì‚¬ìš©í•œë‹¤.</p><p>ì¸¡ì •í•˜ë ¤ëŠ” ì›¹í˜ì´ì§€ì˜ ê´€ë ¨ì„±ê³¼ ì‹ ë¢°ë„ </p><p>ìì‹œì˜ ì ìˆ˜ / ë‚˜ê°€ëŠ” ì´ì›ƒì˜ ìˆ˜ </p><p><img src="/Users/jowon/workspace/jo-member.github.io/_posts/images/image-20210223103102754.png" alt="image-20210223103102754"></p><p>ë˜í•œ í˜ì´ì§€ ë­í¬ëŠ” ì„ì˜ë³´í–‰ì˜ ê´€ì ì—ì„œë„ ì •ì˜ í•  ìˆ˜ìˆë‹¤.</p><p>ì›¹ì„œí¼ëŠ” í˜„ì¬ í•˜ì´í¼ë§í¬ì¤‘ í•˜ë‚˜ë¥¼ ê· ì¼í•œ í™•ë¥ ë¡œ í´ë¦­í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì›¹ì„ ì„œí•‘í•œë‹¤.</p><p><img src="/images/image-20210223103757983.png" alt="image-20210223103757983"></p><p>ì´ ê³¼ì •ì„ ë¬´í•œíˆ ìˆ˜í–‰í•˜ë©´ p(t) = p(t+1)ì´ëœë‹¤. ìˆ˜ë ´í•œ pëŠ” ì •ìƒë¶„í¬ë¼ê³  ë¶€ë¥¸ë‹¤. ê²°êµ­ ì´ë¥¼ ì •ë¦¬í•´ë³´ë©´ íˆ¬í‘œê´€ì ì—ì„œì˜ pagerankì •ì˜ ìˆ˜ì‹ê³¼ ë¹„ìŠ·í•¨ì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë”.</p><h2 id="í˜ì´ì§€ë­í¬ì˜-ê³„ì‚°"><a href="#í˜ì´ì§€ë­í¬ì˜-ê³„ì‚°" class="headerlink" title="í˜ì´ì§€ë­í¬ì˜ ê³„ì‚°"></a>í˜ì´ì§€ë­í¬ì˜ ê³„ì‚°</h2><ol><li><p>ë°˜ë³µê³±</p><p>Power iterationì€ ê°ì›¹í˜ì´ì§€ì— í˜ì´ì§€ ë­í¬ë¥¼ êµ¬í• ë•Œ ì‚¬ìš©ëœë‹¤</p><p>ê°ì›¹í˜ì´ì§€ iì˜ í˜ì´ì§€ ë í¬ ì ìˆ˜ë¥¼ ë™ì¼í•˜ê²Œ (1/ì›¹í˜ì´ì§€ìˆ˜) ë¡œ ì´ˆê¸°í™” í•œë‹¤</p><p>ì•„ë˜ì˜ ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì›¹í˜ì´ì§€ì˜ ì ìˆ˜ë¥¼ ê°±ì‹ í•œë‹¤</p><p><img src="/images/image-20210223105936645.png" alt="image-20210223105936645"></p><p>í˜ì´ì§€ ë­í¬ ì ìˆ˜ê°€ ìˆ˜ë ´í• ë•Œê¹Œì§€ ê³„ì‚°ì„ ë°˜ë³µí•œë‹¤.</p><p><img src="/images/image-20210223110133426.png" alt="image-20210223110133426"></p></li><li><p>ê³¼ì—° ë°˜ë³µê³±ì´ í• ìƒ ìˆ˜ë ´ì„ í• ê¹Œìš”?</p><p>ìˆ˜ë ´í•˜ì§€ ì•Šì„ìˆ˜ê°€ ìˆë‹¤. -&gt; ë“¤ì–´ì˜¤ëŠ” ì •ì ì€ ìˆì§€ë§Œ ë‚˜ê°€ëŠ” ê°„ì„ ì´ ì—†ëŠ” spider trapì— ì˜í•´ ì¼ì–´ë‚¨</p></li><li><p>ê³¼ì—° ìˆ˜ë ´ì„ í•œë‹¤ê³  í•´ë„ ì´ ê²°ê³¼ê°€ í•©ë¦¬ì ì¸ ê°’ì¼ê¹Œìš”?</p><p><img src="/images/image-20210223110453360.png" alt="image-20210223110453360"></p></li></ol><p>ì´ ë¬¸ì œì ë“¤ì— ëŒ€í•œ í•´ê²°ì±… : ìˆœê°„ì´ë™</p><p>ì„ì˜ ë³´í–‰ê´€ì ì—ì„œ</p><p>(1) í˜„ì¬ ì›¹í˜ì´ì§€ì— í•˜ì´í¼ë§í¬ê°€ ì—†ë‹¤ë©´ ì„ì˜ì˜ ì›¹í˜ì´ì§€ë¡œ ìˆœê°„ì´ë™ì„ í•œë‹¤</p><p>(2) í˜„ì¬ ì›¹í˜ì´ì§€ì— í•˜ì´í¼ë§í¬ê°€ ìˆë‹¤ë©´</p><p>$\alpha$ì˜ í™•ë¥ ë¡œ íŒŒì´í¼ ë§í¬ì¤‘ í•˜ë‚˜ë¥¼ ê· ì¼í•œ í™•ë¥ ë¡œ ì„ íƒí•˜ê³  í´ë¦­í•œë‹¤</p><p>(1-$\alpha$)ì˜ í™•ë¥ ë¡œ ì„ì˜ì˜ ì›¹í˜ì´ì§€ë¡œ ìˆœê°„ì´ë™ í•œë‹¤</p><p>ì´ë¡œ ì¸í•´ spider trapì´ë‚˜ dead endì— ê°‡íˆëŠ” ì¼ì´ ì‚¬ë¼ì¡Œë‹¤. </p><p>ìˆœê°„ì´ë™ì˜ ë„ì…ì€ ìˆ˜ì‹ì´ ë°”ë€ë‹¤</p><ol><li><p>ê° ë§‰ë‹¤ë¥¸ ì •ì ì—ì„œ ë‹¤ë¥¸ëª¨ë“  ì •ì ìœ¼ë¡œ ê°€ëŠ” ê°„ì„ ì„ ì¶”ê°€í•œ í›„</p><p><img src="/images/image-20210223110837800.png" alt="image-20210223110837800"></p><p>ì´ì œëŠ” ì´ ìˆ˜ì‹ì„ ì‚¬ìš©í•œë‹¤.</p></li></ol><h1 id="ê·¸ë˜í”„ë¥¼-ì´ìš©í•œ-ë°”ì´ëŸ´-ë§ˆì¼€íŒ…"><a href="#ê·¸ë˜í”„ë¥¼-ì´ìš©í•œ-ë°”ì´ëŸ´-ë§ˆì¼€íŒ…" class="headerlink" title="ê·¸ë˜í”„ë¥¼ ì´ìš©í•œ ë°”ì´ëŸ´ ë§ˆì¼€íŒ…"></a>ê·¸ë˜í”„ë¥¼ ì´ìš©í•œ ë°”ì´ëŸ´ ë§ˆì¼€íŒ…</h1><h2 id="ì˜ì‚¬ê²°ì •-ê¸°ë°˜ì˜-ì „íŒŒ"><a href="#ì˜ì‚¬ê²°ì •-ê¸°ë°˜ì˜-ì „íŒŒ" class="headerlink" title="ì˜ì‚¬ê²°ì • ê¸°ë°˜ì˜ ì „íŒŒ"></a>ì˜ì‚¬ê²°ì • ê¸°ë°˜ì˜ ì „íŒŒ</h2><p>ì£¼ë³€ì˜ ì˜ì‚¬ê²°ì •ì„ ê³ ë ¤í•˜ì—¬ ì˜ì‚¬ê²°ì •ì„ í• ë•Œ ì˜ì‚¬ê²°ì • ê¸°ë°˜ì˜ ì „íŒŒëª¨í˜•ì„ ì‚¬ìš©í•œë‹¤</p><p>â€”&gt; ì„ í˜•ì„ê³„ì¹˜ëª¨í˜• (linear threshold model)</p><p><img src="/images/image-20210223120102155.png" alt="image-20210223120102155"></p><h2 id="í™•ë¥ ì -ì „íŒŒ"><a href="#í™•ë¥ ì -ì „íŒŒ" class="headerlink" title="í™•ë¥ ì  ì „íŒŒ"></a>í™•ë¥ ì  ì „íŒŒ</h2><p>ì½”ë¡œë‚˜ì˜ ì „íŒŒë¥¼ ìˆ˜í•™ì ìœ¼ë¡œ ë‚˜íƒ€ë‚¼ë•ŒëŠ” í™•ë¥ ì  ëª¨í˜•ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤.</p><p>Independent Cascade model</p><p>ë°”ë¦¬ëŸ´ ë§ˆì¼€íŒ…ì´ë€?</p><p>ì†Œë¹„ìë¡œ í•˜ì—¬ê¸ˆ ìƒí’ˆì—ëŒ€í•œ ê¸ì •ì ì¸ ì…ì†Œë¬¸ì„ ë‚´ê²Œ í•˜ëŠ” ê¸°ë²•</p><p>ë°”ì´ëŸ´ ë§ˆì¼€íŒ…ì„ ìœ„í•´ì„œëŠ” ì†Œë¬¸ì˜ ì‹œì‘ì ì´ ì¤‘ìš”í•˜ë‹¤.</p><p>ì‹œë“œ ì§‘í•©ì´ ì „íŒŒì— ë§ì€ ì˜í–¥ì„ ë¯¸ì¹œë‹¤</p><p>ê·¸ë˜í”„. ì „íŒŒëª¨í˜•, ì‹œë“œì§‘í•©ì˜ í¬ê¸°ê°€ ì£¼ì–´ì¡‹ì„ë•Œ ì „íŒŒì˜ ìµœëŒ€í™”ë¥¼ ìœ„í•œ ì‹œë“œì§‘í•©ì€ ì „íŒŒìµœëŒ€í™” ë¬¸ì œì´ë‹¤.</p><p>ì–´ë ¤ìš´ ë¬¸ì œì´ë‹¤. ê·¸ë˜í”„ì— Vê°œì˜ ì •ì ì´ ìˆëŠ”ê²½ìš° ì‹œë“œì§‘í•©ì´ kê°œì¼ë•Œ ê²½ìš°ì˜ ìˆ˜ëŠ” vCk ì´ë‹¤</p><p>ì´ë¡ ì ìœ¼ë¡œ ì „íŒŒìµœëŒ€í™” ë¬¸ì œëŠ” í’€ê¸°ê°€ í˜ë“  ë¬¸ì œì„ì´ ì¦ëª…ì´ë˜ì–´ìˆë‹¤.</p><ol><li><p>ëŒ€í‘œì  íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ì •ì ì˜ ì¤‘ì‹¬ì„± ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.</p><p>ì¦‰ì‹œë“œ í¬ê¸°ê°€ kê°œë¡œ ê³ ì •ì´ë˜ì–´ìˆì„ë•Œ ì •ì ì˜ ì¤‘ì‹¬ì„±ì´ ë†’ì€ìˆ˜ìœ¼ë¡œ kê°œ ì •ì ì„ ì„ íƒí•˜ëŠ” ë°©ë²•ì´ë‹¤.</p><p>ì •ì ì˜ ì¤‘ì‹¬ì„±ìœ¼ë¡œëŠ” í˜ì´ì§€ ë­í¬ ì ìˆ˜, ì—°ê²° ì¤‘ì‹¬ì„±, ê·¼ì ‘ ì¤‘ì‹¬ì„±, ë§¤ê°œ ì¤‘ì‹¬ì„±ë“±ì´ìˆë‹¤. </p></li><li><p>íƒìš• ì•Œê³ ë¦¬ì¦˜</p><p>ì‹œë“œ ì§‘í•©ì˜ ì›ì†Œë¥¼ í•œë²ˆì— í•œëª…ì”© ì„ íƒì„ í•œë‹¤.</p><p>ì •ì ì˜ ì§‘í•© : {1,2,â€¦.,V}</p><p>ê° ì§‘í•©ì— ëŒ€í•´ ì‹œë®¬ë ˆì´ì…˜ì„ ë°˜ë³µí•˜ì—¬ í‰ê· ê°’ì„ ì‚¬ìš©í•œë‹¤. xë¼ëŠ”ì •ì ì´ ìµœì´ˆì˜ì „íŒŒìë¡œ ì„ ì •ì´ ë˜ì–´ìˆë‹¤. ì´ëŸ° ë¹„êµë¥¼ í†µí•´ ë½‘íŒ ì§‘í•©ì€ xë¼ê³  í•˜ì. ì´ì œ xë¥¼ í¬í•¨í•œ í¬ê¸°ê°€ 2ì´ ì‹œë“œ ì§‘í•©ì„ ì°¾ëŠ”ë‹¤.ì´ë¥¼ ëª©í‘œì˜ í¬ê¸°ê¹Œì§€ ë°˜ë³µí•œë‹¤.</p><p>ìµœì´ˆì „íŒŒìê°„ì˜ ì¡°í•©ì„ ê³ ë ¤í•˜ì§€ ì•ŠëŠ”ë‹¤.   </p><p>íƒìš• ì•Œê³ ë¦¬ì¦˜ì€ í•­ìƒ ìµœê³ ì˜ ì‹œë“œ ì§‘í•©ì„ ì°¾ëŠ”ë‹¤ëŠ” ë³´ì¥ì´ ì—†ëŠ” ê·¼ì‚¬ì˜ ì•Œê³ ë¦¬ì¦˜ì´ë‹¤</p><p>í•­ìƒ ìµœì ì˜ ê°’ì´ ì•„ë‹ˆë¼ëŠ” ë§ì´ë‹¤.</p><p>í•˜ì§€ë§Œ ì ì–´ë„ ì–´ëŠì •ë„ì˜ ì‹œë“œì§‘í•©ì€ ì°¾ì„ ìˆ˜ ìˆë‹¤.</p></li></ol>]]></content:encoded>
      
      
      <category domain="https://jo-member.github.io/categories/Boostcamp/">Boostcamp</category>
      
      
      <category domain="https://jo-member.github.io/tags/Graph/">Graph</category>
      
      
      <comments>https://jo-member.github.io/2021/02/23/2021-02-23-Boostcamp22/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Graph</title>
      <link>https://jo-member.github.io/2021/02/22/2021-02-22-Boostcamp21.1/</link>
      <guid>https://jo-member.github.io/2021/02/22/2021-02-22-Boostcamp21.1/</guid>
      <pubDate>Sun, 21 Feb 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;ê·¸ë˜í”„ë€ ì •ì ê³¼ ê°„ì„ ìœ¼ë¡œ ì´ë£¨ì–´ì§„ êµ¬ì¡°&lt;/p&gt;
&lt;p&gt;í•˜ë‚˜ì˜ ê°„ì„ ì€ ë°˜ë“œì‹œ ë‘ê°œì˜ ì •ì ì„ ì—°ê²°í•œë‹¤&lt;/p&gt;
&lt;p&gt;ì •ì  : vertex,node&lt;/p&gt;
&lt;p&gt;ê°„ì„  : Edge,link&lt;/p&gt;
&lt;p&gt;ìš°ë¦¬ì˜ ì‚¬íšŒë° ëª¨ë“  ë‹¤ì–‘í•œ ê²ƒë“¤ì€ êµ¬ì„±ìš”ì†Œê°„ì˜ ë³µì¡í•œ ì‚´í˜¸ì‘ìš©ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ë³µì¡ê³„ì´ë‹¤&lt;/p&gt;
&lt;p&gt;ì´ê²ƒì„ í‘œí˜„í•˜ëŠ” ë°©ì‹ì´ ë°”ë¡œ ê·¸ë˜í”„ì´ë‹¤&lt;/p&gt;
&lt;p&gt;ê·¸ë˜í”„ë€ ë³µì¡ê³„ë¥¼ ê°„ë‹¨í•˜ê²Œ í‘œí˜„í•˜ëŠ” ë°©ì‹ì´ë‹¤&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p>ê·¸ë˜í”„ë€ ì •ì ê³¼ ê°„ì„ ìœ¼ë¡œ ì´ë£¨ì–´ì§„ êµ¬ì¡°</p><p>í•˜ë‚˜ì˜ ê°„ì„ ì€ ë°˜ë“œì‹œ ë‘ê°œì˜ ì •ì ì„ ì—°ê²°í•œë‹¤</p><p>ì •ì  : vertex,node</p><p>ê°„ì„  : Edge,link</p><p>ìš°ë¦¬ì˜ ì‚¬íšŒë° ëª¨ë“  ë‹¤ì–‘í•œ ê²ƒë“¤ì€ êµ¬ì„±ìš”ì†Œê°„ì˜ ë³µì¡í•œ ì‚´í˜¸ì‘ìš©ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ë³µì¡ê³„ì´ë‹¤</p><p>ì´ê²ƒì„ í‘œí˜„í•˜ëŠ” ë°©ì‹ì´ ë°”ë¡œ ê·¸ë˜í”„ì´ë‹¤</p><p>ê·¸ë˜í”„ë€ ë³µì¡ê³„ë¥¼ ê°„ë‹¨í•˜ê²Œ í‘œí˜„í•˜ëŠ” ë°©ì‹ì´ë‹¤</p><span id="more"></span><p>ì •ì  ë¶„ë¥˜ë¬¸ì œ (node classification) ex) ì–´ë– í•œ ê³„ì •ì´ ì–´ë– ê±¸ ë¦¬íŠ¸ìœ—í–ˆëŠ”ì§€ë¥¼ ê°„ì„ ìœ¼ë¡œ í‘œí˜„. ì‚¬ëŒ(node)ì˜ ë³´ìˆ˜ì„±, ì§„ë³´ì„±ì„ íŒë³„í•˜ëŠ” </p><p>ë­í‚¹ ë° ì •ë³´ê²€ìƒ‰ë¬¸ì œ : ì›¹ì´ë¼ëŠ” ê±°ëŒ€í•œ ê·¸ë˜í”„ë¡œë¶€í„° ì–´ë–»ê²Œ ì¤‘ìš”í•œ ì›¹í˜ì´ì§€ë¥¼ ì°¾ì•„ë‚¼ê¹Œ?</p><p>êµ°ì§‘ë¶„ì„ë¬¸ì œ : ì—°ê²°ê´€ê³„ë¡œ ë¶€í„° ì‚¬íšŒì  ë¬´ë¦¬(êµ°ì§‘)ì„ ì°¾ì•„ë‚¼ ìˆ˜ ìˆì„ê¹Œ?</p><p>ì •ë³´ì „íŒŒ &amp; ë°”ì´ëŸ´ ë§ˆì¼€íŒ… ë¬¸ì œ : ì •ë³´ë¼ëŠ” ê²ƒì´ ì–´ë–»ê²Œ ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•´ ì „íŒŒê°€ ë ê¹Œ?</p><p>ë³¸ê°•ì˜ì—ì„œëŠ” ìœ„ì˜ ë¬¸ì œë“¤ì„ í•´ê²°í•˜ëŠ” ê¸°ìˆ ë“¤ì„ ë°°ìš°ê²Œë  ì˜ˆì •</p><p>1ì£¼ì¼ì´ë¼ëŠ” ì§§ì€ ì‹œê°„ì´ë¼ ê¸°ì´ˆë¥¼ ë°°ìš°ê³  ì§ê´€ì ì¸ ë°©ë²•ë¡ ì ì¸ ì„¤ëª…</p><p>ê°„ì„ ì— ë°©í–¥ì´ ìˆëŠ” directed graph vs undirected graph</p><p>í˜‘ì—…ê´€ê³„ê·¸ë˜í”„, í˜ì´ìŠ¤ë¶ ì¹œêµ¬ê·¸ë˜í”„ : undirectied</p><p>ì¸ìš©ê·¸ë˜í”„, íŠ¸ìœˆí„° íŒ”ë¡œìš° ê·¸ë˜í”„ : directed</p><p>ê°„ì„ ì— ê°€ì¤‘ì¹˜ê°€ ìˆëŠ” ê·¸ë˜í”„ : ì „í™”ê·¸ë˜í”„, ìœ ì‚¬ë„ ê·¸ë˜í”„</p><p>ê°„ì„ ì— ê°€ì¤‘ì¹˜ê°€ ì—†ëŠ” ê·¸ë˜í”„ : í˜ì´ìŠ¤ë¶ ì¹œêµ¬ ê·¸ë˜í”„, ì›¹ê·¸ë˜í”„</p><p>ë™ì¢… ê·¸ë˜í”„ vs ì´ì¢…ê·¸ë˜í”„</p><p>ì´ì¢…ê·¸ë˜í”„ëŠ” ë‘ì¢…ë¥˜ì˜ nodeë¥¼ ê°€ì§„ë‹¤ . ì„œë¡œë‹¤ë¥¸ ì •ì  ì‚¬ì´ì—ë§Œ ê°„ì„ ì´ ì—°ê²°ëœë‹¤. Ex) ì‚¬ìš©ì,ìƒí’ˆì‚¬ì´ì˜ ì „ììƒê±°ë˜ ë‚´ì—­</p><p>ë™ì¢…ê·¸ë˜í”„ëŠ” ë‹¨ì¼ì¢…ë¥˜ì˜ ì •ì ì„ ê°€ì§„ë‹¤</p><p>nodeì˜ ì§‘í•© V, edgeì˜ ì§‘í•© : E, </p><p>G = (V,E)</p><p>N<del>out</del>(1), N<del>in</del>(1)ì´ëŸ°ê±°</p><p>ê·¸ë˜í”„ì˜ í‘œí˜„ ë° ì €ì¥</p><p>Networkxë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ë¥¼ í‘œí˜„</p><p>snap.pyë¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë„ ë§ì´ ì‚¬ìš©í•œë‹¤.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure><p>ì¸ì ‘ ë¦¬ìŠ¤íŠ¸</p><p>1 : [2.5]</p><p>2 : [1,3,5]</p><p>3: [2]</p><p>5: [1,2]</p><p>ì¸ì ‘í–‰ë ¬</p><p>ê°„ì„ ì´ ìˆìœ¼ë©´ 1, ì—†ìœ¼ë©´ 0</p><p>ë°©í–¥ì„±ì´ ì—†ìœ¼ë©´ ëŒ€ê°ìœ¼ë¡œ ëŒ€ì¹­</p><p>ìˆìœ¼ë©´ ë‹¤ë¦„</p><p>í¬ì†Œí–‰ë ¬ì„ ì‚¬ìš©í•˜ë©´ ì €ì¥ê³µê°„ì„ ì ˆì•½í•  ìˆ˜ ìˆìŒ (ëŒ€ë¶€ë¶„ì˜ ì›ì†Œê°€ 0ì¼ë•Œ)</p><h2 id="1-ì‹¤ì œê·¸ë˜í”„-vs-ëœë¤ê·¸ë˜í”„"><a href="#1-ì‹¤ì œê·¸ë˜í”„-vs-ëœë¤ê·¸ë˜í”„" class="headerlink" title="1. ì‹¤ì œê·¸ë˜í”„ vs ëœë¤ê·¸ë˜í”„"></a>1. ì‹¤ì œê·¸ë˜í”„ vs ëœë¤ê·¸ë˜í”„</h2><p>ì‹¤ì œ ê·¸ë˜í”„ë€ ë‹¤ì–‘í•œ ë³µì¡ê³„ë¡œë¶€í„° ì–»ì–´ì§„ ê·¸ë˜í”„ë¥¼ ì˜ë¯¸í•œë‹¤</p><p>ë³¸ìˆ˜ì—…ì—ì„œëŠ” MSN ë©”ì‹ ì € ê·¸ë˜í”„ë¥¼ ì‹¤ì œ ê·¸ë˜í”„ì˜ ì˜ˆì‹œë¡œ ì‚¬ìš©í•˜ê² ë‹¤.</p><p>ëœë¤ê·¸ë˜í”„ë€ í™•ë¥ ì  ê³¼ì •ì„ í†µí•´ ìƒì„±ëœ ê·¸ë˜í”„ë¥¼ ì˜ë¯¸í•œë‹¤</p><h3 id="ì—ë¥´ë˜ìŠ¤-ë ˆë‹ˆ-ëœë¤ê·¸ë˜í”„"><a href="#ì—ë¥´ë˜ìŠ¤-ë ˆë‹ˆ-ëœë¤ê·¸ë˜í”„" class="headerlink" title="ì—ë¥´ë˜ìŠ¤-ë ˆë‹ˆ ëœë¤ê·¸ë˜í”„"></a>ì—ë¥´ë˜ìŠ¤-ë ˆë‹ˆ ëœë¤ê·¸ë˜í”„</h3><p>ì„ì˜ì˜ ë‘ nodeì‚¬ì´ì˜ ê°„ì„  ì¡´ì¬ì—¬ë¶€ê°€ ë™ì¼í•œ í™•ë¥ ë¶„í¬ë¡œ ë‚˜íƒ€ë‚´ì–´ì§</p><p>G(n,p)ëŠ” nê°œì˜ ì •ì , ë‘ê°œì˜ ì •ì  ì‚¬ì´ì— ê°„ì„ ì´ ì¡´ì¬í•  í™•ë¥  = p</p><h2 id="2-ì‘ì€-ì„¸ìƒ-íš¨ê³¼"><a href="#2-ì‘ì€-ì„¸ìƒ-íš¨ê³¼" class="headerlink" title="2. ì‘ì€ ì„¸ìƒ íš¨ê³¼"></a>2. ì‘ì€ ì„¸ìƒ íš¨ê³¼</h2><p>ì •ì  uì™€ vì‚¬ì´ì˜ ê²½ë¡œë€</p><p>uì—ì„œ ì‹œì‘í•´ì„œ vì—ì„œ ëë‚˜ì•¼ í•œë‹¤</p><p>ìˆœì—´ì—ì„œ ì—°ì†ëœ ì •ì ì€ ë°˜ë“œì‹œ ê°„ì„ ìœ¼ë¡œ ì—°ê²°ë˜ì–´ìˆì–´ì•¼ í•œë‹¤.</p><p>ê²½ë¡œ, ê±°ë¦¬, ë° ì§€ë¦„</p><p>ê²½ë¡œëŠ” ì—¬ëŸ¬ê°€ì§€ì§€ë§Œ ì´ì¤‘ ê°€ì¥ ì§§ì€ ê²½ë¡œì˜ ê¸¸ì´ê°€ ê±°ë¦¬ì´ë‹¤</p><p>ê·¸ë˜í”„ì—ì„œ ì§€ë¦„ì€ ì •ì ê°„ ê±°ë¦¬ì˜ ìµœëŒ“ê°’ì´ë‹¤.</p><p>ì‘ì€ ì„¸ìƒ íš¨ê³¼</p><p>ì„ì˜ì˜ ë‘ì‚¬ëŒì„ ê³¨ëì„ ë•Œ ì´ë“¤ì€ ëª‡ë‹¨ê³„ì˜ ì§€ì¸ì„ ê±°ì³ì•¼ ì—°ê²°ë˜ëŠ”ê°€?</p><p>ìœ„ì¹˜íƒ€ì—ì„œ ë³´ìŠ¤í„´ê¹Œì§€ ì§€ì¸ì„ 6ë‹¨ê²Œê±°ì¹˜ë©´ ê°€ëŠ¥</p><p>MSNì—ì„œë„ ì •ì ê°„ì˜ í‰ê· ê±°ë¦¬ëŠ”7ì •ë„ë°–ì— ë˜ì§€ ì•ŠëŠ”ë‹¤</p><p>ë‹¨ ê±°ëŒ€ì—°ê²°êµ¬ì¡°ë§Œì„ ê³ ë ¤í•˜ì˜€ë‹¤.</p><p>ì´ëŸ¬í•œ í˜„ìƒì„ ì‘ì€ì„¸ìƒíš¨ê³¼ë¼ê³  í•œë‹¤.</p><p>ì‘ì€ ì„¸ìƒíš¨ê³¼ëŠ” ë†’ì€ í™•ë¥ ë¡œ ëœë¤ê·¸ë˜í”„ì—ë„ ì¡´ì¬í•œë‹¤.</p><p>ì²´ì¸ ì‚¬ì´í´ ê²©ìê·¸ë˜í”„ì—ëŠ” ì´ ì‘ì€ì„¸ìƒê·¸ë˜í”„íš¨ê³¼ê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤.</p><h2 id="ì—°ê²°ì„±ì—-ë‘í„°ìš´-ê¼¬ë¦¬ë¶„í¬"><a href="#ì—°ê²°ì„±ì—-ë‘í„°ìš´-ê¼¬ë¦¬ë¶„í¬" class="headerlink" title="ì—°ê²°ì„±ì— ë‘í„°ìš´ ê¼¬ë¦¬ë¶„í¬"></a>ì—°ê²°ì„±ì— ë‘í„°ìš´ ê¼¬ë¦¬ë¶„í¬</h2><p>ì—°ê²°ì„±?</p><p>ì •ì ì˜ Degreeë€ ê·¸ì •ì ê³¼ ì—°ê²°ëœ ê°„ì„ ì˜ ìˆ˜ : |N(v)| ë¼ê³  í‘œí˜„í•˜ê¸°ë„ í•¨</p><p>ëœë¤ê·¸ë˜í”„ì˜ ì—°ê²°ì„± ë¶„í¬ëŠ” ë†’ì€ í™•ë¥ ë¡œ ì •ê·œë¶„í¬ì™€ ìœ ì‚¬í•˜ë‹¤</p><p>ì‹¤ì œ ê·¸ë˜í”„ëŠ” ì—°ê²°ì„±ì´ ë‘í„°ì›Œì„œ hub ì •ì ì´ ì¡´ì¬í•  ìˆ˜ìˆëŠ”ë°</p><p>ëœë¤ê·¸ë˜í”„ì—ì„œëŠ” ì •ê·œë¶„í¬ë¥¼ ëŒ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤</p><h2 id="ì—°ê²°ìš”ì†Œ"><a href="#ì—°ê²°ìš”ì†Œ" class="headerlink" title="ì—°ê²°ìš”ì†Œ"></a>ì—°ê²°ìš”ì†Œ</h2><ol><li>ì—°ê²°ìš”ì†Œì— ì†í•˜ëŠ” ì •ì ë“¤ì€ ê²½ë¡œë¡œ ì—°ê²°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li><li>1ì˜ ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ì„œ ì •ì ì„ ì¶”ê°€í•  ìˆ˜ ì—†ë‹¤.</li></ol><p>ì‹¤ì œê·¸ë˜í”„ì—ëŠ” ëŒ€ë‹¤ìˆ˜ì˜ ì •ì ì„ í¬í•¨í•˜ëŠ” ê±°ëŒ€ì—°ê²°ìš”ì†Œê°€ ì¡´ì¬í•œë‹¤</p><p>MSNë©”ì‹ ì € ê·¸ë˜í”„ì—ëŠ” 99,9%ì˜ ì •ì ì´ í•˜ë‚˜ì˜ ê±°ëŒ€ì—°ê²°ìš”ì†Œì— í¬í•¨ëœë‹¤</p><p>ì •ì ë“¤ì˜ í‰ê·  ì—°ê²°ì„±ì´ 1ë³´ë‹¤ ì¶©ë¶„íˆ í°ê²½ìš°, ëœë¤ê·¸ë˜í”„ì—ë„ ë†’ì€ í™•ë¥ ë¡œ ê±°ëŒ€ì—°ê²° ìš”ì†Œê°€ ì¡´ì¬í•œë‹¤.</p><p>êµ°ì§‘ì´ë€ ì •ì ë“¤ì˜ ì§‘í•©</p><p>ê°™ì€ êµ°ì§‘ì•ˆì—ì„œì˜ ì •ì  ì‚¬ì´ì—ëŠ” ë§ì€ edgeê°€ ì¡´ì¬</p><p>ì§€ì—­ì  êµ°ì§‘ ê³„ìˆ˜ : ê·¸ ì •ì ì´ êµ°ì§‘ì„ í˜•ì„±í•˜ë ¤ëŠ” ì •ë„</p><p>C<del>i</del> = ì •ì  iì˜ ì´ì›ƒìŒì¤‘ ê°„ì„ ìœ¼ë¡œ ì§ì ‘ ì—°ê²°ëœ ê²ƒì˜ ë¹„ìœ¨</p><p>ì •ì iì˜ ì§€ì—­ì  êµ°ì§‘ê³„ìˆ˜ê°€ ë†’ìœ¼ë©´ ì´ì›ƒë“¤ì´ ì—°ê²°ë˜ì–´ìˆë‹¤.-&gt; ì •ì  iì™€ ì´ì›ƒë“¤ì´ êµ°ì§‘ì„ í˜•ì„±í•œë‹¤</p><p>ì „ì—­ êµ°ì§‘ ê³„ìˆ˜</p><p>ì „ì²´ ê·¸ë˜í”„ì—ì„œ êµ°ì§‘ì˜ í˜•ì„±ì •ë„ë¥¼ ì¸¡ì •</p><p>ê° ì •ì ì—ì„œ ì§€ì—­ì  êµ°ì§‘ê³„ìˆ˜ì˜ í‰ê· ì´ë‹¤. ë‹¨ ì§€ì—­ì  êµ°ì§‘ê³„ìˆ˜ê°€ ì •ì˜ê°€ ì•ˆë˜ë©´ ì§¤</p><p>ì„¸ìƒì—ëŠ” ë§ì€ êµ°ì§‘ì´ ì¡´ì¬í•œë‹¤ </p><ol><li><p>homophily : ìœ ì‚¬í•œ ì •ì ë¼ë¦¬ëŠ”</p></li><li><p>ê³µí†µì´ì›ƒì´ ìˆëŠ”ê²½ìš° ê³µí†µì´ì›ƒì´ ë‘ì •ì ì„ ë§¤ê°œí•˜ëŠ” ì—­í• </p></li></ol><p><img src="/images/image-20210222131012470.png" alt="image-20210222131012470"></p>]]></content:encoded>
      
      
      <category domain="https://jo-member.github.io/categories/Boostcamp/">Boostcamp</category>
      
      
      <category domain="https://jo-member.github.io/tags/Graph/">Graph</category>
      
      
      <comments>https://jo-member.github.io/2021/02/22/2021-02-22-Boostcamp21.1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Transformerì‹¬í™”</title>
      <link>https://jo-member.github.io/2021/02/18/2021-02-18-Boostcamp19.1/</link>
      <guid>https://jo-member.github.io/2021/02/18/2021-02-18-Boostcamp19.1/</guid>
      <pubDate>Wed, 17 Feb 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;Transformer&quot;&gt;&lt;a href=&quot;#Transformer&quot; class=&quot;headerlink&quot; title=&quot;Transformer&quot;&gt;&lt;/a&gt;Transformer&lt;/h1&gt;&lt;br/&gt;

&lt;h2 id=&quot;Self-Attention&quot;&gt;&lt;a href=&quot;#Self-Attention&quot; class=&quot;headerlink&quot; title=&quot;Self-Attention&quot;&gt;&lt;/a&gt;Self-Attention&lt;/h2&gt;&lt;p&gt;ex) I go home&lt;/p&gt;
&lt;p&gt;Iì— ëŒ€í•œ input vectorê°€ hidden stateì²˜ëŸ¼ ì—­í• ì„ í•˜ì—¬ì„œ&lt;/p&gt;
&lt;p&gt;Iì™€ ê°ê°ì˜ ë‹¨ì–´ì— ëŒ€í•œ ë‚´ì ì„ í•œí›„ ì´ì—ëŒ€í•œ softmaxë¥¼ êµ¬í•˜ì—¬ ê°€ì¤‘í‰ê· ì„ êµ¬í•œë‹¤.&lt;/p&gt;
&lt;p&gt;ì´ë ‡ê²Œ encoding vectorê°’ì„ êµ¬í•˜ê²Œ ë˜ë©´ ê²°êµ­ ìê¸°ìì‹ ê³¼ ë‚´ì í•œ ê°’ì´ í°ê°’ì„ ê°€ì ¸, ìê¸° ìì‹ ì— ëŒ€í•œ íŠ¹ì„±ë§Œì´ dominantí•˜ê²Œ ë‹´ê¸¸ê²ƒì´ë¯€ë¡œ, ì´ë¥¼ í•´ê²°í•´ì£¼ê¸° ìœ„í•´ ë‹¤ë¥¸ architectureë¥¼ ì“´ë‹¤&lt;/p&gt;
&lt;p&gt;ê° vectorë“¤ì´ 3ê°€ì§€ì˜ ì—­í• ì„ í•˜ê³ ìˆëŠ” ê²ƒì´ë‹¤. ë™ì¼í•œ setì˜ vectorì—ì„œ ì¶œë°œí–ˆë”ë¼ë„ ê°í˜í• ì— ë”°ë¼ vectorê°€ ì„œë¡œë‹¤ë¥¸í˜•íƒœë¡œ ë³€í™˜í• ìˆ˜ìˆê²Œí•´ì£¼ëŠ” linear transformation matrixê°€ ìˆë‹¤.&lt;/p&gt;
&lt;p&gt;í•œë§ˆë””ë¡œ ê°ê°ì˜ inputì´ ì„œë¡œë‹¤ë¥¸ matrixì— ì ìš©ì´ë˜ì–´ ê°ê°ì´ key, quary,valueê°€ ëœë‹¤ëŠ” ì˜ë¯¸ì´ë‹¤.&lt;/p&gt;
&lt;p&gt;I ë¼ëŠ” wordê°€ ì„œë¡œë‹¤ë¥¸ matrixì— ë”°ë¼ quart, key, valueê°’ì´ ë§Œë“¤ì–´ì§€ê³  ì¿¼ë¦¬ëŠ” 1ê°œì´ê³  ì´ ì¿¼ë¦¬ ë²¡í„°ì™€ ê°ê°ì˜ key vectorì™€ì˜ ë‚´ì ê°’ì„ êµ¬í•˜ê³  ê²°ê³¼ë¥¼ softmaxì— í†µê³¼ì‹œì¼œ ê°€ì¤‘ì¹˜ë¥¼ êµ¬í•œí›„ , ì´ê°’ê³¼ value vectorë¥¼ ê°ê° ê³±í•´ì£¼ì–´ ì´ë“¤ì˜ ê°€ì¤‘í‰ê· ìœ¼ë¡œ ìµœì¢…ì ì¸ vectorë¥¼ êµ¬í•˜ë‹¤. ê²°êµ­ ì´ vectorê°€ featureë“¤ì´ ë‹´ê¸´ encoding vectorì´ë‹¤.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/image-20210218113022613.png&quot; alt=&quot;image-20210218113022613&quot;&gt;&lt;/p&gt;
&lt;p&gt;ì´ëŸ¬í•˜ê²Œ í–‰ë ¬ì—°ì‚°ìœ¼ë¡œ ìœ„ì˜ ê³¼ì •ì„ í•œë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><br/><h2 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h2><p>ex) I go home</p><p>Iì— ëŒ€í•œ input vectorê°€ hidden stateì²˜ëŸ¼ ì—­í• ì„ í•˜ì—¬ì„œ</p><p>Iì™€ ê°ê°ì˜ ë‹¨ì–´ì— ëŒ€í•œ ë‚´ì ì„ í•œí›„ ì´ì—ëŒ€í•œ softmaxë¥¼ êµ¬í•˜ì—¬ ê°€ì¤‘í‰ê· ì„ êµ¬í•œë‹¤.</p><p>ì´ë ‡ê²Œ encoding vectorê°’ì„ êµ¬í•˜ê²Œ ë˜ë©´ ê²°êµ­ ìê¸°ìì‹ ê³¼ ë‚´ì í•œ ê°’ì´ í°ê°’ì„ ê°€ì ¸, ìê¸° ìì‹ ì— ëŒ€í•œ íŠ¹ì„±ë§Œì´ dominantí•˜ê²Œ ë‹´ê¸¸ê²ƒì´ë¯€ë¡œ, ì´ë¥¼ í•´ê²°í•´ì£¼ê¸° ìœ„í•´ ë‹¤ë¥¸ architectureë¥¼ ì“´ë‹¤</p><p>ê° vectorë“¤ì´ 3ê°€ì§€ì˜ ì—­í• ì„ í•˜ê³ ìˆëŠ” ê²ƒì´ë‹¤. ë™ì¼í•œ setì˜ vectorì—ì„œ ì¶œë°œí–ˆë”ë¼ë„ ê°í˜í• ì— ë”°ë¼ vectorê°€ ì„œë¡œë‹¤ë¥¸í˜•íƒœë¡œ ë³€í™˜í• ìˆ˜ìˆê²Œí•´ì£¼ëŠ” linear transformation matrixê°€ ìˆë‹¤.</p><p>í•œë§ˆë””ë¡œ ê°ê°ì˜ inputì´ ì„œë¡œë‹¤ë¥¸ matrixì— ì ìš©ì´ë˜ì–´ ê°ê°ì´ key, quary,valueê°€ ëœë‹¤ëŠ” ì˜ë¯¸ì´ë‹¤.</p><p>I ë¼ëŠ” wordê°€ ì„œë¡œë‹¤ë¥¸ matrixì— ë”°ë¼ quart, key, valueê°’ì´ ë§Œë“¤ì–´ì§€ê³  ì¿¼ë¦¬ëŠ” 1ê°œì´ê³  ì´ ì¿¼ë¦¬ ë²¡í„°ì™€ ê°ê°ì˜ key vectorì™€ì˜ ë‚´ì ê°’ì„ êµ¬í•˜ê³  ê²°ê³¼ë¥¼ softmaxì— í†µê³¼ì‹œì¼œ ê°€ì¤‘ì¹˜ë¥¼ êµ¬í•œí›„ , ì´ê°’ê³¼ value vectorë¥¼ ê°ê° ê³±í•´ì£¼ì–´ ì´ë“¤ì˜ ê°€ì¤‘í‰ê· ìœ¼ë¡œ ìµœì¢…ì ì¸ vectorë¥¼ êµ¬í•˜ë‹¤. ê²°êµ­ ì´ vectorê°€ featureë“¤ì´ ë‹´ê¸´ encoding vectorì´ë‹¤.</p><p><img src="/images/image-20210218113022613.png" alt="image-20210218113022613"></p><p>ì´ëŸ¬í•˜ê²Œ í–‰ë ¬ì—°ì‚°ìœ¼ë¡œ ìœ„ì˜ ê³¼ì •ì„ í•œë²ˆì— ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.</p><span id="more"></span><h2 id="Multi-head-Attention"><a href="#Multi-head-Attention" class="headerlink" title="Multi-head Attention"></a>Multi-head Attention</h2><p><img src="/images/image-20210218115609302.png" alt="image-20210218115609302"></p><p>ì¿¼ë¦¬,key,valueë¥¼ ë§Œë“¤ë•Œ ì—¬ëŸ¬ setì˜ matrixë¥¼ ì ìš©í•˜ì—¬ ì—¬ëŸ¬ attentionì„ ìˆ˜í–‰í•œë‹¤. ì´ëŸ¬í•œ ì„œë¡œë‹¤ë¥¸ ì„ í˜•ë³€í™˜ matrixë¥¼ headë¼ê³  ë¶€ë¥¸ë‹¤. ë™ì¼í•œ sequenceì—ì„œ íŠ¹ì •í•œ quaryì— ëŒ€í•´ì„œ ì—¬ëŸ¬ì¸¡ë©´ìœ¼ë¡œ ì •ë³´ë¥¼ ë½‘ì•„ì•¼í•˜ëŠ” ê²½ìš°ê°€ ìˆë‹¤. </p><p><img src="/images/image-20210218115717813.png" alt="image-20210218115717813"></p><p><img src="/images/image-20210218120149327.png" alt="image-20210218120149327"></p><p>ì´í›„ í•˜ë‚˜ì˜ ì„ í˜•ë³€í™˜ layerë¥¼ ì¶”ê°€í•˜ì—¬ ìš°ë¦¬ê°€ ì›í•˜ëŠ” shapeì˜ outputì„ ì–»ì–´ë‚¸ë‹¤. ì™œ ì´ëŸ¬í•œ shapeìœ¼ë¡œ ë³€í™˜í•´ì•¼í• ê¹Œ? for residual connection</p><p>Residual connectionì„ ì‚¬ìš©í–ˆë‹¤. ì´ëŠ” CVì—ì„œ ë„ë¦¬ì“°ì´ë˜ Resnetì—ì„œ ì‚¬ìš©í•œ residueê°œë…ì„ í™œìš©í•˜ì—¬, attention ê²°ê³¼ì˜ encoded vectorì™€ ì›ë˜ ì…ë ¥ vectorë¥¼ ë”í•œë‹¤. ì´ëŸ¬í•œ ê³¼ì •ì„ í†µí•´ gradient vanishingê³¼ í•™ìŠµì˜ ì†ë„ë¥¼ í•´ê²°í•˜ì˜€ë‹¤.</p><p>Layer Normalization</p><p>ì£¼ì–´ì§„ sampleì— ëŒ€í•´ì„œ ê·¸ê°’ë“¤ì˜ í‰ê· ì„ 0 ë¶„ì‚°ì„ 1ë¡œ ë§Œë“¤ì–´ì¤€í›„ ìš°ë¦¬ê°€ ì›í•˜ëŠ” í‰ê· ê³¼ ë¶„ì‚°ì„ ë§Œë“¤ì–´ì£¼ëŠ” ì„ í˜•ë³€í™˜ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ìˆë‹¤.<img src="/images/image-20210218122035821.png" alt="image-20210218122035821"></p><p>í‘œì¤€í™”ëœ í‰ê· ê³¼ ë¶„ì‚°ìœ¼ë¡œ ë§Œë“¤ì–´ì¤Œ. ì´í›„ affine transformation (ex : y = 2x+3)ì„ ìˆ˜í–‰í•  ê²½ìš° í‰ê· ì€ 3 ë¶„ì‚°ì€ 4ê°€ ëœë‹¤. ì—¬ê¸°ì„œì˜ 2ì™€ 3ì€ NNì´ optimizeí•´ì•¼í•˜ëŠ” paramterê°€ ëœë‹¤. ìœ„ì˜ transformerì—ë„ ì´ëŸ°ì‹ìœ¼ë¡œ ì ìš©ì´ëœë‹¤</p><p><img src="/images/image-20210218122412734.png" alt="image-20210218122412734"></p><p>affine transformationì€ ì´ì œ parameterì´ë¼ í•™ìŠµí•˜ëŠ”? ì™œì„±ëŠ¥ì´ ì˜¬ë¼ê°ˆê¹Œ?</p><p>Transformerì—ì„œì˜ self attentionì€ ìˆœì„œì˜ ì •ë³´ë¥¼ ë‹´ê³ ìˆì§€ ì•Šê¸° ë•Œë¬¸ì— ì¶”ê°€ì ì¸ ì‘ì—…ì´ í•„ìš”í•˜ë‹¤. ì´ ì‘ì—…ì„ transformerì€ postition encodingì— sinusodial functionì„ ì ìš©í•˜ì˜€ë‹¤.</p><p>Optimizerì€ graident descentê°€ ì•„ë‹Œ Adamì„ ì‚¬ìš©í•˜ì˜€ë‹¤. Learning rateì„ ê³ ì •í•œ ê°’ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  í•™ìŠµì¤‘ì— lrì„ ë³€ê²½ì‹œì¼œì£¼ì—ˆë‹¤. </p><h2 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h2><p><SOS>, ë‚˜ëŠ”, ì§‘ì—, ê°„ë‹¤</p><p>Masked Multi-Head Attentionì˜ ê²°ê³¼ê°€ê°€ ì–»ì–´ì¡Œë‹¤ë©´ ì´ë¥¼ ë‹¤ì‹œ multi-head attentionì— ë„£ì–´ì¤€ë‹¤. ê·¸ë° ì´ì œ quaryì—ë§Œ ì´ê²Œ ì‚¬ìš©ë˜ê³  encodingë‹¨ì˜ encoded vectorê°€ ì´ì œ keyì™€ valueê°’ì— ë“¤ì–´ê°€ê²Œ ëœë‹¤. ì´ì œ target languageì˜ vocab sizeì— ë§ëŠ” vectorë¥¼ ìƒì„±í•˜ëŠ” linear transformationì„ ê±¸ì–´ì¤€ë‹¤. ê·¸ê³³ì— soft maxë¥¼ ì·¨í•´ì„œ ë‹¤ìŒ wordë¥¼ ì°¾ì•„ë‚¸ë‹¤. ì´ì œ ground truthì™€ì˜ softmax lossë¥¼ êµ¬í•´ì„œ backpropagationìœ¼ë¡œ í•™ìŠµí•´ ë‚˜ê°„ë‹¤.</p><p><strong>Masked Self Attention</strong></p><p>ì „ì²´ sequenceì— ëŒ€í•œ ì •ë³´ë¥¼ í—ˆìš©í•˜ê²Œ ë˜ë©´ ì²«ë²ˆì§¸ time stepì—ì„œ SOSë§Œì´ ì£¼ì–´ì¡ŒëŠ”ë° ë‚˜ëŠ”ì´ë¼ëŠ” ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•´ì•¼ í•˜ëŠ”ë° ë‚˜ëŠ”ì´ë¼ëŠ” ê°’ê³¼ sosì‚¬ì´ì˜ í–‰ë ¬ê³±ê°’ì´ ìˆê¸° ë•Œë¬¸ì— ì´ìƒí™©ì—ëŠ” ì´ë¥¼ maskingí•´ì£¼ì–´ì•¼ í•œë‹¤.</p><p><img src="/images/image-20210218135058123.png" alt="image-20210218135058123"></p><p>ì´ë ‡ê²Œ maskingí•´ì¤€í›„ normalizeë¥¼ í•´ì£¼ê²Œ ëœë‹¤. ê°€ì¤‘í‰ê· ì˜ í•©ì´ 1ì´ ë˜ë„ë¡</p>]]></content:encoded>
      
      
      <category domain="https://jo-member.github.io/categories/Boostcamp/">Boostcamp</category>
      
      
      <category domain="https://jo-member.github.io/tags/Transformer/">Transformer</category>
      
      <category domain="https://jo-member.github.io/tags/NLP/">NLP</category>
      
      
      <comments>https://jo-member.github.io/2021/02/18/2021-02-18-Boostcamp19.1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Sequence to sequence with Attention</title>
      <link>https://jo-member.github.io/2021/02/17/2021-02-15-Boostcamp18.1/</link>
      <guid>https://jo-member.github.io/2021/02/17/2021-02-15-Boostcamp18.1/</guid>
      <pubDate>Tue, 16 Feb 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;h1 id=&quot;Sequence-to-sequence&quot;&gt;&lt;a href=&quot;#Sequence-to-sequence&quot; class=&quot;headerlink&quot; title=&quot;Sequence to sequence&quot;&gt;&lt;/a&gt;Sequence to sequence&lt;/h1&gt;&lt;br/&gt;

&lt;p&gt;\&lt;/p&gt;
&lt;h2 id=&quot;Seq2Seq-Model&quot;&gt;&lt;a href=&quot;#Seq2Seq-Model&quot; class=&quot;headerlink&quot; title=&quot;Seq2Seq Model&quot;&gt;&lt;/a&gt;Seq2Seq Model&lt;/h2&gt;&lt;p&gt;Ex) Are you free tomorrow?&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/image-20210217110021239.png&quot; alt=&quot;image-20210217110021239&quot;&gt;&lt;/p&gt;
&lt;p&gt;ì„œë¡œ paramterë¥¼ shareí•˜ì§€ ì•ŠëŠ” 2ê°œì˜ ë³„ê°œì˜ RNN modelì„ (ë³´í†µ LSTM) ì“´ë‹¤. ê°ê°ì˜ RNNì„ Decoder, Encoderë¡œ ì‚¬ìš©í•œë‹¤.&lt;/p&gt;
&lt;p&gt;Encoderì˜ ë§ˆì§€ë§‰ë‹¨ì˜ outputì„ vertorize ì‹œì¼œì¤€í›„ decoderì˜ inputì—ëŠ” SOS token, hidden stateì—ëŠ” encoderì˜ outputì„ ë„£ì–´ì¤€ë‹¤.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<h1 id="Sequence-to-sequence"><a href="#Sequence-to-sequence" class="headerlink" title="Sequence to sequence"></a>Sequence to sequence</h1><br/><p>\</p><h2 id="Seq2Seq-Model"><a href="#Seq2Seq-Model" class="headerlink" title="Seq2Seq Model"></a>Seq2Seq Model</h2><p>Ex) Are you free tomorrow?</p><p><img src="/images/image-20210217110021239.png" alt="image-20210217110021239"></p><p>ì„œë¡œ paramterë¥¼ shareí•˜ì§€ ì•ŠëŠ” 2ê°œì˜ ë³„ê°œì˜ RNN modelì„ (ë³´í†µ LSTM) ì“´ë‹¤. ê°ê°ì˜ RNNì„ Decoder, Encoderë¡œ ì‚¬ìš©í•œë‹¤.</p><p>Encoderì˜ ë§ˆì§€ë§‰ë‹¨ì˜ outputì„ vertorize ì‹œì¼œì¤€í›„ decoderì˜ inputì—ëŠ” SOS token, hidden stateì—ëŠ” encoderì˜ outputì„ ë„£ì–´ì¤€ë‹¤.</p><span id="more"></span><h2 id="Seq2Seq-with-Attention"><a href="#Seq2Seq-with-Attention" class="headerlink" title="Seq2Seq with Attention"></a>Seq2Seq with Attention</h2><p>ì•ì—ì„œì˜ RNNì„ ì‚¬ìš©í•œ modelì€ hidden state vectorì˜ dimesionì´ ì •í•´ì ¸ ìˆì–´ì„œ ì…ë ¥ë¬¸ì¥ì˜ ê¸¸ì´ê°€ ê¸¸ì–´ì§€ë©´ ë§ˆì§€ë§‰ time stepì— ìˆëŠ” hiddenstate vectorì— ì•ì„œ ë‚˜ì™”ë˜ ë§ì€ ì •ë³´ë“¤ì´ ì˜ ë‹´ê²¨ì ¸ ìˆì§€ ì•Šë‹¤.</p><p>ì•„ë¬´ë¦¬ ì´ LSTMì—ì„œ longterm dependencyë¥¼ í•´ê²°í•˜ë ¤ í•´ë„êµ¬ì¡°ìƒì˜ ë¬¸ì œ ë•Œë¬¸ì— í•´ê²°í•˜ê¸°ì— ë§¤ìš°í˜ë“¤ë‹¤</p><p>ë”°ë¼ì„œ ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ seq2seqì—ì„œ Attentionì„ í™œìš©í•  ìˆ˜ ìˆë‹¤. Attentionì€ encoderì˜ ê°ê°ì˜ hidden state vectorë¥¼ ì „ì²´ì ìœ¼ë¡œ decoderì— ì œê³µí•´ì£¼ê³  decoderì—ì„œëŠ” ê·¸ë•Œê·¸ë•Œ í•„ìš”í•œ encoderì˜ hidden state vectorë¥¼ ê°€ì ¸ê°€ì„œ ì‚¬ìš©í•œë‹¤</p><p>decoderì˜ hidden state vectorê°€ encoderì˜ ì–´ë–¤ hidden state vectorë¥¼ ê°€ì ¸ì˜¬ì§€ë¥¼ ê²°ì •í•˜ê²Œ ëœë‹¤. ì´ê±°ëŠ” ê°ê°ì„ ë‚´ì í•´ë³´ì•„ì„œ, ë‚´ì ì— ê¸°ë°˜í•œ ìœ ì‚¬ë„ë¥¼ íŒë³„í•˜ê²Œ ë˜ê³  ì´ê²°ê³¼ë¥¼ softmaxì— í†µê³¼ ì‹œì¼œì„œ í™•ë¥ ê°’ì„ ì–»ì–´ë‚´ê³  ì´ë¥¼ ê°ê°ì˜ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©í•˜ì—¬ ì´ë“¤ì˜ ê°€ì¤‘í‰ê· ìœ¼ë¡œì„œ ë‚˜ì˜¤ëŠ” í•˜ë‚˜ì˜ encoding vectorë¥¼ ì–»ì–´ë‚¼ìˆ˜ ìˆë‹¤!!!!!! ì´ëŸ¬í•œ ê°€ì¤‘í‰ê· ìœ¼ë¡œ ë‚˜ì˜¨ í•˜ë‚˜ì˜ vectorë¥¼ ìš°ë¦¬ëŠ” context vectorë¼ê³  ë¶€ë¥¸ë‹¤.  </p><p><img src="/images/image-20210217111855000.png" alt="image-20210217111855000"></p><p>ì´í›„ì— decoder hidden state vectorì™€ context vectorê°€ concatnate ë˜ì–´ output layerì˜ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°€ê²Œ ë˜ê³  ë‹¤ìŒë‚˜ì˜¬ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆê²Œ ëœë‹¤</p><p>ì´ëŸ¬í•œ ê³¼ì •ë“¤ì„ EOSê°€ ë‚˜ì˜¬ë•Œ ê¹Œì§€ ë°˜ë³µí•œë‹¤.</p><p>ì˜ëª»ëœ ë‹¨ì–´ë¥¼ ì „ë‹¨ê³„ì—ì„œ ì˜ˆì¸¡ì„ í•˜ë”ë¼ë„ ë‹¤ìŒë‹¨ê³„ì—ëŠ” ì˜¬ë°”ë¥¸ ground truthë¥¼ ë„£ì–´ì£¼ê¸° ë–„ë¬¸ì— í•˜ë‚˜ê°€ í‹€ë ¤ë„ ì´í›„ê°€ ë§ê°€ì§€ì§€ ì•ŠëŠ”ë‹¤.  í•™ìŠµì´ ëë‚œí›„ ì´ ì˜ëª»ëœ ë‹¨ì–´ë¥¼ ë‹¤ì‹œ ë„£ì–´ì¤€ë‹¤. ë˜í•œ Itâ€™s teacher forcing.</p><p>Teacher forcingì´ ì•„ë‹Œ ë°©ì‹ì´ í•™ìŠµí›„ì— ìš°ë¦¬ê°€ ì‹¤ì œë¡œ ì‚¬ìš©í• ë•Œì™€ ë¹„ìŠ·í•˜ë‹¤.</p><p>Teacher forcingë•ŒëŠ” ground truthë¥¼ ë„£ì–´ì£¼ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì—í•™ìŠµì†ë„ê°€ ë¹ ë¥´ë‹¤</p><p>í•™ìŠµì˜ ì „ë°˜ë¶€ì—ëŠ” teacher forcingì„ ì‚¬ìš©í›„  ì–´ëŠì •ë„ í•™ìŠµì´ ë˜ë©´, ì´ì „ì˜ outputì„ ë‹¤ì‹œ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì£¼ëŠ” ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•œë‹¤.</p><br/><p><img src="/images/image-20210217120519836.png" alt="image-20210217120519836"></p><p>ì´ì²˜ëŸ¼ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ëŠ” ê³¼ì •ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë‚´ì ì€, 3ê°€ì§€ì˜ ì¢…ë¥˜ë¡œ ê³„ì‚°í•´ ë‚¼ ìˆ˜ ìˆë‹¤.</p><p>2ë²ˆì§¸ì¸ general ë°©ì‹ìœ¼ë¡œ ê²Œì‚°í•˜ëŠ” ê²ƒì„ í–‰ë ¬ìœ¼ë¡œ ìƒê°í•´ë³´ì.ë‚´ì ì„ ê¸°ë°˜í•œ ê³„ì‚°ì„ í–‰ë ¬ì˜ ê³±ìœ¼ë¡œ ìƒê°í•´ë³´ë©´,  </p><p><img src="/images/image-20210217120331715.png" alt="image-20210217120331715"></p><p>ëŒ€ê°í–‰ë ¬ì˜ ì„±ë¶„ë“¤ì€ ê°™ì€ ì°¨ì›ë¼ë¦¬ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ê³ , ë‚˜ë¨¸ì§€ ê°’ë“¤ì€ ë‹¤ë¥¸ ì°¨ì›ë¼ë¦¬ì˜ ê³±í•´ì§„ ê°’ë“¤ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤</p><p>ì´ì²˜ëŸ¼ ê°„ë‹¨í•œ ë‚´ì ìœ¼ë¡œ ì •ì˜ëœ í˜•íƒœì˜ ìœ ì‚¬ë„ë¥¼ ê·¸ê°€ìš´ë° í•™ìŠµê°€ëŠ¥í•œ parameterë¥¼ ì¶”ê°€í•¨ìœ¼ë¡œì„œ ìƒˆë¡­ê²Œ scoreë¥¼ ê³„ì‚°í–ˆë‹¤.</p><p>ì´ê²Œ ë°”ë¡œ generalí•œ dot productì´ë‹¤.</p><br/><p>ë‹¤ìŒìœ¼ë¡œ concatì„ ì‚¬ìš©í•œ score ì¸¡ì • ë°©ì‹ì„ ë³´ì</p><p><img src="/images/image-20210217120926535.png" alt="image-20210217120926535"> </p><p>ì´ì²˜ëŸ¼ 2ê°œì˜ vectorë¥¼ concatì‹œì¼œ MLPì˜ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì¤€ í›„ non linear activation functionì„ ì ìš©í•˜ì—¬ ê°’ì„ êµ¬í•´ë‚¸ë‹¤.</p><p><img src="/images/image-20210217121132215.png" alt="image-20210217121132215"></p><p>ì´ìˆ˜ì‹ì„ ê°„ë‹¨í•˜ê²Œ ë³´ë©´ WaëŠ” 1ë²ˆì§¸ layerì˜ ê°€ì¤‘ì¹˜, ê·¸ì´í›„ì— tanhë¥¼ ì ìš©í•œ í›„ vë¥¼ ê³±í•´ì£¼ëŠ”ë° ì´ëŠ” ìš°ë¦¬ê°€ ìµœì¢…ì ìœ¼ë¡œ ì–»ì–´ì•¼í•  outputì´ scalarê°’ì´ê¸° ë–„ë¬¸ì— vëŠ” rowì˜ í˜•íƒœë¥¼ ë„ì–´ì•¼ í•œë‹¤. ë”°ë¼ì„œ tranposeë¥¼ ì‹œì¼œì¤€ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤.</p><br/><p>ê·¸ë ‡ë‹¤ë©´ ì´ë“¤ì˜ paramterì€ ì–´ë– íŒ ë°©ì‹ìœ¼ë¡œ updateë ê¹Œ?</p><p>ê²°êµ­ì€ ì´ëŸ¬í•œ ìœ ì‚¬ë„ë¥¼ êµ¬í•˜ëŠ”ë° í•„ìš”í•œ parameterë“¤ë˜í•œ backpropagationì„ í†µí•˜ì—¬ ì„ í˜•ë³€í™˜ í–‰ë ¬ë“¤ì´ í•™ìŠµë˜ê²Œ ëœë‹¤.</p><br/><h2 id="Attention-is-great"><a href="#Attention-is-great" class="headerlink" title="Attention is great"></a>Attention is great</h2><ul><li><p>Attention significantly impoves NMT performace</p><p>ì–´ë– í•œ í•œ ë¶€ë¶„ì— ì§‘ì¤‘í•  ìˆ˜ ìˆê²Œ í•´ì£¼ì—ˆë‹¤</p></li><li><p>It solves bottle neck problem</p><p>encoderì˜ ë§ˆì§€ë§‰ì„ ì‚¬ìš©í–ˆì–´ì•¼ í•´ì„œ ìƒê¸°ëŠ” long term dependencyë¥¼ í•´ê²°</p></li><li><p>Gradient vanishingì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ì˜€ë‹¤.</p></li><li><p>Attention provides some interpretability</p><p>ìš°ë¦¬ê°€ transformê³¼ì •ì—ì„œ ëª¨ë¸ì´ ì–´ë– í•œ ë¶€ë¶„ì— ì§‘ì¤‘ í–ˆëŠ”ì§€ë¥¼ í™•ì¸ í•  ìˆ˜ ìˆë‹¤. Allignmentë¥¼ NNì´ ìŠ¤ìŠ¤ë¡œ ë°°ìš°ëŠ” í˜„ìƒì„ ë³´ì—¬ì£¼ê²Œ ëœë‹¤.</p></li></ul><h1 id="Beam-search"><a href="#Beam-search" class="headerlink" title="Beam search"></a>Beam search</h1><ul><li>testê³¼ì •ì—ì„œ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì„ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” í•˜ë‚˜ì˜ ë°©ë²•</li></ul><h2 id="Greedy-decoding"><a href="#Greedy-decoding" class="headerlink" title="Greedy decoding"></a>Greedy decoding</h2><p>ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§€ëŠ” ë‹¨ì–´ 1ê°œë¥¼ ì„ íƒí•˜ëŠ” ë°©ë²•</p><p>ì´ë ‡ê²Œ ë˜ë©´ ì–´ë– í•œ ë‹¨ì–´ë¥¼ ì˜ëª» ìƒì„±í•´ë‚´ì—ˆì„ë•Œ ë‹¤ì‹œ ë’¤ë¡œ ëŒì•„ê°ˆìˆ˜ ì—†ì–´ ìµœì ì˜ ì˜ˆì¸¡ê°’ì„ ë‚´ì§€ ëª»í•˜ê²Œ ëœë‹¤</p><p>ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ ë‹¤ì–‘í•œ ë°©ë²•ë“¤ì´ ì œì‹œëœë‹¤</p><br/><h2 id="Exhaustive-Search"><a href="#Exhaustive-Search" class="headerlink" title="Exhaustive Search"></a>Exhaustive Search</h2><p>ì²«ë²ˆì§¸ ìƒì„±í•˜ëŠ” ë‹¨ì–´ê°€ ê°€ì¥í° í™•ë¥ ì´ì˜€ë‹¤ê³  í•´ë„ ë’·ë¶€ë¶„ì—ì„œ ë‚˜ì˜¤ëŠ” í™•ë¥ ê°’ ê°€ì¥í° í™•ë¥ ê°’ì´ ì•„ë‹Œ ê²½ìš°ê°€ ë°œìƒë ìˆ˜ê°€ ìˆë‹¤.</p><p><img src="/images/image-20210217125708440.png" alt="image-20210217125708440"></p><p>ì´ëŠ” ê²°êµ­ time step t ê¹Œì§€ì˜ ê°€ëŠ¥í•œ ëª¨ë“ ê²½ìš°ë¥¼ ë”°ì ¸ì„œ ì´ëŠ” ê³§ vocabê°€ì§€ìˆ˜ê°€ ë˜ê³  V^t^ê°€ ê°€ëŠ¥í•œ ëª¨ë“  ê²½ìš°ì˜ ìˆ˜ì´ë‹¤. ì´ëŠ” ë„ˆë¬´ í° ìˆ«ìì´ê¸° ë•Œë¬¸ì— beam searchë¥¼ ì“°ê²Œëœë‹¤</p><br/><h2 id="Beam-search-1"><a href="#Beam-search-1" class="headerlink" title="Beam search"></a>Beam search</h2><p>ë§¤ time stepë§ˆë‹¤ ëª¨ë“  ê²½ìš°ì˜ ìˆ˜ë¥¼ ê³ ë ¤í•˜ëŠ”ê²Œ ì•„ë‹ˆë¼, ìš°ë¦¬ê°€ ì •í•´ë†“ì€ kê°œì˜ ê°€ëŠ¥í•˜ ê°€ì§“ìˆ˜ë¥¼ ê³ ë ¤í•˜ê³  ë§ˆì§€ë§‰ê¹Œì§€ decodingì„ ì§„í–‰í•œí›„ kê°œì˜ candidateì¤‘ì—ì„œ ê°€ì¥í™•ë¥ ê°’ì´ ë†’ì€ê±¸ ì„ íƒí•˜ëŠ” ë°©ì‹ì´ë‹¤.</p><p>ì´ë¥¼ ìš°ë¦¬ëŠ” hypothesis (ê°€ì„¤)ì´ë¼ê³  ë¶€ë¥¸ë‹¤</p><p>këŠ” beam sizeì´ ì¼ë°˜ì ìœ¼ë¡œ 5~10ìœ¼ë¡œ ì„¤ì •í•˜ê²Œ ëœë‹¤.</p><p> <img src="/images/image-20210217130106952.png" alt="image-20210217130106952"></p><p>í™•ë¥ ë“¤ì˜ ê³±ì…ˆ ì•ì— logë¥¼ ë¶™ì´ê²Œ ë˜ë©´ ê³±ë“¤ì´ ëª¨ë‘ ë§ì…ˆì´ ëœë‹¤. ì—¬ê¸°ì„œ logí•¨ìˆ˜ ë‹¨ì¡°ì¦ê°€ì´ê¸° ë•Œë¬¸ì—, í°ê°’ì´ í°ê°’ì„ ê°€ì§„ë‹¤.</p><p>ex) k = 2</p><ol><li> kê°€ 2ì´ê¸° ë•Œë¬¸ì— ê°€ì¥ í™•ë¥ ê°’ì´ ë†’ì€ 2ê°œì˜ ë‹¨ì–´ë¥¼ ë½‘ëŠ”ë‹¤</li></ol><p><img src="/images/image-20210217130719246.png" alt="image-20210217130719246"></p><ol start="2"><li>ì´ì¤‘ ê°’ì´ í°ê±¸ ê³„ì†í•´ì„œ ì„ íƒí•´ ë‚˜ê°</li></ol><p><img src="/images/image-20210217130908355.png" alt="image-20210217130908355"></p><ul><li>greedyì˜ ê²½ìš° end tokenì´ ë‚˜ì™”ì„ë•Œê°€ ì¢…ë£Œì´ì§€ë§Œ, beam searchì—ì„œëŠ” ì„œë¡œë‹¤ë¥¸ ì‹œì ì—ì„œ end tokenì´ ìƒì„±ë˜ê¸° ë•Œë¬¸ì—, ê°ê°ì´ ëë‚ ë•Œë§ˆë‹¤ í•œê³³ì— ì €ì¥í•´ì¤€ë‹¤.</li></ul><p>ìš°ë¦¬ê°€ì •í•œ Të¼ëŠ” ì‹œê°„ê¹Œì§€ ìˆ˜í–‰í•˜ê±°ë‚˜, ì™„ë£Œëœ hypothesisê°€ nê°œê°€ ë˜ì—ˆì„ë•Œ beam searchë¥¼ ì¤‘ë‹¨í•œë‹¤.</p><p>ìš°ë¦¬ê°€ ê³ ë ¤í•˜ëŠ” hypothesesì˜ ê¸¸ì´ê°€ ë‹¤ë¥¼ë•ŒëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì§§ì€ ê¸¸ì´ì˜ í™•ë¥ ì´ ë†’ì€ê²ƒì´ê³ , ê¸¸ë©´ ë‚®ì„ê²ƒì´ë‹¤. </p><p>ì´ë¥¼ ê³ ë ¤í•´ ì£¼ê¸° ìœ„í•´ì„œëŠ” ê° joint probì„ ë¬¸ì¥ì˜ ê¸¸ì´ë¡œ ë‚˜ëˆ”ìœ¼ë¡œì„œ í•´ê²°í•´ì¤„ ìˆ˜ ìˆë‹¤.</p><h2 id="BLEU-score"><a href="#BLEU-score" class="headerlink" title="BLEU score"></a>BLEU score</h2><ul><li>ìƒì„± modelì˜ ì ìˆ˜ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•œ ì²™ë„</li><li>ê³ ì •ëœ ìœ„ì¹˜ì—ì„œ ì •í•´ì§„ ë‹¨ì–´ê°€ ë‚˜ì™€ì•¼ ëœë‹¤ëŠ” í‰ê°€ë°©ì‹ì€ ë§¤ìš° ë‚˜ìœ ë°©ì‹ì´ë‹¤.</li></ul><p>ex)</p><p>Reference : Half of my heart is in Havana ooh na na</p><p>Predicted :  Half as my heart is in Obama ohh na</p><p>Precision(ì‹¤ì œë¡œ ìœ„ì¹˜ìƒê´€ì—†ì´ ê²¹ì¹˜ëŠ” ë‹¨ì–´ê°€ ëª‡ê°œì¸ê°€) = #(correct words)/length_of_prediction = 7/9</p><p>Recall(ì¬í˜„ë¥ )  = #(correct words)/length_of_reference = 7/10</p><p>F-measure = (precision x recall) / 0.5(precision + recall) (ë‘ ê°’ë“¤ì˜ ì¡°í™”í‰ê· )</p><p>ë³´ë‹¤ ì‘ì€ ì‘ì€ ê°’ì— ê°€ê¹ê²Œ êµ¬í•˜ëŠ” ë°©ì‹ -&gt; ì¡°í™”í‰ê· </p><p>ì´ë ‡ê²Œ êµ¬í•œ ê°’ë“¤ì€ ìˆœì„œë¥¼ ë³´ì¥í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— BLEUê°€ ë‚˜ì™”ë‹¤.</p><h3 id="BiLingual-Evaluation-Understudy"><a href="#BiLingual-Evaluation-Understudy" class="headerlink" title="BiLingual Evaluation Understudy"></a>BiLingual Evaluation Understudy</h3><p><strong>Ngram</strong>ì´ë€ê±¸ ì‚¬ìš©í–ˆë‹¤. ì—°ì†ëœ Nê°œì˜ ë‹¨ì–´ë¡œ ì´ë£¨ì–´ì§„ ë¬¸êµ¬ë¥¼ matchingí•˜ì—¬ì ìˆ˜ë¡œ ë°˜ì˜í•˜ì˜€ë‹¤.</p>]]></content:encoded>
      
      
      <category domain="https://jo-member.github.io/categories/Boostcamp/">Boostcamp</category>
      
      
      <category domain="https://jo-member.github.io/tags/RNN/">RNN</category>
      
      <category domain="https://jo-member.github.io/tags/NLP/">NLP</category>
      
      
      <comments>https://jo-member.github.io/2021/02/17/2021-02-15-Boostcamp18.1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>RNNì‹¬í™”1</title>
      <link>https://jo-member.github.io/2021/02/16/2021-02-15-Boostcamp16.1/</link>
      <guid>https://jo-member.github.io/2021/02/16/2021-02-15-Boostcamp16.1/</guid>
      <pubDate>Mon, 15 Feb 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;br/&gt;

&lt;h1 id=&quot;RNN&quot;&gt;&lt;a href=&quot;#RNN&quot; class=&quot;headerlink&quot; title=&quot;RNN&quot;&gt;&lt;/a&gt;RNN&lt;/h1&gt;&lt;p&gt;ì„œë¡œë‹¤ë¥¸ time stepì—ì„œ ë“¤ì–´ì˜¤ëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ ì²˜ë¦¬í• ë•Œ, ë§¤ë²ˆ ë°˜ë³µë˜ëŠ” ë™ì¼í•œ rnn moduleì„ í˜¸ì¶œí•œë‹¤.&lt;img src=&quot;/images/image-20210216103443317.png&quot; alt=&quot;image-20210216103443317&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/image-20210216103929384.png&quot; alt=&quot;image-20210216103929384&quot;&gt;&lt;/p&gt;
&lt;p&gt;ê° ë‹¨ì–´ë³„ë¡œ í’ˆì‚¬ë¥¼ ì˜ˆì¸¡í•´ì•¼ ë˜ëŠ” ê²½ìš° -&amp;gt; ë§¤ time stepë§ˆë‹¤ yë¥¼ outputìœ¼ë¡œ&lt;/p&gt;
&lt;p&gt;ì–´ë– í•œ ë¬¸ì¥ì˜ ê¸ë¶€ì •ì„ íŒë³„í•˜ëŠ” ê²½ìš° -&amp;gt; ìµœì¢… time stepì˜ yë§Œì´ outputìœ¼ë¡œ&lt;/p&gt;
&lt;p&gt;ëª¨ë“  time stepì—ì„œ ê°™ì€ parameter Wë¥¼ ê³µìœ í•œë‹¤&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<br/><h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><p>ì„œë¡œë‹¤ë¥¸ time stepì—ì„œ ë“¤ì–´ì˜¤ëŠ” ì…ë ¥ ë°ì´í„°ë¥¼ ì²˜ë¦¬í• ë•Œ, ë§¤ë²ˆ ë°˜ë³µë˜ëŠ” ë™ì¼í•œ rnn moduleì„ í˜¸ì¶œí•œë‹¤.<img src="/images/image-20210216103443317.png" alt="image-20210216103443317"></p><p><img src="/images/image-20210216103929384.png" alt="image-20210216103929384"></p><p>ê° ë‹¨ì–´ë³„ë¡œ í’ˆì‚¬ë¥¼ ì˜ˆì¸¡í•´ì•¼ ë˜ëŠ” ê²½ìš° -&gt; ë§¤ time stepë§ˆë‹¤ yë¥¼ outputìœ¼ë¡œ</p><p>ì–´ë– í•œ ë¬¸ì¥ì˜ ê¸ë¶€ì •ì„ íŒë³„í•˜ëŠ” ê²½ìš° -&gt; ìµœì¢… time stepì˜ yë§Œì´ outputìœ¼ë¡œ</p><p>ëª¨ë“  time stepì—ì„œ ê°™ì€ parameter Wë¥¼ ê³µìœ í•œë‹¤</p><span id="more"></span><br/><p>ì£¼ì–´ì§„ vectorê°€ 3ì°¨ì›ì˜ ì…ë ¥ë²¡í„°ë¡œ ì£¼ì–´ì¡Œì„ë•Œ h<del>t-1</del>ì€ 2ì°¨ì›ì´ë¼ê³  ê°€ì •í•˜ì </p><p>x<del>t</del>ì™€ h<del>t-1</del>ë¥¼ ê°™ì´ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ì„œ f<del>W</del>ì— ë„£ì–´ì£¼ë©´, h<del>t</del>ê°€ ë‚˜ì˜¤ê²Œ ëœë‹¤<img src="/images/image-20210216111255186.png" alt="image-20210216111255186"></p><p>í˜„ì¬ timestep tì—ì„œì¶”ê°€ì ì¸ outputlayerë¥¼ ë§Œë“¤ê³  h<del>t</del>ì— W<del>hy</del>ë¥¼ ê³±í•´ì„œ y<del>t</del>ë¥¼ ì–»ì–´ë‚¸ë‹¤.</p><h2 id="Types-of-RNN"><a href="#Types-of-RNN" class="headerlink" title="Types of RNN"></a>Types of RNN</h2><p><strong>One-to-one</strong></p><p>ì…ì¶œë ¥ ëª¨ë‘ê°€ sequence dataì¸ ê²½ìš°ì— ì…ì¶œë ¥ì´ ë‹¨ 1ê°œì¸</p><p><strong>one-to-many</strong></p><p>image captioningì—ì„œ ì´ëŸ¬í•œ êµ¬ì¡°ë¥¼ ëˆë‹¤. </p><p>ì´ˆê¸°ì— ì…ë ¥ì´ í•œë²ˆ ë“¤ì–´ê°€ê³  ì´í›„ ì…ë ¥ìœ¼ë¡œëŠ” 0ìœ¼ë¡œ ì±„ì›Œì§„ tensorë¥¼ ì…ë ¥ìœ¼ë¡œ ì£¼ê²Œëœë‹¤</p><p><strong>many-to-one</strong></p><p>ìµœì¢…ê°’ì„ ë§ˆì§€ë§‰ì—ì„œì•¼ ë‚´ì£¼ëŠ”</p><p>ex) I love movieì—ì„œ RNNì´ ì²˜ë¦¬í•œí›„ ë§ˆì§€ë§‰ì˜ h<del>t</del>ë¥¼ ë´„ìœ¼ë¡œì„œ ê¸ë¶€ì •ì„ ì˜ˆì¸¡í•˜ê²Œ ëœë‹¤. ê¸¸ì´ê°€ ë‹¬ë¼ì§„ë‹¤ë©´ RNN CELLì´ ê·¸ë§Œí¼ í™•ì¥ì´ëœë‹¤</p><p><strong>many-to-many</strong></p><ol><li>ex) machine translation</li></ol><img src="/images/image-20210216120729609.png" alt="image-20210216120729609" style="zoom:50%;" /><ol start="2"><li>Ex) POS, vidioì˜ frameì´ sequenceëŒ€ë¡œ ì£¼ì–´ì§ˆë•Œ</li></ol><h2 id="Character-level-Language-Model"><a href="#Character-level-Language-Model" class="headerlink" title="Character-level Language Model"></a>Character-level Language Model</h2><ul><li>Example of training sequence â€œhelloâ€</li><li>vocab = [h,e,l,o]</li><li>ê°ê°ì˜ characterì€ one-hot-vectorë¡œ í‘œí˜„ì´ ê°€ëŠ¥í•˜ë‹¤</li></ul><img src="/images/image-20210216121012818.png" alt="image-20210216121012818" style="zoom:50%;" /><h2 id="Back-propagation-through-time-BPTT"><a href="#Back-propagation-through-time-BPTT" class="headerlink" title="Back propagation through time (BPTT)"></a>Back propagation through time (BPTT)</h2><p>Whh,Why,Wxh ì™€ ê°™ì€ parameterë“¤ì„ í•™ìŠµí•œë‹¤</p><p>sequenceì „ì²´ë¥¼ í•œë²ˆì— í•™ìŠµí•˜ê¸°ì—ëŠ” physicalì ì¸ í•œê³„ê°€ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì— êµ°ë°êµ°ë° ì§¤ë¼ì„œ ì œí•œëœ ê¸¸ì´ì˜ sequenc ë§Œìœ¼ë¡œ í•™ìŠµì„ ì§„í–‰í•œë‹¤</p><p>ë§¤  time stepë§ˆë‹¤ hidden state vectorê°€ ê±°ì˜ ëª¨ë“  ì •ë³´ë¥¼ ë‹´ê³  ìˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ë§Œì•½ì— hidden stateì˜ ì°¨ì›ì´ 3ì°¨ì›ì´ë¼ë©´, ìš°ë¦¬ê°€ ì›í•˜ëŠ” ì •ë³´ê°€ ê·¸ì¤‘ ì–´ëŠ nodeì— ë‹´ê²¨ì ¸ ìˆì„ê¹Œ? ì´ê±¸ ì—­ì¶”ì . ì²«ë²ˆì§¸ htì˜ nodeë¥¼ ê³ ì •í•´ ë†“ê³  ì´í›„ì˜ ë³€í™”ë“¤ì„ ë´„</p><br/><p>ì •ì‘ ì§€ê¸ˆê¹Œì§€ ë°°ìš´ vanila RNNì€ ì˜ í™œìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. ì´ìœ ëŠ” ë§Œì•½ ê¸´ê±°ë¦¬ì— ìˆëŠ” ì •ë³´ê°€ ë§¤ìš° ì¤‘ìš”í•  ê²½ìš° back propagtionìœ¼ë¡œ êµ¬í•´ì§€ê¸° ë•Œë¬¸ì— gradient vanishingì´ë‚˜ gradient explodeê°€ ì¼ì–´ë‚˜ê²Œ ëœë‹¤. </p><p><img src="/images/image-20210216124337509.png" alt="image-20210216124337509"></p><p>gradientê°’ì´ ì¦í­ë˜ê³ ìˆë‹¤</p><br/><h1 id="LSTM-amp-GRU"><a href="#LSTM-amp-GRU" class="headerlink" title="LSTM &amp; GRU"></a>LSTM &amp; GRU</h1><h2 id="Long-short-term-Memory"><a href="#Long-short-term-Memory" class="headerlink" title="Long short-term Memory"></a>Long short-term Memory</h2><p>ë³´ë‹¤ íš¨ê³¼ì ìœ¼ë¡œ  long term dependencyë¥¼ ì²˜ë¦¬í• ìˆ˜ ìˆê²Œë”í•˜ê¸° ìœ„í•´</p><p>h<del>t</del>ë¥¼ ë‹¨ê¸° ê¸°ì–µì†Œìë¡œ ìƒê°í•  ìˆ˜ ìˆìœ¼ë©°, ì´ëŸ¬í•œ ë‹¨ê¸°ê¸°ì–µì„ ì–¼ë§ˆë‚˜ ê¸¸ê²Œ ëŒê³ ê°ˆ ê²ƒì´ì§€ë¥¼ íŒë³„í•´ì£¼ëŠ” ì—­í• ë“¤ì„ ê°€ì§„ gateë“¤ë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤</p><p>ì „ time stepì—ì„œ ë„˜ì–´ì˜¤ëŠ” ì •ë³´ê°€ 2ê°€ì§€ì˜ ì„œë¡œë‹¤ë¥¸ vectorê°€ ë“¤ì–´ì˜¤ê²Œ ëœë‹¤.</p><p>ìœ„ì— ë“¤ì–´ì˜¤ëŠ” vector : C<del>t</del></p><p>ì•„ë˜ìª½ì— ë“¤ì–´ì˜¤ëŠ” vecor : h<del>t</del></p><p>Ã<img src="/images/image-20210216125806943.png" alt="image-20210216125806943"></p><p>C<del>t-1</del> ì´ì „ cell stateì™€ ì´ì „ stateì˜ hidden stateë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ í˜„ì¬ì˜ csì™€ ssë¥¼ ë‚´ì¤€ë‹¤. Hidden state vectorì€ cell state vectorì¤‘ì— ë…¸ì¶œë˜ëŠ” ì •ë³´ë¥¼ ë‹´ì€, í•œë²ˆ í•„í„°ë§ ëœ vectorì´ë‹¤.</p><p><img src="/images/image-20210216130159755.png" alt="image-20210216130159755"></p><p>ì—¬ê¸°ì„œ sigmoidì˜ ê²°ê³¼ì™€ ê³±í•´ì§€ë©´ ì–¼ë§ˆë§Œí¼ ì´ì „ì˜ ì›ë˜ê°’ì„ ë°˜ì˜í• ì§€ë¥¼ ê²°ì •í•˜ëŠ” ì—­í• ì„ í•œë‹¤. ë§ˆì§€ë§‰ tanhë¥¼ í†µí•´ ë‚˜ì˜¤ëŠ” ê°’ì€ í˜„ì¬ time stepì—ì„œ LSTMì—ì„œ ê³„ì‚°ë˜ëŠ” ìœ ì˜ë¯¸í•œ ì •ë³´ë¼ê³  ìƒê°í•  ìˆ˜ ìˆë‹¤.</p><ol><li><p>Forget gate</p><p><img src="/images/image-20210216131518759.png" alt="image-20210216131518759"></p></li></ol><p>ìœ„ë¥¼ ë³´ë©´ ì´ì „ì˜ hidden stateì™€ í˜„ì¬ì˜ x<del>t</del>ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ sigmoid ì ìš©í›„ 3ì°¨ì›ì˜ vectorê°€ ë‚˜ì˜¤ê²Œ ë˜ì—ˆë‹¤. ì´ë ‡ê²Œ ë‚˜ì˜¨ vectorì™€ ì´ì „ì˜ cell stateì˜ element wise productë¥¼ í•´ì£¼ì–´ì„œ ì´ì „ì˜ cell stateë¥¼ ì–¼ë§ˆë§Œí¼ ë°˜ì˜í• ì§€ë¥¼ ê²Œì‚°í•´ ì£¼ì—ˆë‹¤.</p><ol start="2"><li>Gate gate</li></ol><p><img src="/images/image-20210216132213172.png" alt="image-20210216132213172"></p><p>C<del>t</del>ì— ë”í•´ì£¼ì–´ì•¼ í•˜ëŠ” ê°’ì„ ë°”ë¡œ ë”í•´ì£¼ì§€ ì•Šê³  i<del>t</del>ë¥¼ ê³±í•´ì„œ ë”í•´ì¤€ë‹¤</p><ol start="3"><li>Output gate</li></ol><p><img src="/images/image-20210216132521862.png" alt="image-20210216132521862"></p><p>ì´ì œ cell state vector C<del>t</del>ë¡œ hidden state vector h<del>t</del>ë¥¼ ë§Œë“¤ì–´ì¤€ë‹¤. ì•ì„œ sigmoidë¥¼  ì ìš©í•œ ê°’ë˜í•œ tanhë¥¼ ê±°ì¹œ Celll stateì— ê³±í•œê°’ì— ê³±í•´ì£¼ì–´ ì ì ˆí•œ ë¹„ìœ¨ë§Œí¼ ê°’ì„ ì‘ê²Œ ë§Œë“¤ì–´ì£¼ì–´ ìµœì¢…ì ì¸ h<del>t</del>ë¥¼ ë§Œë“¤ì–´ì£¼ê²Œ ëœë‹¤.</p><p>h<del>t</del>ëŠ” ë‹¤ìŒ rnnì˜ hidden stateë¡œ ë“¤ì–´ê°€ëŠ” ë™ì‹œì— í˜„ì¬ time stepì—ì„œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í• ë•Œ ì´ê±¸ output layerì— ë„˜ê²¨ì£¼ì–´ ì˜ˆì¸¡ê°’ì„ ìƒì„±í•´ ë‚¸ë‹¤</p><h2 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h2><p>LSTMì—ì„œ 2ê°€ì§€ ì¢…ë¥˜ì˜ vectorë¡œ ì¡´ì¬í•˜ë˜ cell stateì™€ hidden state vectorë¥¼ ì¼ì›í•˜ í•˜ì—¬ í•˜ë‚˜ì˜ vectorë§Œì´ ì¡´ì¬í•˜ê²Œ í•œë‹¤ëŠ”ê²Œ íŠ¹ì§•ì´ë‹¤. í•˜ì§€ë§Œ ì „ì²´ì ì¸ ë™ì‘ì›ë¦¬ëŠ” ê±°ì˜ ë¹„ìŠ·</p><p><img src="/images/image-20210216142225794.png" alt="image-20210216142225794"></p><p>forget gateëŒ€ì‹  1-z<del>t</del>ë¥¼ ì‚¬ìš©, i<del>t</del>ëŒ€ì‹  z<del>t</del>ë¥¼ ì‚¬ìš©</p><p>input gateê°€ ì»¤ì§ˆìˆ˜ë¡ forget gateì˜ ê°’ì´ ì ì°¨ ì‘ì•„ì§€ê²Œ ë˜ì–´ ê²°ê³¼ì ìœ¼ë¡œ ì´ì „ hidden state vectorë¥¼ ë” ì ê²Œ ë°˜ì˜í•˜ëŠ” ê²ƒì´ê³ , vice versa</p><ol><li>hidden stateë¥¼ ì¼ì›í™” í•˜ì˜€ë‹¤</li><li>2ê°œì˜ ë…ë¦½ëœ gateë¥¼ í†µí•˜ì—¬ ë™ì‘ë˜ì—ˆë˜ modelì„ í•˜ë‚˜ì˜ gateë§Œìœ¼ë¡œ ì¤„ì—¬ ê³„ì‚°ëŸ‰ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì˜€ë‹¤.</li></ol><p>ì •ë³´ë¥¼ ì£¼ë¡œë‹´ëŠ” cell stateê°€ updateë˜ëŠ” ê³¼ì •ì´ í–‰ë ¬ì˜ ê³„ì†ì ì¸ ê³±ì˜ ì—°ì‚°ì´ ì•„ë‹ˆë¼ ê·¸ë•Œê·¸ë•Œ ì„œë¡œë‹¤ë¥¸ gateë¥¼ ê±°ì³ê°€ë©° updateë˜ê¸° ë•Œë¬¸ì— gradient vanishingì´ ì‚¬ë¼ì§„ë‹¤. ë§ì…ˆì—°ì‚°ì€ ì´ì „ì˜ stateë¥¼ ë³µì‚¬í•´ì£¼ì–´ gradientë¥¼ ìœ ì§€í•˜ëŠ” ì—­í• ì„ í•œë‹¤ê³  ë³¼ ìˆ˜ë„ ìˆë‹¤. RNNì€ ë‹¤ì–‘í•œ ê¸¸ì´ë¥¼ ê°€ì§ˆìˆ˜ ìˆëŠ” ìœ ì—°í•œ í˜•íƒœì˜ deep learningêµ¬ì¡°.</p>]]></content:encoded>
      
      
      <category domain="https://jo-member.github.io/categories/Boostcamp/">Boostcamp</category>
      
      
      <category domain="https://jo-member.github.io/tags/RNN/">RNN</category>
      
      <category domain="https://jo-member.github.io/tags/NLP/">NLP</category>
      
      
      <comments>https://jo-member.github.io/2021/02/16/2021-02-15-Boostcamp16.1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Improving Language Understanding by Generative Pre-Training</title>
      <link>https://jo-member.github.io/2021/02/14/2021-02-14-GPT/</link>
      <guid>https://jo-member.github.io/2021/02/14/2021-02-14-GPT/</guid>
      <pubDate>Sat, 13 Feb 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;br/&gt;

&lt;p&gt;ì´ë²ˆì—ëŠ” openaiì—ì„œ ë°œí‘œí•œ ë…¼ë¬¸ì¸ GPTë¥¼ reviewí•´ë³´ê² ë‹¤&lt;/p&gt;
&lt;p&gt;GPT3ëŠ” ì´ì „ì— reviewí•œ transformerêµ¬ì¡°ë¥¼ í™œìš©í•˜ì—¬ Language understandingì„ íš¨ê³¼ì ìœ¼ë¡œ ë§Œë“¤ì—ˆë‹¤.&lt;/p&gt;
&lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;br/&gt;

&lt;p&gt;ìì—°ì–´ë¥¼ ì´í•´ëŠ” textì¶”ë¡ , ì§ˆë¬¸ì— ëŒ€í•œ ëŒ€ë‹µ, ì˜ë¯¸ì˜ ìœ ì‚¬ì„± í‰ê°€, ë¬¸ì„œë¶„ë¥˜ë“±ì„ í¬í•¨í•˜ê³  ìˆë‹¤. ë¼ë²¨ë§ ë˜ì§€ ì•Šì€ textë“¤ì„ ë§¤ìš° ë„˜ì²˜ë‚˜ì§€ë§Œ, íŠ¹ì • taskì˜ í•™ìŠµì„ ìœ„í•´ labedëœ textë“¤ì€ ë§¤ìš° ì ê¸°ë•Œë¬¸ì— ì¢‹ì€ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ”ê²ƒì€ ë§¤ìš° í˜ë“¤ë‹¤.  Language ëª¨ë¸ì„ unlabledëœ textë¡œ &lt;em&gt;generative pretrain&lt;/em&gt;ì„ í•œì´í›„ ê°ê°ì˜ taskì— ë§ê²Œ fine-tunningì„ í•˜ì˜€ë‹¤.  ì´ëŸ¬í•œ ë§ì€ unlabed textë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•˜ì˜€ë‹¤. ì´ì „ì˜ ì—°êµ¬ì™€ëŠ” ë‹¬ë¦¬,í•„ìš”í•œ taskì— fine-tuningí•˜ì—¬ ì‘ìš©í•˜ëŠ” ê²ƒì´ ë§¤ìš° íš¨ê³¼ì ì´ë‹¤.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<br/><p>ì´ë²ˆì—ëŠ” openaiì—ì„œ ë°œí‘œí•œ ë…¼ë¬¸ì¸ GPTë¥¼ reviewí•´ë³´ê² ë‹¤</p><p>GPT3ëŠ” ì´ì „ì— reviewí•œ transformerêµ¬ì¡°ë¥¼ í™œìš©í•˜ì—¬ Language understandingì„ íš¨ê³¼ì ìœ¼ë¡œ ë§Œë“¤ì—ˆë‹¤.</p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><br/><p>ìì—°ì–´ë¥¼ ì´í•´ëŠ” textì¶”ë¡ , ì§ˆë¬¸ì— ëŒ€í•œ ëŒ€ë‹µ, ì˜ë¯¸ì˜ ìœ ì‚¬ì„± í‰ê°€, ë¬¸ì„œë¶„ë¥˜ë“±ì„ í¬í•¨í•˜ê³  ìˆë‹¤. ë¼ë²¨ë§ ë˜ì§€ ì•Šì€ textë“¤ì„ ë§¤ìš° ë„˜ì²˜ë‚˜ì§€ë§Œ, íŠ¹ì • taskì˜ í•™ìŠµì„ ìœ„í•´ labedëœ textë“¤ì€ ë§¤ìš° ì ê¸°ë•Œë¬¸ì— ì¢‹ì€ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ”ê²ƒì€ ë§¤ìš° í˜ë“¤ë‹¤.  Language ëª¨ë¸ì„ unlabledëœ textë¡œ <em>generative pretrain</em>ì„ í•œì´í›„ ê°ê°ì˜ taskì— ë§ê²Œ fine-tunningì„ í•˜ì˜€ë‹¤.  ì´ëŸ¬í•œ ë§ì€ unlabed textë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµí•˜ì˜€ë‹¤. ì´ì „ì˜ ì—°êµ¬ì™€ëŠ” ë‹¬ë¦¬,í•„ìš”í•œ taskì— fine-tuningí•˜ì—¬ ì‘ìš©í•˜ëŠ” ê²ƒì´ ë§¤ìš° íš¨ê³¼ì ì´ë‹¤.</p><span id="more"></span><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><br/><p>Raw textë¥¼ ì‚¬ìš©í•˜ì—¬ íš¨ê³¼ì ì¸ NLP í•™ìŠµì„ í•˜ê¸°ìœ„í•´ì„œëŠ” ì§€ë„í•™ìŠµì— ëŒ€í•œ ì˜ì¡´ì„±ì„ ì™„í™”í•´ì•¼ í•œë‹¤. ë§ì€ ë”¥ëŸ¬ë‹ ë°©ë²•ë“¤ì€ labeledëœ dataë¥¼ ì‚¬ìš©í•´ì•¼ í•´ì„œ í•œê³„ê°€ ì¡´ì¬í•œë‹¤. ì´ëŸ¬í•œ ìƒí™©ì—ì„œ unlabedëœ dataëŠ” ì‹œê°„ê³¼ ë…¸ë ¥ì´ í•„ìš”í•œ annotationì„ ëª¨ìœ¼ëŠ” ì‘ì—…ë“¤ì„ ëŒ€ì²´í•  ìˆ˜ ìˆë‹¤. ë§Œì•½ ê³ ë ¤ê°€ëŠ¥í•œ ì§€ë„ê°€ ê°€ëŠ¥í•œ ìƒí™©ì´ë¼ë©´, unsupervised ë°©ë²•ì€ modelì˜ ì„±ëŠ¥ì„ ì¦ê°€ì‹œí‚¬ ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ ë°©ì‹ì€ pretrainedëœ word embeddingì„ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ë†’ì´ëŠ”ê²ƒê³¼ ë¹„ìŠ·í•œ ì´ìœ ì´ë‹¤.</p><p>unlabedëœ dataë¡œ word-levelì˜ ì •ë³´ë³´ë‹¤ ë§ì€ ì •ë³´ë¥¼ í™œìš©í•˜ëŠ”ê²ƒì€ 2ê°€ì§€ ì´ìœ ì—ì„œ ë§¤ìš° ì–´ë µë‹¤</p><ol><li>ì–´ë– í•œ ì¢…ë¥˜ì˜ optimization objectiveê°€ ê°€ì¥ íš¨ê³¼ì ìœ¼ë¡œ textë¥¼ í‘œí˜„í• ìˆ˜ ìˆì„ê¹Œ ê°€ ë§¤ìš° unclearí•˜ë‹¤</li><li>ìš°ë¦¬ê°€ ì›í•˜ëŠ” íŠ¹ì • taskì— íš¨ê³¼ì ìœ¼ë¡œ ì ìš©í•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì˜ê²¬ì´ ì¼ì¹˜ê°€ ë˜ì§• ì•Šì•˜ë‹¤. í˜„ì¬ ì¡´ì¬í•˜ëŠ” ë°©ë²•ì€ modelì— íŠ¹ì •í•œ task-specificí•œ ë³€í™”ë¥¼ ê°€í•˜ëŠ” ê²ƒê³¼, ë³µì¡í•œ í•™ìŠµë°©ë²•,ê·¸ë¦¬ê³  í•™ìŠµì„ ë„ì™€ì£¼ëŠ” ëª‡ëª‡ learning objectiveë“¤ì„ ë„£ì–´ì£¼ëŠ”, ì´ëŸ¬í•œ ë°©ë²•ë“¤ì˜ combinationì´ë‹¤</li></ol><p>ì´ëŸ¬í•œ ë¶ˆí™•ì‹¤ì„±ì€ language processingì—ì„œì˜ íš¨ê³¼ì ì¸ semi-supervised learningì„ ë°œì „ì‹œí‚¤ê¸° í˜ë“¤ê²Œ ë§Œë“ ë‹¤.</p><br/><p>ì´ ë…¼ë¬¸ì—ì„œëŠ” unsupervised pre-trainingê³¼ supervised fine-tunningì„ ì¡°í•©í•œ ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ semi-supervised approachë¥¼ í•˜ì˜€ë‹¤. ëª©ì ì€ ê°€ì¥ ë³´í¸ì ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ì•½ê°„ì˜ ì‘ìš©ìœ¼ë¡œ ë‹¤ì–‘í•œ ë¶„ì•¼ì— ì ìš©ì‹œí‚¤ëŠ”ê²ƒì´ë‹¤. </p><p>2-stageë¡œ ë‚˜ëˆ„ì–´ trainí•˜ì˜€ë‹¤</p><ol><li>ì´ˆê¸° parameterë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•´ unlabeled dataë¥¼ ì‚¬ìš©í•˜ì—¬ pre-train í•˜ì˜€ë‹¤ / with transformer</li><li>ìš°ë¦¬ëŠ” ì´ parameterë“¤ì„ íŠ¹ì •í•œ taskì— ë§ëŠ” supervised objective í•™ìŠµì— ì‚¬ìš©í•˜ì˜€ë‹¤.</li></ol><p>ë˜í•œ modelì—ì„œ <em>Transformer</em>ë¥¼ ì‚¬ìš©í•˜ì—¬ long-term dependenciesë¥¼ í•´ê²°í•˜ì˜€ë‹¤.</p><br/><h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h2><p><strong>Semi-supervised learning for NLP</strong></p><p>ìš°ë¦¬ì˜ workëŠ” Semi-supervied learningì˜ ë²”ì£¼ì•ˆì—ìˆë‹¤. ì´ sslì€ sequence labeling, text ë¶„ë¥˜ë“±ì— ì“°ì´ë©´ì„œ í° ê´€ì‹¬ì„ ë°›ê³  ìˆë‹¤. ê°€ì¥ ì´ˆê¸°ì—ëŠ” unlabeled dataë¥¼ supervised learningì˜ featureë¡œ ì‚¬ìš©í•˜ì—¬ wordë‚˜ phrase levelì˜ í†µê³„ë¥¼ ê³„ì‚°í•˜ëŠ”ë° ì‚¬ìš©ë˜ì—ˆë‹¤. ìµœê·¼ ëª‡ë…„ë™ì•ˆ word-embeddingì´ ì–¼ë§ˆë‚˜ ì¢‹ì€ì§€ ë°í˜€ëƒˆë‹¤. ì´ëŸ¬í•œ ì ‘ê·¼ì€ word-levelì˜ ì •ë³´ë¥¼ íŠ¹ì •í•œ high-levelì— ë§ì¶”ì–´ ì¤€ë‹¤. ìµœê·¼ì—ëŠ” word-levelì´ ì•„ë‹Œ phraseë‚˜ sentence levelì˜ embeddingì„ ì‚¬ìš©í•˜ì—¬ textë¥¼ ë‹¤ì–‘í•œ target taskì˜ vector representationì„ ë‚˜íƒ€ë‚´ ì£¼ì—ˆë‹¤.</p><br/><p><strong>Unsupervised pre-training</strong></p><p>Unsupervised pre-trainingì€ supervised learningì„ ë°”ê¾¸ëŠ”ê±° ë³´ë‹¤ëŠ” ì¢‹ì€ initializationì„ ì°¾ëŠ”ê²Œ ëª©ì ì´ë‹¤. ê°ê°ì˜ ì—°êµ¬ë“¤ì€ image classificationê³¼ regression taskì˜ ê¸°ìˆ ì´ ì‚¬ìš©ë˜ì—ˆë‹¤. Pre-trainingì€ ì •ê·œí™” ê³¼ì •ì—ì„œ generalizationì„±ëŠ¥ì„ ì˜¬ë ¤ì¤€ë‹¤. </p><p>ìš°ë¦¬ì˜ ì—°êµ¬ëŠ” language modelingìœ¼ë¡œ modelì„ pre-trainí•œí›„ taskì— ë§ê²Œ fine-tuningí•´ì£¼ëŠ” ê²ƒì´ë‹¤. Pre-trainingì´ ì–¸ì–´ì ì¸ ì •ë³´ë¥¼ ì˜ ì¡ì•„ë‚¼ìˆ˜ ìˆì§€ë§Œ,ì´ì „ì—°êµ¬ì—ì„œ ì‚¬ìš©ëœ LSTMì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ê¸´ dataë¥¼ í•´ì„í•˜ì§€ ëª»í•œë‹¤ëŠ” ë‹¨ì ì´ ì¡´ì¬í•œë‹¤. ë”°ë¼ì„œ ìš°ë¦¬ëŠ” Transformerë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤.ë˜ë‹¤ë¥¸ ì—°êµ¬ì—ì„œëŠ” ëª‡ëª‡ ë³´ì¡°ì ì¸ featureë“¤ì„ ì‚½ì…í•´ì£¼ì–´ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ì§€ë§Œ, ì´ëŠ” ìƒˆë¡œìš´ parameterì˜ ì¦ê°€ë¥¼ ì•¼ê¸°í•œë‹¤. ìš°ë¦¬ì˜ GPTëŠ” transferê³¼ì •ì—ì„œ ìµœì†Œí•œì˜ ìˆ˜ì •ë§Œì„ í•„ìš”ë¡œ í•œë‹¤.</p><br/><p><strong>Auxiliary training objectives</strong></p><p>ì—¬ëŸ¬ ë³´ì¡°ì ì¸ unsupervised trainingì€ semi-supervised learningì˜ ëŒ€ì±„ì ì¸ í˜•íƒœì´ë‹¤. ì´ì „ì˜ ì—°êµ¬ì—ì„œëŠ” ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ ë³´ì¡°ì ì¸ NLPë°©ë²•ë¡ (POS tagging, chunking,ë“±ë“±ë“±)ì„ ì‚¬ìš©í•˜ì˜€ë‹¤. ìµœê·¼ ë˜ë‹¤ë¥¸ ì—°êµ¬ëŠ” ë³´ì¡°ì ì¸ language modelë¥¼ ì¶”ê°€í•˜ì—¬ sequence labelingì˜ ì„±ëŠ¥í–¥ìƒì„ ì´ì•¼ê¸° í•˜ì˜€ë‹¤. </p><br/><h2 id="3-Framework"><a href="#3-Framework" class="headerlink" title="3. Framework"></a>3. Framework</h2><p>í•™ìŠµê³¼ì •ì€ 2ê°œì˜ stageë¡œ ë‚˜ëˆ„ì–´ì ¸ ìˆë‹¤</p><ol><li>unlabeledëœ í° ë§ë­‰ì¹˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì¥ ë²”ìš©ì ì¸ language modelì„ í•™ìŠµí•˜ëŠ” stage</li><li>ì´í›„ labeled dataë¥¼ ì‚¬ìš©í•œ fine-tuning stage</li></ol><br/><p><strong>3.1 Unsupervised pre-training</strong></p><p>unsupervisedì˜ tokenë“¤ = <img src="/images/image-20210214174726972.png" alt="image-20210214174726972">ì´ ì£¼ì–´ì§€ê³ , ì´ì–´ì§€ëŠ” likelihoodë¥¼ maximizeí•˜ê¸°ìœ„í•´ ë³´í¸ì ì¸ language modelì„ ì‚¬ìš©í•œë‹¤.</p><img src="/images/image-20210214174902969.png" alt="image-20210214174902969" style="zoom:150%;" /><p>këŠ” contextì˜ sizeì´ê³ , conditional prob PëŠ” NNì„ ì‚¬ìš©í•˜ì—¬ modeled</p><p>ì´ë“¤ì€ ëª¨ë‘ SGDë¥¼ ì‚¬ìš©í•˜ì—¬ trainingí–ˆë‹¤.</p><p><em>multi-layer Transformer decoder</em>ë¥¼ ì‚¬ìš©í–ˆë‹¤.</p><p>ì´ modelì€ input context tokensì— multi-headed self-attentionì„ í™œìš©í•˜ì˜€ê³ , ì´í›„ì— position-wise feedforward layerë¥¼ ì ìš©í•˜ì—¬ target tokenì—ëŒ€í•œ output distributionì„ êµ¬í•œë‹¤.</p><p><img src="/images/image-20210214180732689.png" alt="image-20210214180732689"></p><p>UëŠ” tokenì˜ context vectorì´ê³ , nì€ layerì˜ ìˆ«ì, W<del>e</del>ëŠ” token embedding matrix, W<del>p</del>ëŠ” position embedding matrixì´ë‹¤.</p><br/><p><strong>3.2 Supervised fine-tuning</strong></p><p>modelì„ trainí•œí›„, supervised target testì— ë§ì¶”ì–´ì„œ parameterë¥¼ ì ìš©í•œë‹¤. labeledëœ dataset C(ê°ê°ì€ input tokenì˜ sequenceë¡œ ì´ë£¨ì–´ì§ ((x^1^,â€¦,x^m^) and label y )) </p><p>Inputì€ pre-trainedëœ modelì„ í†µê³¼í•˜ì—¬ ìµœì¢… transformer blockì˜ activationì¸ h<del>l</del>^m^ì„ ì–»ì–´ë‚´ê³ , ì´í›„ì— linear output layerì— W<del>y</del>ì™€ í•¨ê»˜ ë“¤ì–´ê°„ë‹¤. </p><p><img src="/images/image-20210214181504691.png" alt="image-20210214181504691"></p><p>ì´ëŠ” ì´í›„ì˜ objectiveë¥¼ maximizeí•˜ê²Œ í•œë‹¤.</p><p><img src="/images/image-20210214181541269.png" alt="image-20210214181541269"></p><p>ë³´ì¡°ì ì¸ ì¥ì¹˜ë¡œ language modelingì„ ì‚¬ìš©í•˜ì—¬ fine-tuningì„ í•˜ëŠ”ê²ƒì€ (1) generalizationì„±ëŠ¥ì„ ë†’íŒë‹¤ (2) ìˆ˜ë ´ì†ë„ë¥¼ ë†’íŒë‹¤. ìš°ë¦¬ëŠ” ì•„ë˜ì˜ objectiveë¥¼ optimizeí•œë‹¤</p><p><img src="/images/image-20210214181938559.png" alt="image-20210214181938559"></p><p>Fine-tuningì¤‘ì— ìœ ì¼í•œ extra parameterì€ W<del>y</del>ì™€ êµ¬ë¶„tokenì„ ìœ„í•œ embeddingì´ë‹¤.</p><p><img src="/images/image-20210214182200590.png" alt="image-20210214182200590"></p><p><strong>3.3 Task-specific input transformations</strong></p><p>text classificationê°€ ê°™ì€ ëª‡ëª‡ ë¶„ì•¼ì—ì„œ, ìœ„ì—ì„œ ë¬˜ì‚¬í–ˆë˜ëŒ€ë¡œ ìš°ë¦¬ì˜ modelì„ fine-tuneí•  ìˆ˜ ìˆì—ˆë‹¤. ì§ˆì˜ì‘ë‹µê³¼, textual entailmentì™€ ê°™ì€ ë¬¸ì œì—ëŠ” inputì„ ordered sentence pairs, triplets of document, question, answerìœ¼ë¡œ í•´ì£¼ì—ˆë‹¤. ìš°ë¦¬ì˜ pre-trained modelì´ ì—°ì†ì ì¸ sequenceì—ì„œ í•™ìŠµë˜ì—ˆê¸° ë•Œë¬¸ì—, ì´ëŸ¬í•œ ë¬¸ì œë“¤ì—ëŠ” ì•½ê°„ì˜ ë§ì¶¤ ìˆ˜ì •ì´ í•„ìš”í•˜ë‹¤.  ì´ì „ì˜ ì—°êµ¬ë“¤ì€ transffered representationìœ„ì— íŠ¹ì • architectureë¥¼ ì‚½ì…í•˜ëŠ” í˜•íƒœë¡œ í•™ìŠµí•´ì™”ë‹¤. ì´ëŠ” ë§ì€ì–‘ì˜ cutomizationì´ í•„ìš”í•˜ë©° ì´ëŸ¬í•œ ì¶”ê°€ì ì¸ íŠ¹ì • architectureì—ëŠ” transfer learningì„ ì‚¬ìš©í•˜ì§€ ì•Šì•˜ë‹¤. ëŒ€ì‹  ìš°ë¦¬ëŠ” traveral-stple approach(inputì„ ì •ë ¬ëœ sequenceë¡œ ë§Œë“¤ì–´)ë¥¼ ì‚¬ìš©í•˜ì—¬ ìš°ë¦¬ì˜ pre-trained modelì´ í•™ìŠµí•  ìˆ˜ ìˆê²Œ í•˜ì˜€ë‹¤. ì´ëŸ¬í•œ inputì˜ ì¡°ì •ì€ ë¬¸ì œìƒí™©ì— ë”°ë¼ architectureì˜ í° ìˆ˜ì •ì„ í•˜ì§€ ì•Šì•„ë„ ë˜ê²Œ í•œë‹¤. ëª¨ë“  transformationì€ randomly initializedëœ start,ending tokenì„ í¬í•¨í•œë‹¤.</p><br/><ol><li>Textual entailment(ë¬¸ì¥ì˜ í¬í•¨ê´€ê³„) : ì „ì œ pì™€ ê°€ì„¤ h ì¤‘ê°„ì— delimiter token $ë¥¼ ì‚½ì…í•˜ì—¬ í•©ì³ì£¼ì—ˆë‹¤.</li><li>Similarity (ë¬¸ì¥ì˜ ìœ ì‚¬ë„ í‰ê°€) : ë‘ê°œì˜ ë¹„êµëŒ€ìƒì€ ìˆœì„œê°€ ë”±íˆ ì—†ë‹¤. í•œë§ˆë””ë¡œ ë™ë“±í•œ levelì—ì„œ ë¹„êµí•´ì•¼ ë˜ê¸° ë•Œë¬¸ì— ëª¨ë“  ê°€ëŠ¥í•œ ìˆœì„œë¥¼ ì‚¬ìš©í•˜ê³  transformerì´í›„ì— ë‚˜ì˜¤ëŠ”2ê°œì˜ h<del>l</del>^m^  ì„ í•©ì³ì¤€ë‹¤.</li><li>Question Answering and Commonsense Reasoning (ì§ˆì˜ì‘ë‹µ) : </li></ol><h2 id="3-Model-Atchitecture"><a href="#3-Model-Atchitecture" class="headerlink" title="3. Model Atchitecture"></a>3. Model Atchitecture</h2><br/><p>language model -&gt; labelì´ í•„ìš”ê°€ ì—†ë‹¤</p><p>ì£¼ì–´ì§„ ë‹¨ì–´ë“¤ì„ ê°€ì§€ê³  ë‹¤ìŒë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ”</p><ol><li><p>Generative model</p><p>Generative model</p><p>dataê°€ ë§ì•„ ì§ˆìˆ˜ë¡ ì •í™•ë„ê°€ ë†’ì•„ì§„ë‹¤</p></li><li><p>Discriminative model</p><p>íƒ€ì´íƒ€ë‹‰ê°™ì€</p><p>ë°ì´í„°ê°€ ë§ì§€ ì•Šì„ë•Œ íŒ¨í„´íŒŒì•…ì´ ì‰¬ì›Œì„œ ë§ì´ë“¤ ì‚¬ìš©í•œë‹¤</p><p>í•œì •ëœ dataì— ê³¼ì í•© ë˜ê¸°ê°€ ì‰½ë‹¤</p></li><li><p>sampleëœ dataë¡œëŠ” ì™œê³¡ëœ íŒë‹¨ì„ í•  ìˆ˜ ìˆë‹¤</p></li></ol><p>GPTëŠ” unlabeledëœ dataë¡œ</p><ol><li><p>Pretraining LM</p></li><li><p>finefuning</p><p>ë°ì´í„°ë§Œ taskê´€ë ¨ë°ì´í„°ë¡œ í•™ìŠµ modelì€ ê·¸ëŒ€ë¡œ</p></li></ol><p>Naural Language Inference -&gt; entailment contradictioníŒŒì•…</p><p>ì§ˆì˜ì‘ë‹µ</p><p>ë¹„ìŠ·í•œ ë¬¸ì¥ íŒë³„</p><p>ì£¼ì–´ì§„ ë¬¸ì¥ì„ ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ”</p><p>ë¹„ì§€ë„ í•™ìŠµ labelì´ ìˆëŠ” dataë¡œ fine tunningí•œë‹¤.</p><p>ê¸°ì¡´ language model í•™ìŠµ ê³µì‹ê³¼ ê°™ë‹¤</p><p>transformerì˜ decoderë¡œ êµ¬ì„±</p><p>layerì¶”ê°€ì—†ì´ pretrained LM</p><p>byte pair embeddingì„ ì‚¬ìš©í•˜ì˜€ë‹¤</p><p>ì‹ ì¡°ì–´ ì˜¤íƒˆìì— ì•½í•œ word embeddingì´ ì•„ë‹Œ</p><p>byte pair. â€”â€“&gt; hack,able, deep, learn, ing</p><p>ì´ëŸ°ì‹ìœ¼ë¡œ embeddingì„ í•˜ì˜€ë‹¤.</p><p>dataê°€ ì£¼ì–´ì¡Œì„ë–„</p>]]></content:encoded>
      
      
      <category domain="https://jo-member.github.io/categories/PaperReview/">PaperReview</category>
      
      
      <category domain="https://jo-member.github.io/tags/Transformer/">Transformer</category>
      
      <category domain="https://jo-member.github.io/tags/GPT/">GPT</category>
      
      <category domain="https://jo-member.github.io/tags/NLP/">NLP</category>
      
      
      <comments>https://jo-member.github.io/2021/02/14/2021-02-14-GPT/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Generative Models</title>
      <link>https://jo-member.github.io/2021/02/05/2021-02-05-Boostcamp15.1/</link>
      <guid>https://jo-member.github.io/2021/02/05/2021-02-05-Boostcamp15.1/</guid>
      <pubDate>Thu, 04 Feb 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;br/&gt;



&lt;h1 id=&quot;Generative-Models&quot;&gt;&lt;a href=&quot;#Generative-Models&quot; class=&quot;headerlink&quot; title=&quot;Generative Models&quot;&gt;&lt;/a&gt;Generative Models&lt;/h1&gt;&lt;br/&gt;

&lt;br/&gt;

&lt;ul&gt;
&lt;li&gt;What I can not create, I do not understand&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&quot;https://deepgenerativemodels.github.io/&quot;&gt;https://deepgenerativemodels.github.io/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;br/&gt;

&lt;ul&gt;
&lt;li&gt;What does it mean to learn a generative model&lt;/li&gt;
&lt;li&gt;generative modelì€ ë‹¨ìˆœíˆ ìƒì„±ëª¨ë¸ì´ ì•„ë‹ˆë‹¤ &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Suppose we have some images of dogs&lt;/p&gt;
&lt;p&gt;We want to learn a probability distribution p(x) such that&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Generation : If we sample x&lt;del&gt;new&lt;/del&gt; ~ p(x), x&lt;del&gt;new&lt;/del&gt; should look like a dog&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;implicit models&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Density estimation :p(x) should be high if x look like a dog (ì–´ë–¤ì´ë¯¸ì§€ì˜ í™•ë¥ ì„ ê³„ì‚°í•¨)&lt;/p&gt;
&lt;p&gt;ì´ê±´ ë§ˆì¹˜ image classification&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;explicit models&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Unsupervised representation learning &lt;/p&gt;
&lt;p&gt;íŠ¹ì • imageê°€ ì–´ë–¤ íŠ¹ì§•ì„ ê°€ì§€ê³ ìˆëŠ”ì§€ë¥¼ í•™ìŠµ&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
      
      
      
      <content:encoded><![CDATA[<br/><h1 id="Generative-Models"><a href="#Generative-Models" class="headerlink" title="Generative Models"></a>Generative Models</h1><br/><br/><ul><li>What I can not create, I do not understand</li></ul><p><a href="https://deepgenerativemodels.github.io/">https://deepgenerativemodels.github.io/</a></p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><br/><ul><li>What does it mean to learn a generative model</li><li>generative modelì€ ë‹¨ìˆœíˆ ìƒì„±ëª¨ë¸ì´ ì•„ë‹ˆë‹¤ </li></ul><p>Suppose we have some images of dogs</p><p>We want to learn a probability distribution p(x) such that</p><ul><li><p>Generation : If we sample x<del>new</del> ~ p(x), x<del>new</del> should look like a dog</p><ul><li>implicit models</li></ul></li><li><p>Density estimation :p(x) should be high if x look like a dog (ì–´ë–¤ì´ë¯¸ì§€ì˜ í™•ë¥ ì„ ê³„ì‚°í•¨)</p><p>ì´ê±´ ë§ˆì¹˜ image classification</p><ul><li>explicit models</li></ul></li><li><p>Unsupervised representation learning </p><p>íŠ¹ì • imageê°€ ì–´ë–¤ íŠ¹ì§•ì„ ê°€ì§€ê³ ìˆëŠ”ì§€ë¥¼ í•™ìŠµ</p></li></ul><span id="more"></span><h2 id="How-can-we-represent-p-x"><a href="#How-can-we-represent-p-x" class="headerlink" title="How can we represent p(x)??????"></a><strong>How can we represent p(x)??????</strong></h2><br/><ul><li><p>Bernoulli distribution</p><ul><li><p>D = {Heads, Tails}</p></li><li><p>Specify P(X = Head) = p, P(X = Tails) = (1-p)</p></li></ul></li><li><p>Categorical distribution</p></li></ul><p>ex) Modeling and RGB joint distribution</p><ul><li>(r,g,b) ~ p(R,G,B)</li><li>number of case = 256x256x256</li><li>parameters = 255x255x255 ê°œê°€ í•„ìš”</li></ul><p>í•˜ë‚˜ì˜ RGB pixelë§Œí•´ë„ parameterë¥¼ í‘œí˜„í•˜ë ¤ë©´ ì–´ë§ˆì–´ë§ˆí•œ ìˆ«ìì˜ parameterê°€ í•„ìš”í•˜ë‹¤</p><h3 id="Structure-Through-Independence"><a href="#Structure-Through-Independence" class="headerlink" title="Structure Through Independence"></a>Structure Through Independence</h3><p>What if X1,â€¦.,Xn are independent and binary pixels</p><p>p(x1,â€¦,xn) = p(x1)p(x2)â€¦p(xn)</p><p>possible state : 2^n^</p><p>parameter : nê°œë§Œ í•„ìš”</p><p>ë§Œì•½ ê°ê°ì˜ pixelì´ ë…ë¦½ì ì´ë¼ê³  ê°€ì •í•œë‹¤ë©´ ì´ë ‡ê²Œ parameterìˆ˜ê°€ ì¤„ì–´ë“ ë‹¤</p><p>ê·¼ë° ì´ê±´ ë„ˆë¬´ ë§ì´ ì•ˆëœë‹¤</p><p>ë”°ë¼ì„œ Independenceì™€ fully dependentì‚¬ì´ì˜ ì ˆì¶©ì•ˆ???</p><h3 id="Conditional-Independence"><a href="#Conditional-Independence" class="headerlink" title="Conditional Independence"></a>Conditional Independence</h3><p>Three Important Rule</p><p><img src="/images/image-20210205102341270.png" alt="image-20210205102341270"></p><p>nê°œì˜ joint distrubutionì„ nê°œì˜ conditional distributionìœ¼ë¡œ ë°”ê¾¸ê³ </p><p>zê°€ ì£¼ì–´ì¡Œì„ë•Œ x,yëŠ” independentí•˜ë‹¤ -&gt;ì´ê²Œ ê°€ì • ì™„ì „ xyê°€ independentí•œê²Œ ì•„ë‹ˆë¼ zê°€ ì£¼ì–´ì¡Œì„ë•Œ </p><p>yëŠ” ìƒê´€ì´ì—†ë‹¤ ì´ëŸ°ëŠë‚Œ</p><h3 id="Conditional-Independence-1"><a href="#Conditional-Independence-1" class="headerlink" title="Conditional Independence"></a>Conditional Independence</h3><p>Using the chain rule</p><p><img src="/images/image-20210205103330254.png" alt="image-20210205103330254"></p><p>ì´ ìˆ˜ì‹ ë„ì¶œì—ì„œ ì–´ë– í•œ ìˆ˜í•™ì ì¸ ê°€ì •ì´ ì—†ì´ chain ruleë§Œìœ¼ë¡œ êµ¬í•œ ìˆ˜ì‹ì´ë‹¤ ë”°ë¼ì„œ fully independentì™€ parameter ê°œìˆ˜ëŠ” ê°™ë‹¤</p><ul><li><p>p(x1) :1ê°œ</p></li><li><p>p(x2|x1) : 2ê°œ (one per for p(x2|x1 = 0) and p(x2|x1 = 1))</p></li><li><p>p(x3|x1,x2) : 4ê°œ</p></li><li><p>Hence 1+2+2^2^+â€¦+2^n-1^ = 2^n^-1</p></li></ul><p>i+1ë²ˆì¨° pixelì€ ië²ˆì§¸ pixelì—ë§Œ dependentí•˜ë‹¤ ê°€ì • : markov assumption</p><p><img src="/images/image-20210205103602281.png" alt="image-20210205103602281"></p><p><img src="/images/image-20210205111200710.png" alt="image-20210205111200710"></p><p>ê·¸ ì¤‘ê°„ì— ìˆëŠ” ê±¸ conditional independenceë¥¼ ì˜ í™œìš©í•´ì„œ ì¤‘ê°„ì˜ parameterê°’ì„ ì–»ì–´ëƒˆë‹¤</p><h2 id="Auto-regressive-Model"><a href="#Auto-regressive-Model" class="headerlink" title="Auto-regressive Model"></a>Auto-regressive Model</h2><ul><li><p>suppose we have 28x28 binary pixels</p></li><li><p>goal : p(x) = p(x1,x2â€¦.,x784)</p></li><li><p>how can we parametrize p(x)</p></li><li><p>use chain rule to get joint distribution</p></li><li><p>p(x<del>1:784</del>) = p(x<del>1</del>)p(x<del>2</del>|x<del>1</del>)p(x<del>2</del>|x<del>1:2</del>)â€¦â€¦</p></li><li><p>ì´ê²Œ ë°”ë¡œ auto-regressive model (ië²ˆì§¸ pixelì´ 1~i-1ê¹Œì§€ ëª¨ë“  historyì— dependentí•œ)</p></li><li><p>ê°€ì¥ ì¤‘ìš”í•œê²Œ ìˆœì„œë¥¼ ë§¤ê¸°ëŠ” ê³¼ì •</p><p><strong>ì´ë¯¸ì§€ì— ìˆœì„œ???? â€”-&gt; ìˆœì„œì— ë”°ë¼ ì„±ëŠ¥ì´ë‚˜ ë°©ë²•ë¡ ì´ ë‹¬ë¼ì§ˆìˆ˜ ìˆë‹¤</strong></p></li></ul><h2 id="NADE-Neural-Autoregressive-Density-Estimator"><a href="#NADE-Neural-Autoregressive-Density-Estimator" class="headerlink" title="NADE : Neural Autoregressive Density Estimator"></a>NADE : Neural Autoregressive Density Estimator</h2><ul><li>p(x<del>i</del>|x<del>1:i-1</del>) = </li></ul><p>ië²ˆì§¸ pixelì„ 1~i-1ì— dependentí•˜ê²Œ ë§Œë“ ë‹¤  â€”â€“&gt; </p><p><strong>dependent í•˜ë‹¤ ?</strong> 1-i-1ë²ˆì§¸ pixelê°’ì„ ì…ë ¥ìœ¼ë¡œ ë°›ê³  networkë¥¼ í†µê³¼ì‹œì¼œì„œ ë‚˜ì˜¨ outputì— sigmoidë¥¼ í†µê³¼í•´ì„œ í™•ë¥ ì´ ë‚˜ì˜¤ë„ë¡í•˜ëŠ”ê²ƒ</p><p><img src="/images/image-20210205111934634.png" alt="image-20210205111934634">    </p><p>neural networkì˜ weightì˜ ì°¨ì›ê°’ì€ ì§€ì†í•´ì„œ ëŠ˜ì–´ë‚¨ì´ì „ì…ë ¥ë“¤ì´ ê³„ì†í•´ì„œ ëŠ˜ì–´ë‚˜ê¸° ë•Œë¬¸ì—</p><ul><li>NADE is explicit model</li><li>Suppose we have 784ê°œì˜ binary pixel</li></ul><p>ì•Œê³ ìˆëŠ” ê°’ë“¤ì„ ì§‘ì–´ë„£ì€ë’¤ ê³„ì‚°í•˜ê²Œ ë˜ë©´ í™•ë¥ ê°’ì´ ë‚˜ì˜´</p><p><img src="/images/image-20210205112108078.png" alt="image-20210205112108078"></p><p>Density estimate : í™•ë¥ ì ìœ¼ë¡œ ë¬´ì–¸ê°€ì˜ í™•ë¥ ì„ explití•˜ê²Œ ê³„ì‚°í•œë‹¤</p><p>Continousí•œ r.vë¥¼ modelingí• ë•ŒëŠ” Gaussianì´ ì‚¬ìš©ì´ ëœë‹¤</p><br/><h2 id="Pixel-RNN"><a href="#Pixel-RNN" class="headerlink" title="Pixel RNN"></a>Pixel RNN</h2><br/><ul><li>Use RNNs to define an auto regressive model</li><li>ì´ì „ì— ë´¤ë˜ NADEëŠ” dense layerì„ ì‚¬ìš©í•¨ í•˜ì§€ë§Œ Pixel RNNì€ RNNì„ í†µí•´ generateí•œë‹¤</li><li><img src="/images/image-20210205112323136.png" alt="image-20210205112323136"><ul><li><p>orderingì˜ ìˆœì„œì— ë”°ë¼</p><p>Row LSTM</p><p>Diagonal BiLTM</p><p><img src="/images/image-20210214141351023.png" alt="image-20210214141351023"></p><br/></li></ul></li></ul><br/><h1 id="Latent-Variable-Models"><a href="#Latent-Variable-Models" class="headerlink" title="Latent Variable Models"></a>Latent Variable Models</h1><h2 id="Variational-Auto-encoder"><a href="#Variational-Auto-encoder" class="headerlink" title="Variational Auto-encoder"></a>Variational Auto-encoder</h2><ul><li><p>Is an autoencoder generative model??</p><p>autoencoderì€ inputì„ ì¬ì •ì˜í•˜ëŠ” ê³¼ì •ì´ì§€ generative modelì€ ì•„ë‹ˆë‹¤</p><p>ê³¼ì—° ë¬´ì—‡ë•Œë¬¸ì— Variational Auto-Encoderì€ generation ëª¨ë¸ì¸ê°€?</p></li><li><p>Variational inference (VI)</p><ul><li>The goal of VI is to optimize the variational distribution that best matches the <strong>posterior distribution</strong></li></ul></li><li><p>posterior distribution : observationì´ ì£¼ì–´ì¡Œì„ë•Œ ë‚´ê°€ ê´€ì‹¬ìˆì–´í•˜ëŠ” r.vì˜ í™•ë¥ ë¶„í¬</p><ul><li>posterior distributionì„ ê³„ì‚°í•˜ëŠ”ê±´ ë§¤ìš° í˜ë“¤ê¸° ë•Œë¬¸ì— Variational distributionì„ ê·¼ì‚¬í•œë‹¤</li></ul></li></ul><p>KL divergenceë¥¼ ì‚¬ìš©í•´ì„œ Variational distributionê³¼ Posterior distributionì˜ ì°¨ì´ë¥¼ ì¤„ì—¬ë³´ê² ë‹¤</p><p><img src="/images/image-20210214142712060.png" alt="image-20210214142712060"></p><p><strong>How?</strong></p><p><img src="/images/image-20210214142913172.png" alt="image-20210214142913172"></p><p>ì›í•´ëŠ” KL divergenceë¥¼ ì¤„ì´ëŠ”ê²Œ ëª©ì ì´ì§€ë§Œ ì´ê²Œ ë¶ˆê°€ëŠ¥í•˜ê¸° ë•Œë¬¸ì— ELBOë¼ê³  ë¶ˆë¦¬ëŠ” termì„ ìµœëŒ€í™” í•œë‹¤</p><br/><ul><li><p><strong>ELBO can further be decomposed into</strong></p><p><img src="/images/image-20210214144517622.png" alt="image-20210214144517622"></p></li></ul><p>Reconstruction Term</p><p>xë¼ëŠ” ì…ë ¥ì„ latent spaceë¡œ ë³´ëƒˆë‹¤ê°€ Decoderë¡œ ëŒì•„ì˜¤ëŠ” Reconstruction lossë¥¼ ì¤„ì´ëŠ” term</p><p>Latent spaceì— ì˜¬ë ¤ë†“ì€ ì ë“¤ì´ ì´ë£¨ëŠ” ë¶„í¬ê°€ Latent spaceì˜ prior distributionì™€ ë¹„ìŠ·í•˜ë‹¤? implicití•œ model</p><br/><p>Decoderì´í›„ì˜ output domainì˜ ê°’ë“¤ì´ generation resultì´ë‹¤</p><p>Auto encoderì€ ì´ê²Œ ì•„ë‹ˆë¼ generation modelì´ ì•„ë‹ˆë‹¤</p><br/><p>Key limitation</p><ul><li>Interactable model (hard to evaluate likelihood)</li><li>reconstruction termì€ ìƒê´€ì—†ëŠ”ë° KL divergenceë¥¼ ì‚¬ìš©í•œ prior distributionì—ëŠ” ë¬´ì¡°ê±´ ë¯¸ë¶„ì´ ê°€ëŠ¥í•œ distribution (like Gaussian)ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤. ë”°ë¼ì„œ diverseí•œ latent prior distributionsì—ëŠ” ì‚¬ìš©ì„ í•˜ê¸°ì— í˜ë“¤ë‹¤</li><li>In most cases, we use an isotropic Gaussian</li><li><img src="/images/image-20210214145657271.png" alt="image-20210214145657271"></li></ul><br/><h2 id="Adversarial-Auto-encoder"><a href="#Adversarial-Auto-encoder" class="headerlink" title="Adversarial Auto-encoder"></a>Adversarial Auto-encoder</h2><br/><ul><li><p>It allows us to use any arbitrary latent distributions that we can sample</p><p><img src="/images/image-20210214145814068.png" alt="image-20210214145814068"></p><p>Prior fitting termì„ ganì„ ì‚¬ìš©í•˜ì—¬ ë¶„í¬ë¥¼ ë§ì¶”ì–´ì¤Œ</p><p>samplingì´ ê°€ëŠ¥í•œ ì–´ë– í•œ ë¶„í¬ë„ ë§ì¶œìˆ˜ìˆë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤</p></li></ul><h2 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h2><p><img src="/images/image-20210214151437158.png" alt="image-20210214151437158"></p><p>discriminatorê°€ ì ì°¨ ë°œì „í•´ ë‚˜ê°€ë©´ì„œ generatorë„ ë”°ë¼ì„œ ì„±ëŠ¥ì´ ì˜¬ë¼ê°€ëŠ” ìƒìƒì˜?</p><h3 id="GAN-vs-VAE"><a href="#GAN-vs-VAE" class="headerlink" title="GAN vs VAE"></a>GAN vs VAE</h3><p><img src="/images/image-20210214151545975.png" alt="image-20210214151545975"></p><h3 id="GANì˜-Objective"><a href="#GANì˜-Objective" class="headerlink" title="GANì˜ Objective"></a>GANì˜ Objective</h3><ul><li><p>For discriminator<img src="/images/image-20210214151646421.png" alt="image-20210214151646421"></p><p>where the optimal discriminator is <img src="/images/image-20210214151813712.png" alt="image-20210214151813712"></p></li><li><p>For generator</p><p><img src="/images/image-20210214151923764.png" alt="image-20210214151923764"></p><p><strong>GANì˜ objectiveëŠ” ë‚˜ì˜ true generative distributionê³¼ ë‚´ê°€ í•™ìŠµí•˜ê³ ìí•˜ëŠ” generatorì‚¬ì´ì˜ Jenson-Shannon Divergenceë¥¼ ìµœì†Œí™” í•˜ëŠ”ê²ƒì´ë‹¤</strong></p></li></ul><h3 id="DCGAN"><a href="#DCGAN" class="headerlink" title="DCGAN"></a>DCGAN</h3><p><img src="/images/image-20210214152052429.png" alt="image-20210214152052429"></p><h3 id="Info-GAN"><a href="#Info-GAN" class="headerlink" title="Info-GAN"></a>Info-GAN</h3><p><img src="/images/image-20210214152117180.png" alt="image-20210214152117180"></p><p>í•™ìŠµì‹œì— classë¼ëŠ” randomí•œ one-hot vectorë¥¼ ë§¤ë²ˆ ì§‘ì–´ ë„£ì–´ì¤€ë‹¤</p><p>generationì‹œì— ganì´ íŠ¹ì •ëª¨ë“œì— ì§‘ì¤‘í•  ìˆ˜ ìˆê²Œë”í•´ì¤€ë‹¤</p><h3 id="Text2Image"><a href="#Text2Image" class="headerlink" title="Text2Image"></a>Text2Image</h3><p><img src="/images/image-20210214152233370.png" alt="image-20210214152233370"></p><p>í…ìŠ¤íŠ¸ë¡œ ì´ë¯¸ì§€ë¥¼ generateí•˜ëŠ” ì—°êµ¬</p><p>modelì´ ë§¤ìš° ë³µì¡í•˜ë‹¤â€¦â€¦.</p><br/><p>CycleGAN</p><p><img src="/images/image-20210214152414654.png" alt="image-20210214152414654"></p><p>ì´ cycle consistency lossê°€ ë§¤ìš° ì¤‘ìš”í•˜ë‹¤</p>]]></content:encoded>
      
      
      <category domain="https://jo-member.github.io/categories/Boostcamp/">Boostcamp</category>
      
      
      <category domain="https://jo-member.github.io/tags/Basic/">Basic</category>
      
      <category domain="https://jo-member.github.io/tags/GAN/">GAN</category>
      
      
      <comments>https://jo-member.github.io/2021/02/05/2021-02-05-Boostcamp15.1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Attention Is All You Need</title>
      <link>https://jo-member.github.io/2021/02/05/2021-02-05-Attention/</link>
      <guid>https://jo-member.github.io/2021/02/05/2021-02-05-Attention/</guid>
      <pubDate>Thu, 04 Feb 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;br/&gt;

&lt;h2 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h2&gt;&lt;p&gt;Seuence transduction modelë“¤ì€ í˜„ì¬ ë³µì¡í•œ recurrentí•œ êµ¬ì¡° (RNN) ì´ë‚˜ encoder decoderë¥¼ í¬í•¨í•œ CNNì´ ì£¼ë¥¼ ì´ë£¬ë‹¤. ê°€ì¥ ì¢‹ì€ì„±ëŠ¥ì„ ë‚´ëŠ” modelë˜í•œ attention mechanismì„ ì´ìš©í•˜ì—¬ encoderì™€ decoderë¥¼ ì—°ê²°í•˜ëŠ” í˜•íƒœì´ë‹¤.&lt;/p&gt;
&lt;p&gt;ì´ ë…¼ë¬¸ì—ì„œëŠ” ìƒˆë¡œìš´ ë°©ë²•ì¸ Transformerë¥¼ ì œì•ˆ&lt;/p&gt;
&lt;p&gt;ì´ëŠ” ì˜¤ë¡œì§€ attention mechanismë§Œì„ ì‚¬ìš©!&lt;/p&gt;
&lt;p&gt;ì´ëŠ” RNNì´ë‚˜ CNNë³´ë‹¤ ë” &lt;strong&gt;ë³‘ë ¬í™”ê°€ ê°€ëŠ¥í•˜ê³  trainí•˜ëŠ”ë° ì ì€ ì‹œê°„ì´ ê±¸ë¦°ë‹¤!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;WMT 2014 English to-German dataë¥¼ ì‚¬ìš©í•˜ì—¬ BLEUë¼ëŠ” scoreì—ì„œ 28.4ì ì„ ì–»ì—ˆë‹¤.(ì—¬ëŸ¬ ë…¼ë¬¸ì„ ì½ë‹¤ë³´ë©´ ìì£¼ ë“±ì¥í•˜ëŠ” ì´ BLUE scoreì€ ì •ë¦¬í•´ ë†“ì€ê²Œ ìˆëŠ”ë° ì¶”í›„ì— posting )&lt;/p&gt;
&lt;p&gt;ì´ëŠ” ì•™ìƒë¸”ì„ í¬í•¨í•œ ì´ì „ì˜ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ë³´ë‹¤ 2BLUEê°€ ë†’ë‹¤.&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<br/><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Seuence transduction modelë“¤ì€ í˜„ì¬ ë³µì¡í•œ recurrentí•œ êµ¬ì¡° (RNN) ì´ë‚˜ encoder decoderë¥¼ í¬í•¨í•œ CNNì´ ì£¼ë¥¼ ì´ë£¬ë‹¤. ê°€ì¥ ì¢‹ì€ì„±ëŠ¥ì„ ë‚´ëŠ” modelë˜í•œ attention mechanismì„ ì´ìš©í•˜ì—¬ encoderì™€ decoderë¥¼ ì—°ê²°í•˜ëŠ” í˜•íƒœì´ë‹¤.</p><p>ì´ ë…¼ë¬¸ì—ì„œëŠ” ìƒˆë¡œìš´ ë°©ë²•ì¸ Transformerë¥¼ ì œì•ˆ</p><p>ì´ëŠ” ì˜¤ë¡œì§€ attention mechanismë§Œì„ ì‚¬ìš©!</p><p>ì´ëŠ” RNNì´ë‚˜ CNNë³´ë‹¤ ë” <strong>ë³‘ë ¬í™”ê°€ ê°€ëŠ¥í•˜ê³  trainí•˜ëŠ”ë° ì ì€ ì‹œê°„ì´ ê±¸ë¦°ë‹¤!</strong></p><p>WMT 2014 English to-German dataë¥¼ ì‚¬ìš©í•˜ì—¬ BLEUë¼ëŠ” scoreì—ì„œ 28.4ì ì„ ì–»ì—ˆë‹¤.(ì—¬ëŸ¬ ë…¼ë¬¸ì„ ì½ë‹¤ë³´ë©´ ìì£¼ ë“±ì¥í•˜ëŠ” ì´ BLUE scoreì€ ì •ë¦¬í•´ ë†“ì€ê²Œ ìˆëŠ”ë° ì¶”í›„ì— posting )</p><p>ì´ëŠ” ì•™ìƒë¸”ì„ í¬í•¨í•œ ì´ì „ì˜ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ë³´ë‹¤ 2BLUEê°€ ë†’ë‹¤.</p><span id="more"></span><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><br/><p>RNNëª¨ë¸ (LSTMì´ë‚˜ GRU)ëŠ” machine translationê³¼ ê°™ì€ sequence modelingì˜ State of the artí•œ(ìµœì‹ ì˜ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì˜) ì ‘ê·¼ë°©ì‹ìœ¼ë¡œ ì•Œë ¤ì ¸ìˆë‹¤. RNNì€ inputê³¼ outputì˜ ìœ„ì¹˜ë¥¼ ê³„ì‚°í•œ ê²°ê³¼ë¥¼ ë‹´ê³ ìˆë‹¤. ê³„ì‚°í•˜ëŠ” ì‹œê°„ì´ë‚˜ ìˆœì„œì— ì˜í•´ ì •ë ¬ëœ ìœ„ì¹˜ë“¤ì€ ì´ì „ì˜ hidden state h<del>t-1</del>ë¡œ í‘œí˜„ëœ ì—°ì†ì ì¸ hidden state h<del>t</del>ë¥¼ ìƒì„±í•œë‹¤. ì´ê²ƒì€ ë³¸ì§ˆì ìœ¼ë¡œ training examplesì˜ ë³‘ë ¬í™”ë¥¼ ë°°ì œí•˜ë©°, ì´ë¡œì¸í•´ memoryì˜ í•œê³„ë¡œ ì¸í•œ batch sizeì˜ í•œê³„ ë•Œë¬¸ì— ê¸´ sequence lengthì— êµ‰ì¥íˆ criticalí•œ ìš”ì†Œë¡œ ì‘ìš©í•œë‹¤. ìµœê·¼ì˜ ì—°êµ¬ë“¤ì€ factorizationê³¼ conditional computation(ì´ê²ƒì— ëŒ€í•œ ë…¼ë¬¸: Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks, Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer )ì„ ì´ìš©í•œ ê³„ì‚°ê³¼ì •ì˜ íš¨ìœ¨í™”ë¡œ í° ë°œì „ì„ ì´ë£¨ì–´ëƒˆë‹¤. í•˜ì§€ë§Œ ìˆœì°¨ì ì¸ ê³„ì‚°ì— ì˜í•œ ì œì•½ì€ ì•„ì§ ë‚¨ì•„ìˆë‹¤</p><p>Attention mechanismì€ inputê³¼ outì‚¬ì´ì˜ ê¸¸ì´ì— ìƒê´€ì—†ì´ dependenciesë¥¼  modelingí• ìˆ˜ìˆë‹¤ëŠ” ë¶€ë¶„ì—ì„œ sequence modelingê³¼ transduction modelingì˜ í•„ìˆ˜ì ì¸ ë¶€ë¶„ì´ ë˜ì—ˆë‹¤. í•˜ì§€ë§Œ ëª‡ëª‡ ê²½ìš°ì—ì„œëŠ” ì•„ì§ attention mechanismê³¼ RNNì„ í•©ì³ì„œ ì‚¬ìš©í•˜ê³  ìˆë‹¤.</p><p>ì´ ì—°êµ¬ì—ì„œëŠ” Transformerë¼ëŠ” attention mechanismì—ë§Œ ì˜ì¡´í•˜ì—¬ inputê³¼ outputì˜ dependencyë¥¼ ì´ëŒì–´ë‚´ëŠ” architectureì„ ì œì•ˆí•œë‹¤. Transformerì€ ë³‘ë ¬í™”ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•˜ê³ , ì„±ëŠ¥ì„ ë”ìš± í–¥ìƒì‹œí‚¬ìˆ˜ ìˆë‹¤</p><br/><p>ìš”ì•½ : ìš°ë¦¬ì˜ transformerê°€ training exampleì˜ ë³‘ë ¬í™”ë¡œ ì¸í•œ ì†ë„ í–¥ìƒê³¼ ì¢‹ì€ ì ìˆ˜ë¥¼ ë‚¸ë‹¤.</p><br/><h2 id="2-Background"><a href="#2-Background" class="headerlink" title="2. Background"></a>2. Background</h2><p>encoder , decoderì—ëŒ€í•œ background</p><p>ì¤‘ê°„ì˜ latent spaceëŠ” inputì´ë‚˜ outputë³´ë‹¤ í›¨ì”¬ ìµœì†Œí™”ëœ vectorì´ë‹¤. Sequentialí•œ ê³„ì‚°ì„ ì¤„ì´ëŠ” ëª©í‘œëŠ” ê¸°ë³¸ì ì¸ building blockì—ì„œ CNNì„ ì‚¬ìš©í•˜ì—¬ ë³‘ë ¬ì ìœ¼ë¡œ inputê³¼ outputì˜ hidden representationì„ ê³„ì‚°í•˜ëŠ” ByteNetì´ë‚˜ ConvS2Sì˜ ê¸°ë°˜ì„ ì´ë£¨ê³ ìˆë‹¤. ìœ„ì™€ ê°™ì€ modelì—ì„œëŠ” 2ê°œì˜ inputì´ë‚˜ outputì˜ ê¸¸ì´ê°€ ì¦ê°€í• ìˆ˜ë¡ ê³„ì‚°ëŸ‰ì´ ëŠ˜ì–´ë‚œë‹¤.(ByteNetì€ logì ìœ¼ë¡œ, ConvS2SëŠ” linearí•˜ê²Œ). ì´ëŸ¬í•œ ê²°ê³¼ëŠ” ê±°ë¦¬ì— ë”°ë¥¸ dependenciesë“¤ì„ í•™ìŠµí•˜ê¸°ì— ë”ìš± ì–´ë µê²Œ ë§Œë“ ë‹¤. </p><br/><p>â€» (inputê³¼ outputì‚¬ì´ì˜ ê¸¸ì´ê°€ ê¸¸ì–´ì§€ë©´ ê³„ì‚°ëŸ‰ì´ ì¦ê°€í•´ ì„œë¡œì˜ ì—°ê´€ê´€ê³„ë¥¼ í•™ìŠµí•˜ê¸°ê°€ ì–´ë µë‹¤ëŠ” ëœ»</p><p>cnnì€ í•œë²ˆì— kernel sizeë¥¼ ì§„ì§œ ì»¤ë´¤ì ìµœëŒ€ 7x7ì„ ì“°ê¸° ë•Œë¬¸ì— ë§Œì•½ inputì´ ì—„ì²­ ê¸¸ë‹¤ë©´ CNNì—°ì‚°ì‹œ ê³„ì‚°ëŸ‰ì´ ì¦ê°€í•˜ê²Œ ë˜ê³  ìœ„ì¹˜ì— ëŒ€í•œ ì •ë³´ì˜ ì¼ë¶€ë§Œì´ ë‹´ê¸°ê²Œë¨. ì˜ˆë¥¼ ë“¤ì–´ ê°„ë‹¨í•˜ê²Œ she is pretty and good at playing piano with her own pianoì™€ ê°™ì€ ë¬¸ì¥ì—ì„œ ë’¤ì— herê³¼ ì²˜ìŒ sheëŠ” ê¸´ ê±°ë¦¬ë¥¼ ê°€ì§€ê²Œ ë˜ì–´ì„œ ì´ ì •ë³´ë¥¼ ë‹´ê¸°ì— CNNì€ ë¶€ì ì ˆ?).</p><br/><p>Transformerì—ì„œëŠ” linearë‚˜ logmatricí•˜ê²Œ ê³„ì‚°ëŸ‰ì´ ì¦ê°€í•˜ì§€ ì•Šê³  constantí•œ numberë¡œ ì¦ê°€í•œë‹¤.Attention-weigheted positionì˜ <strong>í‰ê· </strong>ì„ ì‚¬ìš©í•˜ì—¬  Effectiveí•œ **í•´ìƒë„?**ê°€ ê°ì†Œí•¨ì—ë„Multi-Head Attentionê³¼ ìƒí˜¸ì‘ìš© í•¨ìœ¼ë¡œì„œ ê³„ì‚°ëŸ‰ì„ ì¤„ì˜€ë‹¤.</p><p>Self-attentionì€ ì„œë¡œ ë‹¤ë¥¸ positionì— ìˆëŠ” sequenceë¥¼ í‘œí˜„í•˜ê¸° ìœ„í•´ ì„œë¡œë¥¼ relatingí•œë‹¤. </p><p>Self-attentionì€ reading comprehension, abstractive summarization, textual entailment and learning task-independent sentence representationê³¼ ê°™ì€ ë¶„ì•¼ì—ì„œ ì„±ê³µì ìœ¼ë¡œ ì‚¬ìš©ë˜ì–´ì ¸ ì™”ë‹¤.</p><p>End-to-end memory networkì€ ìˆœì„œì— ë”°ë¼ ì •ë ¬ëœ recurrenceê°€ ì•„ë‹Œ recurrent attention mechanismì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ê³ ìˆê³ , ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆë‹¤.</p><p>Transformerì€ ì²˜ìŒìœ¼ë¡œ RNNì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì˜¤ë¡œì§€ self-attentionë§Œì´ ì“°ì¸ ì²«ë²ˆì§¸ ë³€ì—­ modelì´ë‹¤.</p><br/><br/><p>ìš”ì•½ :  Sequenceí•œ ë¬¸ì œì—ì„œì˜ ëª¨ë¸</p><p>â€‹    RNNì˜ ë‹¨ì  : ë³‘ë ¬í™”ì˜ ì–´ë ¤ì›€ìœ¼ë¡œ ì¸í•œ ê³„ì‚°ì˜ ë³µì¡ë„ ì¦ê°€, train ì‹œê°„ì˜ ì¦ê°€,</p><p>â€‹    (ê·¸ë¦¬ê³  ê°•ì˜ì—ì„œ ë§Œì•½     sequentialí•œ ë°ì´í„°ì¤‘ ì¤‘ê°„ì— ì–´ëŠ í•˜ë‚˜ê°€ë¹ ì§„ë‹¤ë©´ í•´ê²°í•˜ê¸°ê°€ ì–´ë µë‹¤ê³  í–ˆë‹¤)</p><p>â€‹    CNNì˜ ë‹¨ì  : ë³‘ë ¬ì ì¸ ê³„ì‚°ì€ ì´ë£¨ì–´ ì§€ì§€ë§Œ, inputì´ë‚˜ outputì˜ ê¸¸ì´ê°€ ì¦ê°€í• ìˆ˜ë¡ ê³„ì‚°ë„ ë§ê³  ë‹¨ì–´ê°„ì˜ ê´€    ê³„íŒŒì•…ì´ ë¹¡ì…ˆ</p><p>â€‹    ë”°ë¼ì„œ Attentionë§Œ ì“´ Transformer ì§±</p><p><br/><br/></p><h2 id="3-Model-Atchitecture"><a href="#3-Model-Atchitecture" class="headerlink" title="3. Model Atchitecture"></a>3. Model Atchitecture</h2><p>ê°€ì¥ ê²½ìŸë ¥ì´ ì¢‹ì€ neural sequence transduction modelì€ encoder-decoder êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆë‹¤. Encoderì€ ì…ë ¥ sequenceë¥¼ x = (x<del>1</del>,â€¦.x<del>n</del>)ìœ¼ë¡œ í‘œí˜„í•˜ì˜€ê³  ì´ë¥¼ z = (z<del>1</del>,â€¦.z<del>n</del>)ìœ¼ë¡œ mapí•œë‹¤. ì£¼ì–´ì§„ zë¡œ decoderê°€ output sequenceì¸ (y<del>1</del>,â€¦,y<del>m</del>)ì„ ìƒì„±í•´ ë‚¸ë‹¤.(ë³´í†µ ì¤‘ê°„ì˜ latent ì¸µì€ inputê³¼ outputì— ë¹„í•´ ì‘ì€ dimensionì„ ê°€ì§„ë‹¤ê³  ì¡°êµë‹˜ê»˜ì„œ ì„¤ëª…) ê° stepë§ˆë‹¤ modelì€ <strong>auto-regressive</strong>í•˜ë©°, ë¬¸ì¥ì„ ìƒì„±í• ë•Œ ì´ì „ì— ìƒì„±ëœ symbolì„ additional inputìœ¼ë¡œ ê°€ì •í•œë‹¤.</p><p><br/><br/></p><br/><p>â€» Auto regressive ë³µìŠµ</p><p>(ê³ ì •ëœ ê¸¸ì´ì¸ $\tau$ë§Œí¼ì˜ ì‹œí€€ìŠ¤ë§Œ í™œìš©í•˜ëŠ” ê²½ìš° Autoregressive Model(ìê¸°íšŒê·€ëª¨ë¸)ì´ë¼ê³  ë¶€ë¥¸ë‹¤</p><p>ì§ì „ê³¼ê±°ì˜ ì •ë³´ë‘ ì§ì „ì •ë³´ê°€ ì•„ë‹Œ ì •ë³´ë“¤ì„ H<del>t</del>ë¡œ ë¬¶ì–´ì„œ í™œìš©)</p><p><img src="/images/image-20210204114520892-1612513436394.png" alt="image-20210204114520892"></p><p><br/><br/></p><p><br/><br/></p><p>Transformerì€ stackedëœ self-attentionì„ ì‚¬ìš©í•˜ê³  ìˆê³ , encoderì™€ decoderë¶€ë¶„ì— ëª¨ë‘ fully connected layerë¥¼ ì‚½ì…í•˜ì˜€ë‹¤.</p><p><img src="/images/image-20210205125403138.png" alt="image-20210205125403138"></p><br/><h3 id="3-1-Encoder-and-Decoder-Stacks"><a href="#3-1-Encoder-and-Decoder-Stacks" class="headerlink" title="3.1 Encoder and Decoder Stacks"></a>3.1 Encoder and Decoder Stacks</h3><p><strong>Encoder</strong> : encoderì€ N=6 (6ê°œ)ì¸ ê°ê°ì˜ identicalí•œ layerë“¤ì´ ì¸µì¸µì´ ìŒ“ì—¬ìˆë‹¤. ê°ê°ì˜ layerë“¤ì€ 2ê°œì˜ sub-layerë¡œ êµ¬ì„±ë˜ì–´ìˆë‹¤. ì²«ë²ˆì§¸ëŠ” Multi-Head Attentionì´ê³ , ë‘ë²ˆì§¸ëŠ” ê°„ë‹¨í•œ fully-connectedëœ feed-forward networkì´ë‹¤.</p><p>ìš°ë¦¬ëŠ” ê°ê°ì˜ sublayerì— <strong>residual connection</strong>ì„ ë“¤ì–´ ì£¼ì—ˆë‹¤.</p><br/><p>â€»ì—¬ê¸°ì„œ ê³¼ì—° residual connectionì„ ë„£ì€ ì´ìœ ê°€ ë­˜ê¹Œ? overfitting ë°©ì§€ like ResNet??</p><br/><p>ê°ê°ì˜ sub-layerì˜ outputì€ <em>LayerNorm(x + Sublayer(x))</em>. ëª¨ë“  sublayer modelê³¼ embedding layerì˜ outputì˜ ì°¨ì›ì€ d<del>model</del> = 512 ì´ë‹¤.</p><br/><p><strong>Decoder</strong> : Decoderë˜í•œ N=6ì¸ ê°ê°ì˜ identicalí•œ layerë“¤ì´ ì¸µì¸µì´ ìŒ“ì—¬ìˆë‹¤. Encoderì˜ 2ê°œì˜ ê° sub-layerì— Decoderì€ <strong>encoder stackì˜ outputì— ëŒ€í•œ multi-Head attention</strong>ì„ ìˆ˜í–‰í•˜ëŠ” ì¸µì´ ì¶”ê°€ê°€ ë˜ì—ˆë‹¤.</p><p>Encoderì™€ ê°™ì´ sublayerì— residual connectionì„ ë§Œë“¤ì–´ ì£¼ì—ˆë‹¤. í•˜ìœ„ positionì´ attendí•˜ëŠ”ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ self-attention-layerì„ ì•½ê°„ ìˆ˜ì •í•˜ì˜€ë‹¤**(ì´ê²Œ masking). ì´ maskingì€ iìœ„ì¹˜ì˜ ì˜ˆì¸¡ì´ ië³´ë‹¤ ê³¼ê±°ì˜ ê²ƒìœ¼ë¡œë§Œ êµ¬í•´ì§€ê²Œ í•˜ê¸° ìœ„í•¨ì´ë‹¤.**</p><br/><p>â€» Maskingì€ NLP ë¬¸ì œì—ì„œ êµ‰ì¥íˆ ë§ì´ ì“°ì¸ë‹¤ê³  í•œë‹¤. ì•Œì•„ë‘ì</p><br/><br/><h3 id="3-2-Attention"><a href="#3-2-Attention" class="headerlink" title="3.2 Attention"></a>3.2 Attention</h3><p>Attention functionì€ queryì™€ set of key-value pairë“¤ì„ outputì— mappingí•˜ëŠ” í•¨ìˆ˜ì´ë‹¤. (query,key,value,outputì€ ëª¨ë‘ vector). Outputì€ valueë“¤ì˜ weighted sumìœ¼ë¡œ ê³„ì‚°í•˜ë©°, ì´ weightëŠ” queryì™€ ë‹¤ë¥¸ëª¨ë“  keyê°’ë“¤ì˜ <strong>compatibility function</strong>ìœ¼ë¡œ ì •í•´ì§„ë‹¤.</p><p>â€»ì—¬ê¸°ì„œ compatibility functionì´ë€?</p><p>ë’¤ì—ì„œ sumì˜ í˜•íƒœì™€ dot productë¡œ ë‚˜ëˆ„ì–´ ì§„ë‹¤. ì´ë“¤ì˜ ì°¨ì´ì ì€ ë’¤ì— ê¸°ìˆ </p><p><img src="/images/image-20210205131926013.png" alt="image-20210205131926013"></p><br/><h4 id="3-2-1-Scaled-Dot-Product-Attention"><a href="#3-2-1-Scaled-Dot-Product-Attention" class="headerlink" title="3.2.1 Scaled Dot-Product Attention"></a>3.2.1 Scaled Dot-Product Attention</h4><p>ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ attentionì„ â€œScaled Dot-Product Attentionâ€ì´ë¼ê³  ë¶€ë¥¸ë‹¤. Inputì€ d<del>k</del>ì˜ ì°¨ì›ì„ ê°€ì§€ëŠ” keysì™€ queries(ë‘˜ì€ ì—°ì‚°(ë‚´ì )ì„ ìœ„í•´ ê°™ì€ ì°¨ì›ì„ ê°€ì§„ë‹¤)ì™€  d<del>v</del>ì˜ ì°¨ì›ì„ ê°€ì§€ëŠ” valuesë¡œ ì´ë£¨ì–´ì ¸ ìˆë‹¤. ìš°ë¦¬ëŠ” í•˜ë‚˜ì˜ query ë¥¼ ë‹¤ì€ ëª¨ë“  keysë“¤ê³¼ ë‚´ì í•˜ê³ (ì´ ê²°ê³¼ ê°’ì´ ë°”ë¡œ ê°•ì˜ì—ì„œ score) sqrt(d<del>k</del>)ë¡œ ë‚˜ëˆ„ì–´ ì¤€ë‹¤. ì´í›„ softmax functionì„ ì ìš©í•˜ì—¬ valueì˜ weightë¥¼ ì–»ì–´ë‚¸ë‹¤.</p><p>â€» ië²ˆì§¸ ë‹¨ì–´ì— ëŒ€í•œ score vector ê³„ì‚°ì‹œ iì˜ ì¿¼ë¦¬ vectorì™€ ë‹¤ë¥¸ëª¨ë“  key vectors ì‚¬ì´ì˜ ë‚´ì  (Matmul)</p><p>ìœ„ì˜ ê³¼ì •ë“¤ì„ queriesë“¤ì„ Q matrix, keys and valuesë¥¼ ê°ê° K and Vë¼ê³  í•œë‹¤ë©´ ì•„ë˜ì˜ ì‹ìœ¼ë¡œ í‘œí˜„ê°€ëŠ¥</p><p><img src="/images/image-20210205132622631.png" alt="image-20210205132622631"></p><p>ê°€ì¥ ë§ì´ì“°ëŠ” attention functionì˜ í•¨ìˆ˜ëŠ” additive attentionê³¼ ìœ„ì™€ ê°™ì€ dot-product attentionì´ë‹¤. ìš°ë¦¬ëŠ” dot-product attentionì„ ì¼ë‹¤. </p><p>Additive attentionì€ í•˜ë‚˜ì˜ hidden layerì™€ feed forward networkë¥¼ ì‚¬ìš©í•˜ì—¬compatibility functionì„ ê³„ì‚°í•œë‹¤. ì´ë‘ê°€ì§€ëŠ” ë³µì¡ë„ ì¸¡ë©´ì—ì„œ ë¹„ìŠ·í•˜ì§€ë§Œ, dot-product attentionì´ ë”ë¹ ë¥´ê³  ê³µê°„ ì ˆì•½ì ì´ë‹¤.(ì´ìœ ëŠ” í–‰ë ¬ì˜ ê³„ì‚°ìœ¼ë¡œ í‘œí˜„ê°€ëŠ¥)</p><p>ì‘ì€ ê°’ì„ ê°€ì§€ëŠ” d<del>k</del>ì—ì„œì˜  ë‘ mechanismì€ ìœ ì‚¬í•˜ê² ì§€ë§Œ, í° d<del>k</del>ë¡œ ë‚˜ëˆ„ì–´ ì£¼ì§€ ì•Šìœ¼ë©´ additive attentionì´ dot-productì˜ ì„±ëŠ¥ì„ ë„˜ëŠ”ë‹¤. í°  d<del>k</del>ëŠ”  dot -productëŠ” í°ê°’ì„ ê°€ì§€ê²Œ ë˜ê³ , ì´ëŠ” softmax functionì´ ë§¤ìš° ì‘ì€ gradientë¥¼ ê°€ì§€ê²Œ í•œë‹¤. ì´ëŸ¬í•œ ì˜í–¥ì„ ì¤„ì´ê¸° ìœ„í•´ sqrt(d<del>k</del>)ë¡œ ë‚˜ëˆ„ì–´ ì£¼ì—ˆë‹¤. (scale)</p><br/><h4 id="3-2-2-Multi-Head-Attention"><a href="#3-2-2-Multi-Head-Attention" class="headerlink" title="3.2.2 Multi-Head Attention"></a>3.2.2 Multi-Head Attention</h4><p>d<del>model</del>(max sequence)ì˜ ì°¨ì›ì„ ê°€ì§€ëŠ” keys,values,queriesìœ¼ë¡œ ì´ë£¨ì–´ì§„ single attentionì„ ìˆ˜í–‰í•˜ëŠ”ê²ƒì´ ì•„ë‹ˆë¼, ìš°ë¦¬ëŠ” queries, keys, valuesë“¤ì— ê°ê° hë²ˆ d<del>k</del>,d<del>k</del>,d<del>v</del>ë¥¼ ê³±í•˜ì—¬ projectí•œê°’ì´ ë”ìš± ì¢‹ì€ê²ƒì„ ì•Œì•„ë‚´ì—ˆë‹¤.</p><p>ì´ëŸ¬í•œ <strong>projection</strong>ì„ ê±°ì¹˜ë©´ attention functionì„ ë³‘ë ¬ì ìœ¼ë¡œ ìˆ˜í–‰ í•  ìˆ˜ìˆìœ¼ë©°, d<del>v</del>ì˜ ì°¨ì›ì„ ê°€ì§€ëŠ” outputì„ ì–»ì–´ë‚¼ ìˆ˜ ìˆë‹¤. ì´ outputì€ ë‹¤ì‹œ í•˜ë‚˜ë¡œ concatnatedë˜ì–´ projectedëœë‹¤.</p><p><img src="/images/image-20210205134008271.png" alt="image-20210205134008271"></p><p>Multi-Head Attentionì€ ì„œë¡œë‹¤ë¥¸ ìœ„ì¹˜ì—ì„œì˜ ì„œë¡œë‹¤ë¥¸ subspaceì˜ í‘œí˜„ì„ jointly attend í•˜ê²Œ í•œë‹¤.</p><p><img src="/images/image-20210205134243929.png" alt="image-20210205134243929"></p><p>ìš°ë¦¬ëŠ” h = 8ê°œì˜ parallel attention layerì„ ì‚¬ìš©í•˜ì˜€ê³ ,d<del>k</del>,d<del>v</del>,d<del>model</del>/h = 64</p><p><strong>ê°ê°ì˜ headì—ì„œ ì°¨ì›ì„ ì¤„ì„ìœ¼ë¡œì„œ ì „ì²´ì ì¸ ê³„ì‹¼ë¹„ìš©ì´ single head attentionê³¼ ë¹„ìŠ·í•˜ê²Œ ë§Œë“¤ì—ˆë‹¤???????</strong></p><p>â€» í•œë§ˆë””ë¡œ ì´ì œ d<del>model</del>ì˜ ì°¨ì›ì„ hë§Œí¼ parrel layerì— ë‚˜ëˆ„ì–´ì„œ ë„£ì—ˆìœ¼ë‹ˆ ê²°êµ­ single head attentionê³¼ ë¹„ìŠ·í•˜ë‹¤ëŠ” ì´ì•¼ê¸°ì¸ê°€??</p><br/><h4 id="3-2-3-Applications-of-Attention-in-our-Model"><a href="#3-2-3-Applications-of-Attention-in-our-Model" class="headerlink" title="3.2.3 Applications of Attention in our Model"></a>3.2.3 Applications of Attention in our Model</h4><p>Transformerì€ multi-head attentionì„ 3ê°€ì§€ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©í•˜ê³  ìˆë‹¤</p><ol><li><p>â€œEncoder - Decoder attentionâ€ layerì—ì„œ queriesëŠ” ì´ì „ì˜ decoder layerì—ì„œ ì˜¤ê³ , encoderì˜ outputì—ì„œ ì˜¤ëŠ” keyì™€ valueë“¤ì„ ì €ì¥í•œë‹¤. ì´ê²ƒì€ input sequenceì˜ ëª¨ë“  positionë“¤ì„ ëª¨ë“  positionì˜ decoderê°€ attend í•˜ê²Œ í•´ì¤€ë‹¤.</p><p>í•œë§ˆë””ë¡œ decoderì„ ì¿¼ë¦¬ë§Œ ë“¤ê³ ìˆì–´ë„ ëœë‹¤.</p><br/></li><li><p>Self attention layerë¥¼ í¬í•¨í•˜ëŠ” encoder. Self attention layerì—ì„œëŠ” ì´ì „ encoderì˜ layerì˜ ê²°ê³¼ì—ì„œë¶€í„° ë‚˜ì˜¨ ìœ„ì¹˜ì™€ ê°™ì€ ìœ„ì¹˜ì—ì„œ  ëª¨ë“  key, values, and queriesê°€ ë‚˜ì˜¨ë‹¤. encoderì†ì˜ ê°ê°ì˜ ìœ„ì¹˜ë“¤ì€  ì´ì „ encoderì˜ ì´ì „ layerì˜ ëª¨ë“  ìœ„ì¹˜ì— ì§‘ì¤‘í•œë‹¤. (ëª¨ë“  í˜„ì¬ layerì˜ ìœ„ì¹˜ê°€ ì´ì „ layerì˜ ëª¨ë“  position ì •ë³´ë“¤ì„ ê°€ì§„ë‹¤? ì´ëŸ°ëŠë‚Œ?)</p><br/></li><li><p>ë¹„ìŠ·í•˜ê²Œ decoderì˜ self attention layerë˜í•œ ëª¨ë“   decoderì•ˆì˜ ëª¨ë“ (ìê¸°ìì‹ ê¹Œì§€) positionì— ì§‘ì¤‘í•œë‹¤.<strong>Auto regressive íŠ¹ì„±ì„ ë³´ì¡´ì‹œí‚¤ê¸° ìœ„í•´ ì™¼ìª½ì˜ ì •ë³´ë“¤ì´ decoderë¡œ flow in í•˜ëŠ”ê±¸ ë§‰ì•„ì£¼ì–´ì•¼ í•œë‹¤. ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ê±¸ scaled dot product attentionì•ˆì˜ softmaxì˜ output ê°’ì—masking outí•¨ìœ¼ë¡œì„œ í•´ê²°í•œë‹¤</strong></p><p>ì´ê±¸ ë‹¤ì‹œí•œë²ˆ ìƒê°í•´ ë³´ì•„ì•¼ ê² ë‹¤</p><p>Auto regressiveí•œ íŠ¹ì„±ì´ë€ ì´ì „ì˜ ì •ë³´ë“¤ ë§Œìœ¼ë¡œ í˜„ì¬ê°’ì„ ë„ì¶œí•´ë‚´ëŠ” íŠ¹ì„±</p><p>ê·¸ë‹ˆê¹Œ ê²°êµ­ì€ ìœ„ì—(1)ì‹ì—ì„œ softmaxì˜ ê²°ê³¼ê°’ì— ë¯¸ë˜ì˜ ì •ë³´ë“¤ì€ ëª¨ë‘ masking í•´ì¤€ë‹¤ëŠ”ê²ƒì´ë‹¤.</p><p>ê·¸ë‹ˆê¹Œ ê²°êµ­ì—” <img src="/images/image-20210205132622631-1612515516800.png" alt="image-20210205132622631"> </p><p>ì´ì‹ì—ì„œ ë¯¸ë˜ì˜ ì •ë³´ë“¤ê¹Œì§€ Kì™€ Qì˜ ë‚´ì ê²°ê³¼ê°€ ë‹¤ë‹´ê³  ìˆìœ¼ë‹ˆê¹Œ ë¯¸ë˜ì˜ ì •ë³´ëŠ” ë§ˆìŠ¤í‚¹ í•´ì¤€ë‹¤.</p><br/></li></ol><h3 id="3-3-Position-wise-Feed-Forward-Networks"><a href="#3-3-Position-wise-Feed-Forward-Networks" class="headerlink" title="3.3 Position-wise Feed Forward Networks"></a>3.3 Position-wise Feed Forward Networks</h3><p>encoderì™€ decoderì•ˆì˜ ê° layerì—ëŠ” fully connected feed forward networkë¥¼ ê°€ì ¸ì•¼ í•œë‹¤.  ì´ <strong>fully connected feed forward networkëŠ” ê°ê°ì˜ ìœ„ì¹˜ì— ë…ë¦½ì ìœ¼ë¡œ ë”°ë¡œ ì ìš©ëœë‹¤</strong></p><p><img src="/images/image-20210205155145255.png" alt="image-20210205155145255"></p><p>ìœ„ì‹ì„ ë³´ë©´ 2ê°œì˜ linear transformationê³¼ ReLU activationì„ ê·¸ì‚¬ì´ì— ì‚¬ìš©í•˜ì˜€ë‹¤.</p><p><strong>Linear transformationì„ ê°ê°ì˜ positionì— ê°™ì€ ê±¸ ì ìš©í•´ì•¼ í•œë‹¤. ê·¸ë¦¬ê³  layerê³¼ layerì‚¬ì´ì—ëŠ” ë‹¤ë¥¸ parameterë¥¼ ì ìš©í•´ì•¼ í•œë‹¤. ë˜ë‹¤ë¥¸ ë°©ë²•ì€ 1ì˜ kernel sizeë¥¼ ê°€ì§€ëŠ” 2ê°œì˜ convoltionì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤.</strong></p><p>â€» ê·¸ë‹ˆê¹Œ í•˜ë‚˜ì˜ layerì—ëŠ” ê°™ì€ weightë¥¼ ì ìš©í•˜ê³  ë‹¤ë¥¸ layerì‚¬ì´ì—ëŠ” ë‹¤ë¥¸ weightë¥¼ ì ìš©í•œë‹¤ëŠ” ëœ»???</p><br/><p>d<del>model</del> = 512</p><p>inner-layerâ€™s dimension d<del>ff</del> = 2048</p><br/><h3 id="3-4-Embedding-and-Softmax"><a href="#3-4-Embedding-and-Softmax" class="headerlink" title="3.4 Embedding and Softmax"></a>3.4 Embedding and Softmax</h3><p>ì—¬íƒ€ ë‹¤ë¥¸ ë²ˆì—­ ëª¨ë¸ê³¼ ê°™ì´ ì—¬ê¸°ì„œë„ í•™ìŠµëœ embaddingì„ ì‚¬ìš©í–ˆë‹¤.</p><p>Decodeë˜ì–´ ë‚˜ì˜¨ê²°ê³¼ë„ í•™ìŠµëœ linear transformationê³¼ softmaxí•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ tokenì˜ í™•ë¥ ì„ ê³„ì‚°í•˜ì˜€ë‹¤.</p><p>embedding layerë“¤ì—ëŠ” ê°™ì€ weightì™€ presoftmax linear transformationì„ ì‚¬ìš©, weightì˜ ê²°ê³¼ì— sqrt(d<del>model</del>)ì„ ì‚¬ìš©í–ˆë‹¤.</p><br/><h3 id="3-5-Positional-Encoding"><a href="#3-5-Positional-Encoding" class="headerlink" title="3.5 Positional Encoding"></a>3.5 Positional Encoding</h3><p>ìš°ë¦¬ì˜ modelì€ recurrenceë„ ì—†ê³  convolutionë„ ì—†ì–´ì„œ ê°ê°ì˜ modelì´ sequenceì˜ ìˆœì„œë¥¼ ì‚¬ìš©í•˜ê²Œ í•˜ì—¬ë©´ position ì •ë³´ë¥¼ ì‚½ì…í•´ ì£¼ì–´ì•¼ í•œë‹¤.</p><p>ë”°ë¼ì„œ </p><p><img src="/images/image-20210205094724396-1612516229839.png" alt="image-20210205094724396"></p><p>ì´ì™€ ê°™ì´ ê°ê° embeddingëœ vectorì— positional encodingëœ vectorë¥¼ ë”í•´ì¤€ë‹¤</p><p>ì´ ì—°êµ¬ì—ì„œëŠ” cosê³¼ sin í•¨ìˆ˜ë¥¼ ì‚¬ìš©í–ˆë‹¤</p><p><img src="/images/image-20210205181144831.png" alt="image-20210205181144831"></p><p>pos ëŠ” position iëŠ” ì°¨ì›</p><p>ê°ê°ì˜ ìœ„ì¹˜ê°€ sinusodialí•˜ê²Œ encoding ë˜ë„í˜¹ í•˜ì˜€ë‹¤. ì£¼ê¸°ê°€ ì¡°ì˜¬ë¼ ê¸¸ì–´ì„œ ë‹¤ë¥¸ìœ„ì¹œë° ì£¼ê¸°ì„± ë•Œë¬¸ì— ê°™ì€ ê°’ì„ ê°€ì§€ëŠ” ê²½ìš°ëŠ” ë“œë¬¼ë‹¤</p><br/><h2 id="4-Why-Self-Attention"><a href="#4-Why-Self-Attention" class="headerlink" title="4. Why Self-Attention"></a>4. Why Self-Attention</h2><p>ì´ ë¶€ë¶„ì—ì„œëŠ” self attention layerë¥¼ RNNê³¼ CNNì— ë”ìš± ìì„¸íˆ ë¹„êµí•œë‹¤.</p><p>ì•ì—ì„œ ì„¤ëª…í•œê±°ì— ëŒ€í•œ ë³´ì¶©ì„¤ëª…</p><ol><li><p>í•œ layerì—ì„œ ê³„ì‚° ë³µì¡ë„ì—ì„œì˜ ì´ë“</p></li><li><p>ë³‘ë ¬í™” ë  ìˆ˜ ìˆëŠ”ê³„ì‚°ì˜ ì´ëŸ‰</p></li><li><p>ê¸¸ì´ê°€ ê¸°ì´ì´ì¼ì–´ì¡Œì„ë•Œ ì–¼ë§ˆë‚˜ networkì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€</p><p>ê¸¸ì´ê°€ ì¡¸ë¼ë¦¬ ê¸¸ì–´ì¡Œì„ë•Œ dependenciesëŠ” ë§¤ìš° ì¤‘ìš”í•˜ë‹¤. ì´ì— ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ë¯¸ì¹˜ëŠ” ì˜í–¥ì¤‘ í•˜ë‚˜ê°€ signalí•˜ë‚˜ê°€ networkë¥¼ ìˆœíšŒí•˜ëŠ” ê¸¸ì´ì´ë‹¤?? ì´ê²Œ ì§§ì•„ì§ˆìˆ˜ë¡ ê¸´ ê¸¸ì´ì— ëŒ€í•œ ìƒí˜¸ì ì¸ ê´€ê³„ê°€ ë” ì˜ í•™ìŠµëœë‹¤. ë”°ë¼ì„œ ê° modelë§ˆë‹¤ modelì—ì„œ inputê³¼ output ì‚¬ì´ì˜ ê±°ë¦¬? ë­í•˜ì´íŠ¼ ê·¸ ì–¼ë§ˆë‚˜ modelì´ compactí•œê°€</p></li></ol><p><img src="/images/image-20210205181818372.png" alt="image-20210205181818372"></p><p>ìœ„ tableì„ ë³´ë©´ computationalí•œ ì„±ëŠ¥ì„ ë†’ì´ê¸° ìœ„í•´ self attention ëª¨ë¸ì€ í•´ë‹¹í•˜ëŠ” output ìœ„ì¹˜ì˜ ì˜¤ì§ size r ë§Œí¼ì˜ input sequence ì£¼ìœ„ë¥¼ ê³ ë ¤í•˜ë„ë¡ ì œí•œë˜ì–´ìˆë‹¤.</p><p>ì´ê±°ì— ëŒ€í•œ ì—°êµ¬ëŠ” ì¶”í›„ì— ë°œí‘œí•˜ê² ë‹¤ê³  ì í˜€ìˆë‹¤. ê·¸ëŸ¼ ì´ë¯¸ ë‚˜ì™€ìˆê² ì§€?</p><p>í•˜ì´íŠ¼ ìœ„ì—êº¼ ë¹„êµí•´ë³´ë©´ ëª¨ë“  ì¸¡ë©´ì—ì„œ self attentionì´ ì™€ë”°</p><br/><h2 id="5-Training"><a href="#5-Training" class="headerlink" title="5. Training"></a>5. Training</h2><h3 id="1-Training-data-and-batching"><a href="#1-Training-data-and-batching" class="headerlink" title="1. Training data and batching"></a>1. Training data and batching</h3><p>WMT 2014ë¥¼ ì‚¬ìš©í•˜ì—¬ trainí•¨</p><p>ê·¸ë¦¬ê³  ë¬¸ì¥ì€ target vocabì™€ 37000ê°œë¥¼ ê³µìœ í•˜ëŠ” byte-pair encodingì´ë¼ëŠ” ë°©ì‹ì„ ì‚¬ìš©í–ˆìŒ</p><p>ê° traning batchëŠ” 25000ê°œì˜ source tokenê³¼ 25000ê°œì˜ target tokenì„ í¬í•¨í•˜ëŠ” ë¬¸ì¥ì˜ setìœ¼ë¡œ ì •í•´ì£¼ì—ˆë‹¤.</p><h3 id="2-Optimizer"><a href="#2-Optimizer" class="headerlink" title="2. Optimizer"></a>2. Optimizer</h3><p>Adamì„ ì¼ê³ , lrì„ ë‹¨ê³„ì ìœ¼ë¡œ ë³€í™”ì‹œì¼°ë‹¤.ì•„ë˜ì™€ ê°™ì€ ìˆ˜ì‹ìœ¼ë¡œ</p><p><img src="/images/image-20210205182950061.png" alt="image-20210205182950061"></p><br/><h3 id="3-Regularization"><a href="#3-Regularization" class="headerlink" title="3. Regularization"></a>3. Regularization</h3><ol><li><p>Residual Dropout</p><p>ë”í•´ì§€ê³  normalized ë˜ê¸°ì „ì— ê°ê°ì˜ sublayerì˜ outputì— dropoutì„ ì ìš©í•˜ì˜€ë‹¤</p><p>ê·¸ë¦¬ê³  ë˜ embeddingëœ vectorì™€ positionì˜ í•©ì´í›„ì—ë„ ì ìš©í•˜ì˜€ë‹¤</p><p>P<del>drop</del>ì€ 0.1 </p></li><li><p>Label Smoothing???</p><p>ì´ëŸ°ê±¸ ì ìš©í–ˆë‹¤ê³  í•˜ëŠë„¤ ì´ê²Œ ì•½ê°„ ì˜ˆì¸¡ë¶ˆê°€ëŠ¥í•œê±¸ ë”í•´ì¤˜ì„œ modelì´ ë” ìƒˆë¡œìš´ê²ƒì„ ë°°ìš°ê²Œë”í•˜ëŠ” ê±°ë¼í•˜ëŠ”ë° ê± ê°„ë‹¨í•˜ê²Œ ë‚˜ì™€ìˆë‹¤</p><br/></li></ol><h2 id="6-Results"><a href="#6-Results" class="headerlink" title="6. Results"></a>6. Results</h2><p>BLEU score ì˜ë‚˜ì™”ë‹¤ ì–´ì©Œêµ¬ ì €ì©Œêµ¬ í•˜ë‹¤ê°€</p><p>base modelì—ì„œëŠ” 5ê°œì˜ checkpointë¥¼ ë§Œë“¤ì–´ì„œ ê·¸ê²ƒì˜ í‰ê· ì„ ë‚¸ í•˜ë‚˜ì˜ modelì„ ì¼ê³ , ê° check pointëŠ” 10ë¶„ë§ˆë‹¤ í•œë²ˆì”© intervalì„ ì£¼ì—ˆë‹¤.</p><p>ì´ê²Œ ë‚´ê°€ ì¡°êµë‹˜í•œí…Œ ì§ˆë¬¸í–ˆë˜ ë¶€ë¶„ê³¼ ì¢€ ì—°ê´€ì„±ì´ ìˆë‹¤. ì´ë ‡ê²Œ ì¤‘ê°„ì¤‘ê°„ì— modelì„ ê¸°ë¡í•˜ê³  í‰ê· ì„ ë‚´ëŠ” ë°©ì‹ë„ ìˆêµ¬ë‚˜</p><p>ê·¸ë¦¬ê³  ì´ beam searchë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤ê³  í•œë‹¤</p><p>ì´ê±´ ì´ì „ì˜ ë…¼ë¬¸ë“¤ì„ ì½ì„ë•Œë„ ìì£¼ ì‚¬ìš©í–ˆë˜ ê¸°ë²•ì´ë‹¤</p><p>ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•˜ë©´ ê°€ì¥ í™•ë¥ ì´ ë†’ì€ Kê°œì„ ì„ íƒí•˜ë©° ì§„í–‰í•˜ëŠ” ê²ƒì´ë‹¤</p><p>greedyë°©ë²•ë³´ë‹¤ íš¨ìœ¨ì ì´ê³  scoreê°€ ì˜ë‚˜ì˜¨ë‹¤ê³  ë“¤ì—ˆë‹¤</p><h3 id="6-2-Model-Variations"><a href="#6-2-Model-Variations" class="headerlink" title="6.2 Model Variations"></a>6.2 Model Variations</h3><p>ì•„ë˜ tableì˜ (A)ë¥¼ ë³´ë©´ attentionì˜ headì˜ ê°œìˆ˜ì™€ key,valueì˜ dimensionì„ ë³€í™”ì‹œì¼œì£¼ì—ˆë‹¤. ë„ˆë¬´ ë§ì€ headë¥¼ ì‚¬ìš©í•´ë„ ì•ˆë˜ê³  í•˜ë‚˜ë§Œ ì‚¬ìš©í•´ë„ ì•ˆë¨</p><p>ì´ê±´ ë„ˆë¬´ ë‹¹ì—°í•œê±°ë‹¤ ë­ë“ ì§€ ì ë‹¹í•œê²Œ ì¢‹ë‹¤</p><p><img src="/images/image-20210205184119740.png" alt="image-20210205184119740"></p><h3 id="6-3-English-Constituency-Parsing"><a href="#6-3-English-Constituency-Parsing" class="headerlink" title="6.3 English Constituency Parsing"></a>6.3 English Constituency Parsing</h3><p>ì´ Transformerë¥¼ í™œìš©í•œ modelì€ í†µì—­ì—ì„œ ë‚˜ì•„ê°€ì„œ ì˜ì–´ êµ¬ë¬¸ì„ ë¶„ì„í•´ì£¼ëŠ” ë°©ë²•ìœ¼ë¡œ ë°œì „ì‹œì¼œë‚˜ê°€ì•¼ í•œë‹¤. </p><p>ì´ê±´ ë³„ë¡œ ì¤‘ìš”í•˜ì§€ ì•Šì€ê²ƒ ê°™ë‹¤</p><p>í•´ë³´ë‹ˆê¹Œ RNNë³´ë‹¤ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚˜íƒ€ë‚´ì—ˆë‹¤ ë</p><h2 id="7-Conclusion"><a href="#7-Conclusion" class="headerlink" title="7. Conclusion"></a>7. Conclusion</h2><p>ê²°ë¡  </p><p>ê¸°ì¡´ê³¼ ë‹¤ë¥´ê²Œ attentionì—ë§Œ ê¸°ë°˜ì„ ë‘” multi-headed self attentionì„ ì‚¬ìš©í•œ ì´ transformerì€ ë‹¤ë¥¸ RNNì´ë‚˜ CNNë³´ë‹¤ ì„±ëŠ¥ì´ ë¹ ë¥´ë©° ì´ Transfomerë¥¼ ë”ìš±í° inputê³¼ outputì„ ê°€ì§€ëŠ” imageë‚˜ ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ë“±ì—ì ìš©ì‹œí‚¤ëŠ” ê²ƒì„ ê¸°ëŒ€í•˜ê³  ìˆë‹¤.</p><p>Transformer ì§±ì§±ë§¨</p><p>ê·¸ë¦¬ê³  ì¡°êµë‹˜ê»˜ì„œ ê´€ì‹¬ ìˆìœ¼ì‹  Neuroscienceì™€ Attentionì‚¬ì´ì˜ ê´€ë ¨</p><p><img src="/images/image-20210205185431936.png" alt="image-20210205185431936"></p><p>ë³´ë©´ ìš°ë¦¬ ì¸ê°„ì˜ í™©ë°˜ì—ì„œë„ ì´ attentionì˜ ê°œë…ì„ ì ìš©í•´ì„œ ì‚¬ë¬¼ì„ ì¸ì§€í•˜ê³  ìˆìœ¼ë‹ˆ, ì˜ë˜ëŠ”ê²Œ ì–´ì°Œë³´ë©´ ë‹¹ì—°í•˜ë‹¤</p><p>ì¶œì²˜ : <a href="https://arxiv.org/pdf/1706.03762.pdf">https://arxiv.org/pdf/1706.03762.pdf</a></p><p>ê·¸ë¦¬ê³  naver boostcamp</p>]]></content:encoded>
      
      
      <category domain="https://jo-member.github.io/categories/PaperReview/">PaperReview</category>
      
      
      <category domain="https://jo-member.github.io/tags/Transformer/">Transformer</category>
      
      <category domain="https://jo-member.github.io/tags/NLP/">NLP</category>
      
      
      <comments>https://jo-member.github.io/2021/02/05/2021-02-05-Attention/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>RNN1</title>
      <link>https://jo-member.github.io/2021/02/04/2021-02-04-Boostcamp14.1/</link>
      <guid>https://jo-member.github.io/2021/02/04/2021-02-04-Boostcamp14.1/</guid>
      <pubDate>Wed, 03 Feb 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h1 id=&quot;RNN&quot;&gt;&lt;a href=&quot;#RNN&quot; class=&quot;headerlink&quot; title=&quot;RNN&quot;&gt;&lt;/a&gt;RNN&lt;/h1&gt;&lt;hr&gt;
&lt;br/&gt;

&lt;h2 id=&quot;Sequence-Data-amp-Model&quot;&gt;&lt;a href=&quot;#Sequence-Data-amp-Model&quot; class=&quot;headerlink&quot; title=&quot;Sequence Data &amp;amp; Model&quot;&gt;&lt;/a&gt;Sequence Data &amp;amp; Model&lt;/h2&gt;&lt;br/&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;ì†Œë¦¬, ì£¼ê°€, ë¬¸ìì—´ ë“±ì˜ ë°ì´í„°ë¥¼ ì‹œí€€ìŠ¤ ë°ì´í„°ë¡œ ë¶„íœ´í•©ë‹ˆë‹¤&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ì‹œê³„ì—´ ë°ì´í„°ëŠ” ì‹œê°„ìˆœì„œì— ë”°ë¼ ë‚˜ì—´ëœ ë°ì´í„°ë¡œ ì‹œí€€ìŠ¤ ë°ì´í„°ì— ì†í•œë‹¤&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ë…ë¦½ë™ë“±ë¶„í¬ ê°€ì •ì„ ì˜ ìœ„í•´í•˜ê¸° ë•Œë¬¸ì— ìˆœì„œë¥¼ ë°”ê¾¸ê±°ë‚˜ ê³¼ê±°ì •ë³´ì— ì†ì‹¤ì´ ë°œìƒí•˜ë©´ ë°ì´í„°ì˜ í™•ë¥ ë¶„í¬ë„ ë°”ë€Œê²Œ ëœë‹¤&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Markov model : first order autoregressive model&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ì´ë“¤ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Latent autoregressive model&lt;/p&gt;
&lt;p&gt;hidden stateê°€ ê³¼ê±°ì˜ ì •ë³´ë“¤ì„ summerizeí•œë‹¤&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><br/><br/></p><h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><hr><br/><h2 id="Sequence-Data-amp-Model"><a href="#Sequence-Data-amp-Model" class="headerlink" title="Sequence Data &amp; Model"></a>Sequence Data &amp; Model</h2><br/><ul><li><p>ì†Œë¦¬, ì£¼ê°€, ë¬¸ìì—´ ë“±ì˜ ë°ì´í„°ë¥¼ ì‹œí€€ìŠ¤ ë°ì´í„°ë¡œ ë¶„íœ´í•©ë‹ˆë‹¤</p></li><li><p>ì‹œê³„ì—´ ë°ì´í„°ëŠ” ì‹œê°„ìˆœì„œì— ë”°ë¼ ë‚˜ì—´ëœ ë°ì´í„°ë¡œ ì‹œí€€ìŠ¤ ë°ì´í„°ì— ì†í•œë‹¤</p></li><li><p>ë…ë¦½ë™ë“±ë¶„í¬ ê°€ì •ì„ ì˜ ìœ„í•´í•˜ê¸° ë•Œë¬¸ì— ìˆœì„œë¥¼ ë°”ê¾¸ê±°ë‚˜ ê³¼ê±°ì •ë³´ì— ì†ì‹¤ì´ ë°œìƒí•˜ë©´ ë°ì´í„°ì˜ í™•ë¥ ë¶„í¬ë„ ë°”ë€Œê²Œ ëœë‹¤</p></li><li><p>Markov model : first order autoregressive model</p></li><li><p>ì´ë“¤ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Latent autoregressive model</p><p>hidden stateê°€ ê³¼ê±°ì˜ ì •ë³´ë“¤ì„ summerizeí•œë‹¤</p></li></ul><span id="more"></span><h3 id="ë‹¤ë£¨ëŠ”-ë²•"><a href="#ë‹¤ë£¨ëŠ”-ë²•" class="headerlink" title="ë‹¤ë£¨ëŠ” ë²•"></a>ë‹¤ë£¨ëŠ” ë²•</h3><ul><li>ì¡°ê±´ë¶€ í™•ë¥ ì„ ì´ìš©(ê³¼ì˜ ì •ë³´ë¥¼ ê°€ì§€ê³  ë¯¸ë˜ë¥¼ ì˜ˆì¸¡ )</li></ul><p><img src="/images/image-20210204112231880.png" alt="image-20210204112231880"></p><p>ë°”ë¡œì§ì „ê¹Œì§€ì˜ ì •ë³´ S-1ë¥¼ ì‚¬ìš©í•´ì„œ í˜„ì¬ì¸ Së¥¼ ì—…ë°ì´íŠ¸</p><p>ë°˜ë“œì‹œ ëª¨ë“  ê³¼ê±°ì˜ ì •ë³´ë¥¼ ê°€ì§€ê³  ì—…ë°ì´íŠ¸ í•˜ëŠ” ê²ƒì€ ì•„ë‹ˆë‹¤</p><p>ë”°ë¼ì„œ ì¡°ê±´ë¶€ì— ë“¤ì–´ê°€ëŠ” ë°ì´í„°ì˜ ê¸¸ì´ëŠ” <strong>ê°€ë³€ì ì´ë‹¤</strong></p><br/><p>ê³ ì •ëœ ê¸¸ì´ì¸ $\tau$ë§Œí¼ì˜ ì‹œí€€ìŠ¤ë§Œ í™œìš©í•˜ëŠ” ê²½ìš° Autoregressive Model(ìê¸°íšŒê·€ëª¨ë¸)ì´ë¼ê³  ë¶€ë¥¸ë‹¤</p><p>ì§ì „ê³¼ê±°ì˜ ì •ë³´ë‘ ì§ì „ì •ë³´ê°€ ì•„ë‹Œ ì •ë³´ë“¤ì„ H<del>t</del>ë¡œ ë¬¶ì–´ì„œ í™œìš©</p><p><img src="/images/image-20210204114520892.png" alt="image-20210204114520892"></p><p>ê¸¸ì´ê°€ ê°€ë³€ì ì´ì§€ ì•Šê³  ì´ì œ ê³ ì •ë˜ê¸° ë•Œë¬¸ì— ì—¬ëŸ¬ê°€ì§€ ì¥ì ì„ ê°€ì§€ê³  ìˆë‹¤</p><p>ì‚¬ì‹¤ì€ ê³¼ê±°ì˜ ëª¨ë“  ì •ë³´ë¥¼ ê³ ë ¤í•˜ê¸°ê°€ í˜ë“  ë¬¸ì œì ì„ ê³ ì³ì„œ ì´ì œ ì´ì „ì˜ ì •ë³´ë¥¼ ìš”ì•½í•˜ëŠ”H<del>t</del>ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ëª¨ë¸ â€”-&gt; RNN</p><p><br/><img src="/images/image-20210204132225632.png" alt="image-20210204132225632"></p><h2 id="RNN-ì´í•´í•˜ê¸°"><a href="#RNN-ì´í•´í•˜ê¸°" class="headerlink" title="RNN ì´í•´í•˜ê¸°"></a>RNN ì´í•´í•˜ê¸°</h2><ul><li><p>ê¸°ë³¸ì ì¸ ëª¨í˜•ì€ MLPì™€ ìœ ì‚¬í•˜ë‹¤</p></li><li><p><img src="/images/image-20210204115917697.png" alt="image-20210204115917697"></p></li><li><p>RNNì˜ ì—­ì „íŒŒëŠ” ì ì¬ë³€ìˆ˜ì˜ ì—°ê²°ê·¸ë˜í”„ì— ë”°ë¼ ìˆœì°¨ì ìœ¼ë¡œ ê³„ì‚°í•œë‹¤</p><p>Back Propagation Through Time</p></li></ul><h3 id="BTTPë¥¼-ì‚´í´ë´…ì‹œë‹¤"><a href="#BTTPë¥¼-ì‚´í´ë´…ì‹œë‹¤" class="headerlink" title="BTTPë¥¼ ì‚´í´ë´…ì‹œë‹¤"></a>BTTPë¥¼ ì‚´í´ë´…ì‹œë‹¤</h3><p>BTTPë¥¼ í†µí•´ gradientë¥¼ ê³„ì‚°í•´ë³´ë©´ ë¯¸ë¶„ì˜ ê³±ìœ¼ë¡œ ì´ë£¨ì–´ì§„ í•­ì´ ê³„ì‚°ì´ ëœë‹¤</p><p><img src="/images/image-20210204123130405.png" alt="image-20210204123130405"></p><p>ê¸¸ì–´ì§€ë©´ ê³„ì‚°ì´ ë¶ˆì•ˆì •í•´ì§ìœ¼ë¡œ(gradient vanishingê³¼ ê°™ì€)ë¬¸ì œê°€ ìˆê¸° ë•Œë¬¸ì—</p><p>ê¸¸ì´ë¥¼ ëŠëŠ”ê²ƒìœ¼ë¡œ truncated BPTT</p><br/><h3 id="Gradient-vanishing-ë¬¸ì œì˜-í•´ê²°"><a href="#Gradient-vanishing-ë¬¸ì œì˜-í•´ê²°" class="headerlink" title="Gradient vanishing ë¬¸ì œì˜ í•´ê²°??"></a>Gradient vanishing ë¬¸ì œì˜ í•´ê²°??</h3><ul><li>ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ê¸¸ì–´ì§€ëŠ” ê²½ìš°ì—ëŠ” BTTPë¥¼ í†µí•œ ì—­ì „íŒŒ ì•Œê³ ë¦¬ì¦˜ì˜ ê³„ì‚°ì´ ë¶ˆì•ˆì •í•´ ì§€ë¯€ë¡œ ê¸¸ì´ë¥¼ ëŠëŠ”ê²ƒì´ ì¤‘ìš”í•˜ë‹¤</li><li>ex) LSTM, GRU â€¦..</li></ul><p><img src="/images/image-20210204132428721.png" alt="image-20210204132428721"></p><p>RNNì„ ì‹œê°„ìˆœìœ¼ë¡œ ì­‰ í’€ë©´ ê²°êµ­ fully connected layer networkê°€ ëœë‹¤</p><p>ê°€ì¥ì–´ë ¤ìš´ ? ë‹¨ì  ? â€”-&gt; í•˜ë‚˜ì˜ fixed ruleë¡œ ì´ì „ì˜ ì •ë³´ë“¤ì„ summerizeí•˜ê¸° ë•Œë¬¸ì— ë¨¼ ê³¼ê±°ì˜ ì •ë³´ë“¤ì´ í˜„ì¬ì—ì„œ ì‚´ì•„ë‚¨ê¸°ê°€ í˜ë“¤ë‹¤!! ì´ê²Œ short term dependencies</p><p><img src="/images/image-20210204132956315.png" alt="image-20210204132956315"></p><p>ê²°êµ­ ë¨¼ ê³¼ê±°ì˜ ì •ë³´ë“¤ì€ ë§ì€ ì–‘ì˜ activation functionê³¼ Wê³±ì˜ ê²°ê³¼ë¡œ vanishing or explodingë˜ëŠ” í˜„ìƒì´ ì¼ì–´ë‚˜ê²Œ ëœë‹¤</p><br/><br/><h2 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h2><p><img src="/images/image-20210204133224090.png" alt="image-20210204133224090"></p><p>LSTMì˜ ì „ì²´ì ì¸ êµ¬ì¡° </p><p><img src="/images/image-20210204133348991.png" alt="image-20210204133348991"></p><p>ë“¤ì–´ì˜¤ëŠ” ì…ë ¥ì´ 3ê°œ ë‚˜ê°€ëŠ”ê²Œ 3ê°œ</p><p>ì‹¤ì œë¡œ ë‚˜ê°€ëŠ”ê±´ h<del>t</del> (hidden state)</p><p><img src="/images/image-20210205094139431-1612486098130.png" alt="image-20210205094139431"></p><p><img src="/images/image-20210205094150152-1612486110711.png" alt="image-20210205094150152"></p><p><img src="/images/image-20210205094207767-1612486121259.png" alt="image-20210205094207767"></p>]]></content:encoded>
      
      
      <category domain="https://jo-member.github.io/categories/Boostcamp/">Boostcamp</category>
      
      
      <category domain="https://jo-member.github.io/tags/Basic/">Basic</category>
      
      <category domain="https://jo-member.github.io/tags/RNN/">RNN</category>
      
      <category domain="https://jo-member.github.io/tags/NLP/">NLP</category>
      
      
      <comments>https://jo-member.github.io/2021/02/04/2021-02-04-Boostcamp14.1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>RNN2</title>
      <link>https://jo-member.github.io/2021/02/04/2021-02-04-Boostcamp14.2/</link>
      <guid>https://jo-member.github.io/2021/02/04/2021-02-04-Boostcamp14.2/</guid>
      <pubDate>Wed, 03 Feb 2021 15:00:00 GMT</pubDate>
      
      <description>&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h1 id=&quot;Transformer&quot;&gt;&lt;a href=&quot;#Transformer&quot; class=&quot;headerlink&quot; title=&quot;Transformer&quot;&gt;&lt;/a&gt;Transformer&lt;/h1&gt;&lt;br/&gt;

&lt;h2 id=&quot;Sequential-Model&quot;&gt;&lt;a href=&quot;#Sequential-Model&quot; class=&quot;headerlink&quot; title=&quot;Sequential Model&quot;&gt;&lt;/a&gt;Sequential Model&lt;/h2&gt;&lt;br/&gt;

&lt;p&gt;&lt;img src=&quot;/images/image-20210204173823314.png&quot; alt=&quot;image-20210204173823314&quot;&gt;&lt;/p&gt;
&lt;p&gt;ìœ„ì™€ ê°™ì€ ë¬¸ì œë¡œ, RNNê°™ì´ sequentialí•œ ë¬¸ì œë“¤ì„ í•´ê²°í•  ë•Œ, ì¤‘ê°„ì— ë‹¨ì–´ê°€ ë¹ ì§€ê±°ë‚˜ í•˜ë©´ í•´ê²°í•˜ê¸°ê°€ ì–´ë ¤ì›€&lt;/p&gt;
&lt;p&gt;â€”&amp;gt; ì—¬ê¸°ì„œ ë‚˜ì˜¨ê²Œ Attentionì„ ì‚¬ìš©í•œ Transformer&lt;/p&gt;</description>
      
      
      
      <content:encoded><![CDATA[<p><br/><br/></p><h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><br/><h2 id="Sequential-Model"><a href="#Sequential-Model" class="headerlink" title="Sequential Model"></a>Sequential Model</h2><br/><p><img src="/images/image-20210204173823314.png" alt="image-20210204173823314"></p><p>ìœ„ì™€ ê°™ì€ ë¬¸ì œë¡œ, RNNê°™ì´ sequentialí•œ ë¬¸ì œë“¤ì„ í•´ê²°í•  ë•Œ, ì¤‘ê°„ì— ë‹¨ì–´ê°€ ë¹ ì§€ê±°ë‚˜ í•˜ë©´ í•´ê²°í•˜ê¸°ê°€ ì–´ë ¤ì›€</p><p>â€”&gt; ì—¬ê¸°ì„œ ë‚˜ì˜¨ê²Œ Attentionì„ ì‚¬ìš©í•œ Transformer</p><span id="more"></span><br/><h2 id="Transformer-1"><a href="#Transformer-1" class="headerlink" title="Transformer"></a>Transformer</h2><br/><ul><li>Transformer is the first sequence transduction model based entirely on attention</li><li>RNNì²˜ëŸ¼ ì¬ê·€ì ì¸ê²Œ ì•„ë‹ˆë¼ based on attention</li></ul><p><img src="/images/image-20210204174108604.png" alt="image-20210204174108604"></p><ul><li>from a birdâ€™s-eye view, this is what the Transformer does for machine translation tasks</li></ul><p><img src="/images/image-20210204185901783.png" alt="image-20210204185901783"></p><p>ê²°êµ­ì€ sequence to sequnece (ë¶ˆì–´ -&gt; ì˜ì–´ )machine translation</p><p>ì…ì¶œë ¥ sequence ëŠ” ìˆ«ìê°€ ë‹¤ë¥¼ìˆ˜ ìˆë‹¤</p><p><img src="/images/image-20210204185951005.png" alt="image-20210204185951005"></p><p>ëª¨ë¸ì€ í•˜ë‚˜ì„. 100ê°œê°€ ë“¤ì–´ê°€ë„ 100ë²ˆ ì¬ê·€ì ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ”ê²Œì•„ë‹ˆë¼ í•œë²ˆì— nê°œë¥¼ ì²˜ë¦¬</p><p>generationí• ë•ŒëŠ” 1ë‹¨ì–´ì”© ë§Œë“¤ê²Œ ëœë‹¤</p><p>ë™ì¼í•œêµ¬ì¡°ë¥¼ ê°€ì§€ì§€ë§Œ ê³µìœ í•˜ì§€ ì•ŠëŠ” encoderì™€ decoderê°€ stackë˜ì–´ìˆë‹¤</p><p>encoderê°€ ë°”ë€”ìˆ˜ ìˆëŠ” nê°œì˜ ë‹¨ì–´ë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ëŠ”ì§€</p><p>1ê°œì˜ encoderì— nê°œì˜ ë‹¨ì–´ê°€ í•œë²ˆì— ë“¤ì–´ê°„ë‹¤</p><p>self attention + Feed Forward Neural Network -&gt;next encoder</p><p>Self- Attention is the cornerstone of Transformer</p><h2 id="Transformer-2"><a href="#Transformer-2" class="headerlink" title="Transformer"></a>Transformer</h2><p><img src="/images/image-20210205094243692.png" alt="image-20210205094243692"></p><p><img src="/images/image-20210205094305510.png" alt="image-20210205094305510"></p><p><img src="/images/image-20210205094323449.png" alt="image-20210205094323449"></p><p><img src="/images/image-20210205094338045.png" alt="image-20210205094338045"></p><p><img src="/images/image-20210205094354596.png" alt="image-20210205094354596"></p><p><img src="/images/image-20210205094421353.png" alt="image-20210205094421353"></p><p><img src="/images/image-20210205094434034.png" alt="image-20210205094434034"></p><p><img src="/images/image-20210205094446386.png" alt="image-20210205094446386"></p><p><img src="/images/image-20210205094508533.png" alt="image-20210205094508533"></p><p><img src="/images/image-20210205094524834.png" alt="image-20210205094524834"></p><p><img src="/images/image-20210205094724396.png" alt="image-20210205094724396"></p>]]></content:encoded>
      
      
      <category domain="https://jo-member.github.io/categories/Boostcamp/">Boostcamp</category>
      
      
      <category domain="https://jo-member.github.io/tags/Basic/">Basic</category>
      
      <category domain="https://jo-member.github.io/tags/RNN/">RNN</category>
      
      <category domain="https://jo-member.github.io/tags/Transformer/">Transformer</category>
      
      <category domain="https://jo-member.github.io/tags/NLP/">NLP</category>
      
      
      <comments>https://jo-member.github.io/2021/02/04/2021-02-04-Boostcamp14.2/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
