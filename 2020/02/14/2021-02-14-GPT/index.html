<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Paper Review) Improving Language Understanding by Generative Pre-Training - Jo Member</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Jo Member"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Jo Member"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="이번에는 openai에서 발표한 논문인 GPT를 review해보겠다 GPT3는 이전에 review한 transformer구조를 활용하여 Language understanding을 효과적으로 만들었다. Abstract  자연어를 이해는 text추론, 질문에 대한 대답, 의미의 유사성 평가, 문서분류등을 포함하고 있다. 라벨링 되지 않은 text들을 매우"><meta property="og:type" content="blog"><meta property="og:title" content="Paper Review) Improving Language Understanding by Generative Pre-Training"><meta property="og:url" content="https://jo-member.github.io/2020/02/14/2021-02-14-GPT/"><meta property="og:site_name" content="Jo Member"><meta property="og:description" content="이번에는 openai에서 발표한 논문인 GPT를 review해보겠다 GPT3는 이전에 review한 transformer구조를 활용하여 Language understanding을 효과적으로 만들었다. Abstract  자연어를 이해는 text추론, 질문에 대한 대답, 의미의 유사성 평가, 문서분류등을 포함하고 있다. 라벨링 되지 않은 text들을 매우"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://jo-member.github.io/2020/02/14/2021-02-14-GPT/assets/images/image-20210214174726972.png"><meta property="og:image" content="https://jo-member.github.io/2020/02/14/2021-02-14-GPT/assets/images/image-20210214174902969.png"><meta property="og:image" content="https://jo-member.github.io/2020/02/14/2021-02-14-GPT/assets/images/image-20210214180732689.png"><meta property="og:image" content="https://jo-member.github.io/2020/02/14/2021-02-14-GPT/assets/images/image-20210214181504691.png"><meta property="og:image" content="https://jo-member.github.io/2020/02/14/2021-02-14-GPT/assets/images/image-20210214181541269.png"><meta property="og:image" content="https://jo-member.github.io/2020/02/14/2021-02-14-GPT/assets/images/image-20210214181938559.png"><meta property="og:image" content="https://jo-member.github.io/2020/02/14/2021-02-14-GPT/assets/images/image-20210214182200590.png"><meta property="article:published_time" content="2020-02-13T15:00:00.000Z"><meta property="article:modified_time" content="2021-04-21T17:46:23.990Z"><meta property="article:author" content="jo-member"><meta property="article:tag" content="AI, Deep_learning, python, nlp, cv"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="assets/images/image-20210214174726972.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://jo-member.github.io/2020/02/14/2021-02-14-GPT/"},"headline":"Paper Review) Improving Language Understanding by Generative Pre-Training","image":["https://jo-member.github.io/2020/02/14/2021-02-14-GPT/assets/images/image-20210214174726972.png","https://jo-member.github.io/2020/02/14/2021-02-14-GPT/assets/images/image-20210214174902969.png","https://jo-member.github.io/2020/02/14/2021-02-14-GPT/assets/images/image-20210214180732689.png","https://jo-member.github.io/2020/02/14/2021-02-14-GPT/assets/images/image-20210214181504691.png","https://jo-member.github.io/2020/02/14/2021-02-14-GPT/assets/images/image-20210214181541269.png","https://jo-member.github.io/2020/02/14/2021-02-14-GPT/assets/images/image-20210214181938559.png","https://jo-member.github.io/2020/02/14/2021-02-14-GPT/assets/images/image-20210214182200590.png"],"datePublished":"2020-02-13T15:00:00.000Z","dateModified":"2021-04-21T17:46:23.990Z","author":{"@type":"Person","name":"jo-member"},"description":"이번에는 openai에서 발표한 논문인 GPT를 review해보겠다 GPT3는 이전에 review한 transformer구조를 활용하여 Language understanding을 효과적으로 만들었다. Abstract  자연어를 이해는 text추론, 질문에 대한 대답, 의미의 유사성 평가, 문서분류등을 포함하고 있다. 라벨링 되지 않은 text들을 매우"}</script><link rel="canonical" href="https://jo-member.github.io/2020/02/14/2021-02-14-GPT/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Jo Member" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/jo-member"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-9-tablet is-9-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2020-02-13T15:00:00.000Z" title="2020. 2. 14. 오전 12:00:00">2020-02-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-04-21T17:46:23.990Z" title="2021. 4. 22. 오전 2:46:23">2021-04-22</time></span><span class="level-item"><a class="link-muted" href="/categories/PaperReview/">PaperReview</a></span></div></div><h1 class="title is-3 is-size-4-mobile">Paper Review) Improving Language Understanding by Generative Pre-Training</h1><div class="content"><br/>

<p>이번에는 openai에서 발표한 논문인 GPT를 review해보겠다</p>
<p>GPT3는 이전에 review한 transformer구조를 활용하여 Language understanding을 효과적으로 만들었다.</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><br/>

<p>자연어를 이해는 text추론, 질문에 대한 대답, 의미의 유사성 평가, 문서분류등을 포함하고 있다. 라벨링 되지 않은 text들을 매우 넘처나지만, 특정 task의 학습을 위해 labed된 text들은 매우 적기때문에 좋은 모델을 학습시키는것은 매우 힘들다.  Language 모델을 unlabled된 text로 <em>generative pretrain</em>을 한이후 각각의 task에 맞게 fine-tunning을 하였다.  이러한 많은 unlabed text를 사용하여 학습하였다. 이전의 연구와는 달리,필요한 task에 fine-tuning하여 응용하는 것이 매우 효과적이다.</p>
<span id="more"></span>

<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><br/>

<p>Raw text를 사용하여 효과적인 NLP 학습을 하기위해서는 지도학습에 대한 의존성을 완화해야 한다. 많은 딥러닝 방법들은 labeled된 data를 사용해야 해서 한계가 존재한다. 이러한 상황에서 unlabed된 data는 시간과 노력이 필요한 annotation을 모으는 작업들을 대체할 수 있다. 만약 고려가능한 지도가 가능한 상황이라면, unsupervised 방법은 model의 성능을 증가시킬 수 있다. 이러한 방식은 pretrained된 word embedding을 사용하여 성능을 높이는것과 비슷한 이유이다.</p>
<p>unlabed된 data로 word-level의 정보보다 많은 정보를 활용하는것은 2가지 이유에서 매우 어렵다</p>
<ol>
<li>어떠한 종류의 optimization objective가 가장 효과적으로 text를 표현할수 있을까 가 매우 unclear하다</li>
<li>우리가 원하는 특정 task에 효과적으로 적용하는 방법에 대한 의견이 일치가 되징 않았다. 현재 존재하는 방법은 model에 특정한 task-specific한 변화를 가하는 것과, 복잡한 학습방법,그리고 학습을 도와주는 몇몇 learning objective들을 넣어주는, 이러한 방법들의 combination이다</li>
</ol>
<p>이러한 불확실성은 language processing에서의 효과적인 semi-supervised learning을 발전시키기 힘들게 만든다.</p>
<br/>

<p>이 논문에서는 unsupervised pre-training과 supervised fine-tunning을 조합한 방법을 사용하여 semi-supervised approach를 하였다. 목적은 가장 보편적으로 학습하여 약간의 응용으로 다양한 분야에 적용시키는것이다. </p>
<p>2-stage로 나누어 train하였다</p>
<ol>
<li>초기 parameter를 학습하기 위해 unlabeled data를 사용하여 pre-train 하였다 / with transformer</li>
<li>우리는 이 parameter들을 특정한 task에 맞는 supervised objective 학습에 사용하였다.</li>
</ol>
<p>또한 model에서 <em>Transformer</em>를 사용하여 long-term dependencies를 해결하였다.</p>
<br/>

<h2 id="2-Related-Work"><a href="#2-Related-Work" class="headerlink" title="2. Related Work"></a>2. Related Work</h2><p><strong>Semi-supervised learning for NLP</strong></p>
<p>우리의 work는 Semi-supervied learning의 범주안에있다. 이 ssl은 sequence labeling, text 분류등에 쓰이면서 큰 관심을 받고 있다. 가장 초기에는 unlabeled data를 supervised learning의 feature로 사용하여 word나 phrase level의 통계를 계산하는데 사용되었다. 최근 몇년동안 word-embedding이 얼마나 좋은지 밝혀냈다. 이러한 접근은 word-level의 정보를 특정한 high-level에 맞추어 준다. 최근에는 word-level이 아닌 phrase나 sentence level의 embedding을 사용하여 text를 다양한 target task의 vector representation을 나타내 주었다.</p>
<br/>

<p><strong>Unsupervised pre-training</strong></p>
<p>Unsupervised pre-training은 supervised learning을 바꾸는거 보다는 좋은 initialization을 찾는게 목적이다. 각각의 연구들은 image classification과 regression task의 기술이 사용되었다. Pre-training은 정규화 과정에서 generalization성능을 올려준다. </p>
<p>우리의 연구는 language modeling으로 model을 pre-train한후 task에 맞게 fine-tuning해주는 것이다. Pre-training이 언어적인 정보를 잘 잡아낼수 있지만,이전연구에서 사용된 LSTM을 사용하는 것은 긴 data를 해석하지 못한다는 단점이 존재한다. 따라서 우리는 Transformer를 사용하였다.또다른 연구에서는 몇몇 보조적인 feature들을 삽입해주어 성능을 향상시켰지만, 이는 새로운 parameter의 증가를 야기한다. 우리의 GPT는 transfer과정에서 최소한의 수정만을 필요로 한다.</p>
<br/>

<p><strong>Auxiliary training objectives</strong></p>
<p>여러 보조적인 unsupervised training은 semi-supervised learning의 대채적인 형태이다. 이전의 연구에서는 다양한 종류의 보조적인 NLP방법론(POS tagging, chunking,등등등)을 사용하였다. 최근 또다른 연구는 보조적인 language model를 추가하여 sequence labeling의 성능향상을 이야기 하였다. </p>
<br/>

<h2 id="3-Framework"><a href="#3-Framework" class="headerlink" title="3. Framework"></a>3. Framework</h2><p>학습과정은 2개의 stage로 나누어져 있다</p>
<ol>
<li>unlabeled된 큰 말뭉치를 사용하여 가장 범용적인 language model을 학습하는 stage</li>
<li>이후 labeled data를 사용한 fine-tuning stage</li>
</ol>
<br/>

<p><strong>3.1 Unsupervised pre-training</strong></p>
<p>unsupervised의 token들 = <img src="assets/images/image-20210214174726972.png" alt="image-20210214174726972">이 주어지고, 이어지는 likelihood를 maximize하기위해 보편적인 language model을 사용한다.</p>
<img src="assets/images/image-20210214174902969.png" alt="image-20210214174902969" style="zoom:150%;" />

<p>k는 context의 size이고, conditional prob P는 NN을 사용하여 modeled</p>
<p>이들은 모두 SGD를 사용하여 training했다.</p>
<p><em>multi-layer Transformer decoder</em>를 사용했다.</p>
<p>이 model은 input context tokens에 multi-headed self-attention을 활용하였고, 이후에 position-wise feedforward layer를 적용하여 target token에대한 output distribution을 구한다.</p>
<p><img src="assets/images/image-20210214180732689.png" alt="image-20210214180732689"></p>
<p>U는 token의 context vector이고, n은 layer의 숫자, W<del>e</del>는 token embedding matrix, W<del>p</del>는 position embedding matrix이다.</p>
<br/>

<p><strong>3.2 Supervised fine-tuning</strong></p>
<p>model을 train한후, supervised target test에 맞추어서 parameter를 적용한다. labeled된 dataset C(각각은 input token의 sequence로 이루어짐 ((x^1^,…,x^m^) and label y )) </p>
<p>Input은 pre-trained된 model을 통과하여 최종 transformer block의 activation인 h<del>l</del>^m^을 얻어내고, 이후에 linear output layer에 W<del>y</del>와 함께 들어간다. </p>
<p><img src="assets/images/image-20210214181504691.png" alt="image-20210214181504691"></p>
<p>이는 이후의 objective를 maximize하게 한다.</p>
<p><img src="assets/images/image-20210214181541269.png" alt="image-20210214181541269"></p>
<p>보조적인 장치로 language modeling을 사용하여 fine-tuning을 하는것은 (1) generalization성능을 높힌다 (2) 수렴속도를 높힌다. 우리는 아래의 objective를 optimize한다</p>
<p><img src="assets/images/image-20210214181938559.png" alt="image-20210214181938559"></p>
<p>Fine-tuning중에 유일한 extra parameter은 W<del>y</del>와 구분token을 위한 embedding이다.</p>
<p><img src="assets/images/image-20210214182200590.png" alt="image-20210214182200590"></p>
<p><strong>3.3 Task-specific input transformations</strong></p>
<p>text classification가 같은 몇몇 분야에서, 위에서 묘사했던대로 우리의 model을 fine-tune할 수 있었다. 질의응답과, textual entailment와 같은 문제에는 input을 ordered sentence pairs, triplets of document, question, answer으로 해주었다. 우리의 pre-trained model이 연속적인 sequence에서 학습되었기 때문에, 이러한 문제들에는 약간의 맞춤 수정이 필요하다.  이전의 연구들은 transffered representation위에 특정 architecture를 삽입하는 형태로 학습해왔다. 이는 많은양의 cutomization이 필요하며 이러한 추가적인 특정 architecture에는 transfer learning을 사용하지 않았다. 대신 우리는 traveral-stple approach(input을 정렬된 sequence로 만들어)를 사용하여 우리의 pre-trained model이 학습할 수 있게 하였다. 이러한 input의 조정은 문제상황에 따라 architecture의 큰 수정을 하지 않아도 되게 한다. 모든 transformation은 randomly initialized된 start,ending token을 포함한다.</p>
<br/>

<ol>
<li>Textual entailment(문장의 포함관계) : 전제 p와 가설 h 중간에 delimiter token $를 삽입하여 합쳐주었다.</li>
<li>Similarity (문장의 유사도 평가) : 두개의 비교대상은 순서가 딱히 없다. 한마디로 동등한 level에서 비교해야 되기 때문에 모든 가능한 순서를 사용하고 transformer이후에 나오는2개의 h<del>l</del>^m^  을 합쳐준다.</li>
<li>Question Answering and Commonsense Reasoning (질의응답) : </li>
</ol>
<h2 id="3-Model-Atchitecture"><a href="#3-Model-Atchitecture" class="headerlink" title="3. Model Atchitecture"></a>3. Model Atchitecture</h2><br/>











<p>language model -&gt; label이 필요가 없다</p>
<p>주어진 단어들을 가지고 다음단어를 예측하는</p>
<ol>
<li><p>Generative model</p>
<p>Generative model</p>
<p>data가 많아 질수록 정확도가 높아진다</p>
</li>
<li><p>Discriminative model</p>
<p>타이타닉같은</p>
<p>데이터가 많지 않을때 패턴파악이 쉬워서 많이들 사용한다</p>
<p>한정된 data에 과적합 되기가 쉽다</p>
</li>
<li><p>sample된 data로는 왜곡된 판단을 할 수 있다</p>
</li>
</ol>
<p>GPT는 unlabeled된 data로</p>
<ol>
<li><p>Pretraining LM</p>
</li>
<li><p>finefuning</p>
<p>데이터만 task관련데이터로 학습 model은 그대로</p>
</li>
</ol>
<p>Naural Language Inference -&gt; entailment contradiction파악</p>
<p>질의응답</p>
<p>비슷한 문장 판별</p>
<p>주어진 문장을 그룹으로 분류하는</p>
<p>비지도 학습 label이 있는 data로 fine tunning한다.</p>
<p>기존 language model 학습 공식과 같다</p>
<p>transformer의 decoder로 구성</p>
<p>layer추가없이 pretrained LM</p>
<p>byte pair embedding을 사용하였다</p>
<p>신조어 오탈자에 약한 word embedding이 아닌</p>
<p>byte pair. —–&gt; hack,able, deep, learn, ing</p>
<p>이런식으로 embedding을 하였다.</p>
<p>data가 주어졌을떄</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Paper Review) Improving Language Understanding by Generative Pre-Training</p><p><a href="https://jo-member.github.io/2020/02/14/2021-02-14-GPT/">https://jo-member.github.io/2020/02/14/2021-02-14-GPT/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>jo-member</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2020-02-14</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2021-04-22</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icon" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="notification is-danger">You need to set <code>install_url</code> to use ShareThis. Please set it in <code>_config.yml</code>.</div></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" href="/" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>Afdian.net</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/" alt="Alipay"></span></a><a class="button donate" href="/" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a><a class="button donate" href="/" target="_blank" rel="noopener" data-type="patreon"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><div class="notification is-danger">You forgot to set the <code>business</code> or <code>currency_code</code> for Paypal. Please set it in <code>_config.yml</code>.</div><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/02/16/2021-02-15-Boostcamp16.1/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Day17) RNN</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/02/05/2021-02-05-Boostcamp15.1/"><span class="level-item">Day15) Generative Models</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div class="notification is-danger">You forgot to set the <code>shortname</code> for Disqus. Please set it in <code>_config.yml</code>.</div></div></div></div><div class="column column-left is-3-tablet is-3-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Abstract"><span class="level-left"><span class="level-item">1</span><span class="level-item">Abstract</span></span></a></li><li><a class="level is-mobile" href="#1-Introduction"><span class="level-left"><span class="level-item">2</span><span class="level-item">1. Introduction</span></span></a></li><li><a class="level is-mobile" href="#2-Related-Work"><span class="level-left"><span class="level-item">3</span><span class="level-item">2. Related Work</span></span></a></li><li><a class="level is-mobile" href="#3-Framework"><span class="level-left"><span class="level-item">4</span><span class="level-item">3. Framework</span></span></a></li><li><a class="level is-mobile" href="#3-Model-Atchitecture"><span class="level-left"><span class="level-item">5</span><span class="level-item">3. Model Atchitecture</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Boostcamp/"><span class="level-start"><span class="level-item">Boostcamp</span></span><span class="level-end"><span class="level-item tag">24</span></span></a></li><li><a class="level is-mobile" href="/categories/Further-Q/"><span class="level-start"><span class="level-item">Further_Q</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Mathmatics-for-ML/"><span class="level-start"><span class="level-item">Mathmatics_for_ML</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/PaperReview/"><span class="level-start"><span class="level-item">PaperReview</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/blog/"><span class="level-start"><span class="level-item">blog</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-02-02T15:00:00.000Z">2021-02-03</time></p><p class="title"><a href="/2021/02/03/2021-02-03-Boostcamp13.1/">Day13) CNN1</a></p><p class="categories"><a href="/categories/Boostcamp/">Boostcamp</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-02-01T15:00:00.000Z">2021-02-02</time></p><p class="title"><a href="/2021/02/02/2021-02-02-Boostcamp12.1/">Day12) Optimization</a></p><p class="categories"><a href="/categories/Boostcamp/">Boostcamp</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-01-28T15:00:00.000Z">2021-01-29</time></p><p class="title"><a href="/2021/01/29/2021-01-29-week2/">Week2</a></p><p class="categories"><a href="/categories/Further-Q/">Further_Q</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-29T15:00:00.000Z">2020-12-30</time></p><p class="title"><a href="/2020/12/30/2020-12-30-ML&amp;Mathmatics/">Introduction and Motivation</a></p><p class="categories"><a href="/categories/Mathmatics-for-ML/">Mathmatics_for_ML</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-12-29T15:00:00.000Z">2020-12-30</time></p><p class="title"><a href="/2020/12/30/2020-12-30-ML&amp;Mathmatics2/">Linear Algebra</a></p><p class="categories"><a href="/categories/Mathmatics-for-ML/">Mathmatics_for_ML</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Jo Member" height="28"></a><p class="is-size-7"><span>&copy; 2021 jo-member</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>