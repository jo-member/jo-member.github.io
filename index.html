<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Jo Member</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Jo Member"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Jo Member"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="끄적끄적"><meta property="og:type" content="blog"><meta property="og:title" content="Jo Member"><meta property="og:url" content="https://jo-member.github.io/"><meta property="og:site_name" content="Jo Member"><meta property="og:description" content="끄적끄적"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://jo-member.github.io/img/og_image.png"><meta property="article:author" content="jo-member"><meta property="article:tag" content="AI, Deep_learning, python, nlp, cv"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://jo-member.github.io"},"headline":"Jo Member","image":["https://jo-member.github.io/img/og_image.png"],"author":{"@type":"Person","name":"jo-member"},"description":"끄적끄적"}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Jo Member" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item is-active" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/jo-member"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-07-12T03:09:10.000Z" title="2021. 7. 12. 오후 12:09:10">2021-07-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-12T07:38:39.914Z" title="2021. 7. 12. 오후 4:38:39">2021-07-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Competition/">Competition</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/07/12/VQA/">VQA (Visual Question Answering)</a></h1><div class="content"><p>Boostcamp에서 만난 동료들과 함께 <a target="_blank" rel="noopener" href="https://www.aiconnect.kr/main/competition/list">2021 인공지능 온라인 경진대회</a>에 참여했습니다.<br>총 10개의 과제중 시각장애인 시스템 개발을 위한 VQA 모델이라는 Competition에 참여하였습니다.</p>
<h2 id="개요"><a href="#개요" class="headerlink" title="개요"></a>개요</h2><p><strong>이미지를 보고 주어진 질문에 답변하는 Visual Question Answering 모델 개발</strong><br>VQA란 시각정보를 기반으로 질문에 답변하는 시스템입니다.<br>실내 및 실외 생활 거주 환경에서 촬영된 이미지와 그에 관련된 질문, 대답이 세트로 이루어져 있습니다.<br>총 224,464개의 이미지 파일과 702,135건의 질문-답변 쌍이 train data로 주어졌습니다.</p>
<h2 id="관련-논문-review"><a href="#관련-논문-review" class="headerlink" title="관련 논문 review"></a>관련 논문 review</h2><ol>
<li><a href="">VQA: Visual Question Answering</a></li>
<li>Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering</li>
<li>Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge</li>
<li>Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks</li>
<li>UNITER: UNiversal Image-TExt Representation Learning</li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-04-25T11:52:06.000Z" title="2021. 4. 25. 오후 8:52:06">2021-04-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-05-22T10:02:18.393Z" title="2021. 5. 22. 오후 7:02:18">2021-05-22</time></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/04/25/Pstage3-Image-Segmentation-Detection/">Pstage3_Image_Segmentation_Detection</a></h1><div class="content"><h1 id="Image-Segmentation"><a href="#Image-Segmentation" class="headerlink" title="Image Segmentation"></a>Image Segmentation</h1><p><a target="_blank" rel="noopener" href="https://github.com/bcaitech1/p3-ims-obd-hansarang">https://github.com/bcaitech1/p3-ims-obd-hansarang</a></p>
<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><ul>
<li><p>문제정의 : 쓰레기가 찍힌 사진에서 쓰레기를 Segmentation </p>
</li>
<li><p><strong>Input data</strong> :  4109장의 쓰레기 사진중, 3287장 (80%)는 train data, 나머지 812장(20%)는 private test data  (512,512)의 이미지</p>
<ul>
<li><p><strong>Annotation</strong> </p>
<ol>
<li>train_all.json: train에 쓰일 수 있는 모든 image, annotation 정보 (image: 3272, annotation: 26400)</li>
<li>train.json: train_all.json 중 4/5에 해당하는 정보 (image: 2617, annotation: 21116)</li>
<li>val.json: train_all.json 중 1/5에 해당하는 정보 (image: 655, annotation: 5284)</li>
<li>test.json: 예측해야할 이미지들의 정보 (image: 837)</li>
</ol>
<ul>
<li>id: 파일 안에 annotation 고유 id, 이건 한 image 안에 여러가지의 객체가 있기 떄문에 image별로 각각의 객체의 annotation들이 있다.</li>
<li>segmentation: masking 되어 있는 고유의 좌표</li>
<li>bbox: 객체가 존재하는 박스의 좌표 (x_min, y_min, w, h)</li>
<li>area: 객체가 존재하는 영역의 크기</li>
<li>category_id: 객체가 해당하는 class의 id</li>
<li>image_id: annotation이 표시된 이미지 고유 id</li>
</ul>
</li>
<li><p>images</p>
<ul>
<li>id: 파일 안에서 image 고유 id, ex) 1</li>
<li>height: 512</li>
<li>width: 512</li>
<li>file_name: ex) batch_01_vt/002.jpg</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Output data</strong> : 11 class = {UNKNOWN, General trash, Paper, Paper pack, Metal, Glass, Plastic, Styrofoam, Plastic bag, Battery, Clothing}</p>
</li>
<li><p><strong>평가 Metric</strong></p>
<img src="../images/image-20210426120429513.png" alt="image-20210426120429513" style="zoom:50%;" />

<img src="../images/image-20210426120549788.png" alt="image-20210426120549788" style="zoom:50%;" /></li>
</ul>
<p>벌써 2주전의 기억이라 가물가물하지만 일렬의 과정들을 하나하나 되짚어 보며 이어나가도록 하겠습니다.</p>
<p>deeplab V3+, efficientnet-b5</p>
<ol>
<li>EDA</li>
</ol>
<p>먼저 EDA 부터 진행하였습니다. 수업에서 제공해주신 eda들로 우리 data의 label분포를 확인할 수 있었고, 따로 이미지 data를 시각화를 해보며 이전의 stage와 마찬가지로 상당히 imbalance하다는 사실을 알게되었습니다. </p>
<p>이에 stage 2때도 적용하였던 focal loss와 다양한 augmentation을 사용하여 해결해야겠다는 생각이 들었습니다.</p>
<ol start="2">
<li>Model</li>
</ol>
<p>위에서 언급한것 처럼 처음부터 sota에 가까운 deeplab V3+를 선정하였고, 효율적이고 다양한 실험과정을 위해 backbone은 efficientnet b1으로진행하였습니다. 이에 작은 model에서의 parameter가 과연 큰 model에서도 똑같이 적용될까라는 의문이 들었지만, 이는 lr이나 scheduler에 해당한다고 생각이 되어, augmentation실험에서만 model의 size를 낮추었습니다.</p>
<p>가장처음 한 실험은 제기억에는 동일조건에서의  backbone에 따른 성능이였습니다.</p>
<p>다양한 크기의 Resnext와 efficientNet으로 실험을 진행하였고, 결론적으로 efficientNet-b5를 backbone으로 쓴 model이 가장 성능이 좋았습니다.<br>Resnext는 efficientNet에 비해 수렴속도도 빠르고 epoch당 시간도 적게 걸려, 이후의 앙상블을 위해 best model을 저장해 두었습니다. </p>
<ol start="3">
<li>Augmentation</li>
</ol>
<p>이번 task에서 쓰게된 augmentation은 아래와 같습니다</p>
<ol>
<li>HorizontalFlip(p=0.5)</li>
<li>Rotate(p=0.5, limit=45)</li>
<li>Cutout(num_holes=4, max_h_size=20, max_w_size=20),            </li>
<li>CLAHE(),            </li>
<li>RandomBrightnessContrast(p=0.5),            </li>
<li>Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0)</li>
</ol>
<p>이렇게 조합해서 썼을때 가장 성능이 좋았다는 결론을 얻었었습니다.<br>다양한 조합과 확률 값들을 적용하여 비교하여 진행하는 일련의 과정들은 매우 고되고 많은 시간을 필요로 하였습니다.<br>여기서 지금와서 생각해보면 Auto Augmentation을 적용해 보았으면 좋았을듯 싶습니다…</p>
<p>또한 추가적으로 horizontalflip을 이용한 tta를 적용시켜 보았지만, 성능의 하락을 야기했습니다.</p>
<ol start="4">
<li>Loss &amp; Optimizer &amp; Scheduler</li>
</ol>
<p>Loss는 Focal loss와 soft-crossentropy-loss를 각각 0.3,0.7의 가중치를 두어 학습하였습니다. 원래는 Focal만을 사용하였지만, stage1에서 multi loss에서 재미를 많이 봤었기 때문에, 마스터님의 의견을 듣고 scl을 추가해 주었습니다.</p>
<p>왜인지는 모르겠지만  soft-crossentropy-loss만을 사용하였을때 가장 성능이 좋아, 앙상블때의 다양성을 위해 multiloss로도 학습을 해두었습니다.</p>
<p>Optimizer또한 Adam계열의 Adamp를 사용하였고, Adam계열과 잘어울리는 Customized된 CosineAnnealingWarmRestarts의 scheduler를 사용하였습니다. 확실이 중간중간에 lr을 높혀주는게 local minimum을 잘빠져나오는 모습을 확인 할 수있었습니다. 내부에 내장된 Cosin scheduler은 gamma가 없기때문에 customized된 scheduler를 불러다 사용하였습니다. Adam에 잘맞는 cosine 계열의 scheduler를 사용한 결과, steplr을 사용한 타 팀원의 model 대비 제 model의 성능이 잘나왔음을 확인하였습니다.</p>
<p>wandb의 그래프를 보시면 보통 18 epoch쯤에서 최고점을 찍고 수렴하는 모습을 관찰하였습니다.</p>
<ol start="5">
<li>K-fold &amp; Pseudo Labeled data</li>
</ol>
<p>single model의 성능의 한계에 부딛혀 0.63대를 헤어나오지 못하고있었던 2주차…<br>기존의 최고성능 parameter를 고정하고 Train+all과 pseudo labeled된 data를 합쳐서 2배의 data로 학습을 진행하였고 결과는 매우 성공적이였습니다. K-fold로 진행하고 싶었지만, GPU자원의 부족으로 인한 시간의 한계때문에 Train-all로 진행하여 제가 경험적으로 체득한 18 epoch에서 끊는 방식을 체택하였습니다. 결과는 매우성공적으로 single model 기준 0.6842라는 큰 성능향상을 얻어내었습니다.</p>
<p>다른 팀원분들도 pseudo label을 적용하여 앙상블을 하였다면 더 좋은 결과를 얻어낼 수 있었을텐데 매우 아쉽습니다.</p>
<ol start="6">
<li>앙상블</li>
</ol>
<p>최종적으로 저의 다양한 backbone과 loss를 가지는 model들을 조합하여 soft voting을 하였습니다. 가중치는 LB상으로 가장높은 model에 0.4를 주었고 나머지에 0.2씩을 주어 총 4개의 singel   model을 앙상블 하여 제출을 해봤는데, 0.6961이라는 아주 높은 점수가 나왔습니다. 이 model에 다른 팀원분들의 model hard voting 해보았지만 성능이 계속 하락하여 결국에는 저의 model만을 사용한 점수가 최종점수가 되는 아쉬운 상황이 연출되었습니다…</p>
<p>어느정도 팀원들간의 평균적인 점수대가 비슷해야 앙상블 했을때 좋은 점수를 낼수있었지만, psudo label을 저만 돌렸었기 때문에…<br>시간이 2일정도 더있었다면 다른 팀원 분들도 수도라벨로 성능을 어느정도 향상시켜 비슷한 점수대로 맞춰줄수 있었을 텐데 하는 아쉬움이 남았습니다…</p>
<h1 id="Object-Detection"><a href="#Object-Detection" class="headerlink" title="Object Detection"></a>Object Detection</h1><ul>
<li><strong>평가 Metric</strong></li>
</ul>
<p><img src="../images/image-20210522134724067.png" alt="image-20210522134724067"></p>
<p><img src="../images/image-20210522140707268.png" alt="image-20210522140707268"></p>
<p>위와 같은 PB curve를 그린다. 이 때 recall과 precision은 confidence score별로 점들이 생성됩니다.<br>이후 (A+B)에 해당하는 영역의 넓이가 AP가 되고, 각각의 class의 AP의 평균이 저희가 구하려는 mAP입니다.</p>
<p>이번 object task에서는 mmdetection이라는 강력한 tool을 기반으로 실험을 진행하였습니다.<br>mmdetection에서는 저희가 config파일만을 수정하여 준다면 손쉽게 다양한 방법으로 다양한 model들을 실험해 볼 수있었습니다.</p>
<ol>
<li>Model</li>
</ol>
<p>이번 task에서또한 sota model로 알려진 swin transformer를 backbone으로 쓰고 detector 부분은 cascade mask rcnn과 htc를 사용하였습니다.<br>다행이도 Swin transformer의 config파일이 git에 전부 올라와있었고, 저희의 실험환경에 맞게 조금 변경해 주면 되었습니다. 하지만 이 mmdetection이라는 툴자체에 적응을 하는데 시간이 좀 소요가 되었고, 한 3-4일 정도가 지나서야 어느정도 가닥이 잡히면서 어떻게 써야할지 감이 잡혔던것 같습니다.</p>
<p>backbone을 고정한 후 neck을 변경시켜서 다양한 실험을 해보았습니다.</p>
<ol>
<li>FPN</li>
<li>PAFPN </li>
<li>NAS-FPN</li>
<li>BiFPN</li>
</ol>
<p>이렇게 4가지의 선택지가 있었는데 이중 가장 오래된 FPN을 선택한 이유는 한가지 입니다. 왜냐하면 pretrained된 pth파일을 github에서 제공해주고 있는데, 이 model에서 FPN을 쓰고있기 때문입니다.</p>
<p>처음에는 backbone만을 pretrained된걸 가져와서 쓰다가, 전체가 trained된 model이 있는것을 발견하고 실험해보았는데 전체가 pretrained된걸 가져와서 저희 task에 fine tuning? transfer learning하는 방식이 더욱 성능이 좋았습니다. </p>
<p>FPN으로 trained된 전체 model을 가져다가 NAS-FPN으로 바꾸어준 model에 적용을 시켜줄시 neck쪽의 weight들에는 값이 들어가지 않게됩니다. 이것이 성능이 더 좋을 수도 있기때문에 이러한 방법도 시도해 보았지만, 바꾸지 않고 그대로 FPN을 사용하는것이 더 좋았습니다.</p>
<p>한가지 아쉬웠던 것은 pretrained된 Swin transformer를 backbone으로 쓰면서 swin에 대한 어느정도 전반적인 이해만을 가지고 있었을뿐, 세세한 model의 구조는 알지 못한채 작성되어진 config 파일만을 가지고 실험에만 집중할 수 밖에 없었던 상황이였습니다.</p>
<p>약간씩 parameter들을 수정해 주면서, 근본적인 이해없이 직관에 의해 실험을 반복하고 있는 제 자신을 발견한 후 competition에 대한 약간의 회의감이 들었습니다. 하지만 멘토님께서 library를 잘다루는 것도 하나의 능력이라고 말씀해주셔서 다시 한번 생각해 보았던것 같습니다.</p>
<ol start="2">
<li>Augmentation</li>
</ol>
<p>Augmentation에는 Flip과 Autoaugmentation, Normalize등을 적용해보았습니다.<br>가장 critical하게 작용했던 augementation이 바로 autoaug로, 여기서 resize와 crop size를 어떻게 주느냐에 따라 성능차이가 조금씩 발생했습니다. 이전 stage들에서의 경험으로, image task에서 high scale의 image training은 오랜 시간을 요구하지만 그만큼 성능이 잘나왔습니다. 따라서 resize의 list에는 upscale된 정사각형과 가로가 긴 직사각형, 세로가 긴 직사각형등을 고루 섞어 autoaug안에 인자로 넣어주었습니다.</p>
<p>이러한 변경점은 정사각형만을 넣어줬을때, low scaleing 해주었을때에 비해서 점수의 큰 향상을 야기했습니다.</p>
<ol start="3">
<li>Loss Optimizer Scheduler</li>
</ol>
<p><strong>Loss</strong></p>
<p>저희가 바꾸어 줄 수있었던 loss는 bbox loss로 3가지 정도의 선택지가 있었습니다. 그중 DIoU Loss를 채택하였을때 성능이 약간 상승했고, classification loss쪽의 cross entropy loss는 건드리지 않았습니다.  </p>
<p><strong>Optimizer</strong> </p>
<p>Optimizer은 AdamW를 사용하였고, 초기 lr값은 1e-4으로 고정시켜 주었습니다.</p>
<p><strong>Scheduler</strong></p>
<p>Scheduler은 model에 따라 다르게 적용시켜 주었습니다.</p>
<p>HTC를 이용한 model에는 cosineannealing을 cascade mask rcnn을 적용한 model에는 steplr을 사용하였습니다.</p>
<p>StepLR을 사용시 어떠한 epoch에서 lr값을 감소시켜줄지를 정할 수 있었는데, 평균적으로 8,11 epoch에서 map50값이 수렴하기 시작하는것을 확인하고 이쯤에서 gamma=0.1의 factor로 lr값을 감소시켜주었습니다.</p>
<ol start="4">
<li>Pseudo-labeling</li>
</ol>
<p>이전 segementation에서 pseudo labeling으로 큰 재미를 보았었기 때문에 이번 task에서는 좀 일찍 최고성능의 model로 pseudo data를 만들어 빠르게 실험해 보았습니다. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./train_all.json&#x27;</span>) <span class="keyword">as</span> json_file1:</span><br><span class="line">    train_data = json.load(json_file1)</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./test.json&#x27;</span>) <span class="keyword">as</span> json_file2:</span><br><span class="line">    test_data = json.load(json_file2)</span><br><span class="line"></span><br><span class="line">start = <span class="built_in">len</span>(train_data[<span class="string">&#x27;images&#x27;</span>])</span><br><span class="line">train_id = train_data[<span class="string">&#x27;images&#x27;</span>]</span><br><span class="line">test_id = test_data[<span class="string">&#x27;images&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> test_id:</span><br><span class="line">    idx[<span class="string">&#x27;id&#x27;</span>] = start</span><br><span class="line">    start+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">PredictionString = pd.read_csv(<span class="string">&#x27;./output1.csv&#x27;</span>)[<span class="string">&#x27;PredictionString&#x27;</span>]</span><br><span class="line">annotation = []</span><br><span class="line">ids = <span class="number">26402</span></span><br><span class="line">image_id = start</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> bboxs <span class="keyword">in</span> PredictionString:</span><br><span class="line">    bboxs = bboxs.strip().split(<span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    bboxs = [<span class="built_in">float</span>(i) <span class="keyword">for</span> i <span class="keyword">in</span> bboxs]</span><br><span class="line">    bboxs = [bboxs[i:i + <span class="number">6</span>] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="built_in">len</span>(bboxs), <span class="number">6</span>)]</span><br><span class="line">    <span class="keyword">for</span> bbox <span class="keyword">in</span> bboxs:</span><br><span class="line">        prob = bbox[<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> prob&lt;<span class="number">0.8</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        temp = <span class="built_in">dict</span>()</span><br><span class="line">        temp[<span class="string">&#x27;id&#x27;</span>] = ids</span><br><span class="line">        temp[<span class="string">&#x27;image_id&#x27;</span>] = image_id</span><br><span class="line">        temp[<span class="string">&#x27;category_id&#x27;</span>] = <span class="built_in">int</span>(bbox[<span class="number">0</span>])</span><br><span class="line">        temp[<span class="string">&#x27;segmentation&#x27;</span>] = [[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]]</span><br><span class="line">        temp[<span class="string">&#x27;area&#x27;</span>] = <span class="number">1</span></span><br><span class="line">        bbox = bbox[<span class="number">2</span>:]</span><br><span class="line">        new = [bbox[<span class="number">0</span>],bbox[<span class="number">3</span>],bbox[<span class="number">2</span>]-bbox[<span class="number">0</span>],bbox[<span class="number">3</span>]-bbox[<span class="number">1</span>]]</span><br><span class="line">        new = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">list</span>(np.<span class="built_in">round</span>(new, <span class="number">1</span>))]</span><br><span class="line">        temp[<span class="string">&#x27;bbox&#x27;</span>] = new</span><br><span class="line">        temp[<span class="string">&#x27;iscrowd&#x27;</span>] = <span class="number">0</span></span><br><span class="line">        annotation.append(temp)</span><br><span class="line">        ids+=<span class="number">1</span></span><br><span class="line">    image_id+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">train_data[<span class="string">&#x27;images&#x27;</span>] += test_id</span><br><span class="line">train_data[<span class="string">&#x27;annotations&#x27;</span>] += annotation</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;./train+pseudo.json&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> outfile:</span><br><span class="line">    json.dump(json_data1, outfile,indent=<span class="number">4</span>)</span><br><span class="line">    </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>위의 코드로 pseudo data를 coco형태로 바꾸어준뒤 통합된 json 파일로 train을 진행하였습니다. 그러나 threshold값을 설정해주는게 매우 애매했다.<br>이에 따라 성능이 너무 하락하는 현상이 발생하였고 결국 pseudo label된 data는 쓰지 못하였습니다…</p>
<p>segementation에서 잘먹히던 pseudo label이 detection에서는 부정확한 label값들로 학습이 어려운가 봅니다.</p>
<ol start="5">
<li>WBF</li>
</ol>
<p>마지막으로 최고 single model 기준 htc와 cascade 모두 0.5572의 점수를 얻어냈고 총 4개의 model을 앙상블한 결과 0.5824의 결과를 얻어냈습니다.<br>이후 모든 팀원들의 csv 파일을 WBF하여 최종적인 score 0.5884를 얻어내었습니다.</p>
<p>Conclusion</p>
<p>한가지 가장 중요하게 느낀점은 이렇게 competition을 마친이후에 관련 논문들과 kaggle notebook들을 자세히 정독하며 쓰였던 방법론들과 model들을 상세하게 공부해야 겠다는 필요성입니다.</p>
<p>competition 진행중에 개선해야 할 사항은 중간중간 팀원들간의 평균적인 점수대를 맞추어 놓아야 최종 앙상블 과정에서 큰 성능 향상을 이룰수 있다는 점입니다. </p>
<p>굉장히 열정적인 4주를 보냈습니다… 아쉬움도 남고 후련하기도 합니다…<br>진행했던 많은 실험 내용들을 모두 랩업레포트에 담지 못했다…. 추후에 체계적으로 정리해서 git에 올려둬야겠습니다.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-04-22T06:29:38.000Z" title="2021. 4. 22. 오후 3:29:38">2021-04-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-04-29T09:28:32.668Z" title="2021. 4. 29. 오후 6:28:32">2021-04-29</time></span><span class="level-item"><a class="link-muted" href="/categories/Boostcamp/">Boostcamp</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/04/22/Pstage2-KLUE/">Pstage2_KLUE</a></h1><div class="content"><h1 id="문장내-개체관-관계-추출"><a href="#문장내-개체관-관계-추출" class="headerlink" title="문장내 개체관 관계 추출"></a>문장내 개체관 관계 추출</h1><p>뭔가 아쉬웠던 P-stage 2 KLUE가 끝이 났다.</p>
<p>이번 stage에서는 리더보드 순위를 올리는데에만 집중하기 보다는 다양한 task를 써보고 원리를 이해하고 결과를 토론계시판에 꼭 조금이라도 공유하는 방식으로 하기로 마음먹었었다.</p></div><a class="article-more button is-small is-size-7" href="/2021/04/22/Pstage2-KLUE/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-03-07T15:00:00.000Z" title="2021. 3. 8. 오전 12:00:00">2021-03-08</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-12T04:45:29.581Z" title="2021. 7. 12. 오후 1:45:29">2021-07-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Boostcamp/">Boostcamp</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/03/08/2021-03-08-Boostcamp31.1/">Image Classification</a></h1><div class="content"><br/>



<p>K Nearest Neighbors (k-NN)</p>
<p>기존의 data가 가지고있는 label을 활용해서 새로운 data의 label을 분류하는 문제가 된다. 이렇게 된다면 미리 유사도를 정의해야 한다. 그리고 system 복잡도가 너무 높다. 따라서 data를 NN의 parameter에 녹여넣는 것이다.</p>
<p>Yann Lecun의 CNN 개발 : 우편번호인식에 혁신을 이루어냄</p>
<p>Using better activation function   </p>
<p>annotation data의 효율적인 학습 기법 </p>
<p>data 부족문제의 완화 : 대표적인 방법들</p>
<ol>
<li>Data augmentation</li>
<li>Leveraging pre-trained information</li>
<li>Leveraging unlabeled dataset for training</li>
</ol></div><a class="article-more button is-small is-size-7" href="/2021/03/08/2021-03-08-Boostcamp31.1/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-22T15:00:00.000Z" title="2021. 2. 23. 오전 12:00:00">2021-02-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-12T04:44:38.284Z" title="2021. 7. 12. 오후 1:44:38">2021-07-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Boostcamp/">Boostcamp</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/23/2021-02-23-Boostcamp22/">Graph2</a></h1><div class="content"><h1 id="검색엔진에서의-그래프"><a href="#검색엔진에서의-그래프" class="headerlink" title="검색엔진에서의 그래프"></a>검색엔진에서의 그래프</h1><br/>

<h1 id="페이지랭크의-배경"><a href="#페이지랭크의-배경" class="headerlink" title="페이지랭크의 배경"></a>페이지랭크의 배경</h1><h3 id="1-1-웹과-그래프"><a href="#1-1-웹과-그래프" class="headerlink" title="1.1 웹과 그래프"></a>1.1 웹과 그래프</h3><p>웹(방향성이 있는 그래프) = 웹페이지(node) + 하이퍼링크(edge)</p>
<p>웹페이지는 추가적으로 키워드 정보를 포함하고있다.</p>
<h3 id="2-2-구글이전의-검색엔진"><a href="#2-2-구글이전의-검색엔진" class="headerlink" title="2.2 구글이전의 검색엔진"></a>2.2 구글이전의 검색엔진</h3><ol>
<li><p>웹을 거대한 디렉토리로 정리</p>
<p>웹페이지의 수가 증가함에 따라 카테고리 수도 무한정 커지는 문제가 있다</p>
<p>카테고리 분류가 모호할수가 있다.</p>
</li>
<li><p>키워드에 의존한 검색엔진</p>
<p>악의적인 웹피이지에 취약하다</p>
</li>
</ol></div><a class="article-more button is-small is-size-7" href="/2021/02/23/2021-02-23-Boostcamp22/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-21T15:00:00.000Z" title="2021. 2. 22. 오전 12:00:00">2021-02-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-12T04:44:08.695Z" title="2021. 7. 12. 오후 1:44:08">2021-07-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Boostcamp/">Boostcamp</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/22/2021-02-22-Boostcamp21.1/">Graph</a></h1><div class="content"><p>그래프란 정점과 간선으로 이루어진 구조</p>
<p>하나의 간선은 반드시 두개의 정점을 연결한다</p>
<p>정점 : vertex,node</p>
<p>간선 : Edge,link</p>
<p>우리의 사회및 모든 다양한 것들은 구성요소간의 복잡한 살호작용으로 이루어진 복잡계이다</p>
<p>이것을 표현하는 방식이 바로 그래프이다</p>
<p>그래프란 복잡계를 간단하게 표현하는 방식이다</p></div><a class="article-more button is-small is-size-7" href="/2021/02/22/2021-02-22-Boostcamp21.1/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-17T15:00:00.000Z" title="2021. 2. 18. 오전 12:00:00">2021-02-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-12T04:43:07.198Z" title="2021. 7. 12. 오후 1:43:07">2021-07-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Boostcamp/">Boostcamp</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/18/2021-02-18-Boostcamp19.1/">Transformer심화</a></h1><div class="content"><h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><br/>

<h2 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h2><p>ex) I go home</p>
<p>I에 대한 input vector가 hidden state처럼 역할을 하여서</p>
<p>I와 각각의 단어에 대한 내적을 한후 이에대한 softmax를 구하여 가중평균을 구한다.</p>
<p>이렇게 encoding vector값을 구하게 되면 결국 자기자신과 내적한 값이 큰값을 가져, 자기 자신에 대한 특성만이 dominant하게 담길것이므로, 이를 해결해주기 위해 다른 architecture를 쓴다</p>
<p>각 vector들이 3가지의 역할을 하고있는 것이다. 동일한 set의 vector에서 출발했더라도 각혁할에 따라 vector가 서로다른형태로 변환할수있게해주는 linear transformation matrix가 있다.</p>
<p>한마디로 각각의 input이 서로다른 matrix에 적용이되어 각각이 key, quary,value가 된다는 의미이다.</p>
<p>I 라는 word가 서로다른 matrix에 따라 quart, key, value값이 만들어지고 쿼리는 1개이고 이 쿼리 벡터와 각각의 key vector와의 내적값을 구하고 결과를 softmax에 통과시켜 가중치를 구한후 , 이값과 value vector를 각각 곱해주어 이들의 가중평균으로 최종적인 vector를 구하다. 결국 이 vector가 feature들이 담긴 encoding vector이다.</p>
<p><img src="/images/image-20210218113022613.png" alt="image-20210218113022613"></p>
<p>이러하게 행렬연산으로 위의 과정을 한번에 처리할 수 있다.</p></div><a class="article-more button is-small is-size-7" href="/2021/02/18/2021-02-18-Boostcamp19.1/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-16T15:00:00.000Z" title="2021. 2. 17. 오전 12:00:00">2021-02-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-12T04:42:43.659Z" title="2021. 7. 12. 오후 1:42:43">2021-07-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Boostcamp/">Boostcamp</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/17/2021-02-15-Boostcamp18.1/">Sequence to sequence with Attention</a></h1><div class="content"><h1 id="Sequence-to-sequence"><a href="#Sequence-to-sequence" class="headerlink" title="Sequence to sequence"></a>Sequence to sequence</h1><br/>

<p>\</p>
<h2 id="Seq2Seq-Model"><a href="#Seq2Seq-Model" class="headerlink" title="Seq2Seq Model"></a>Seq2Seq Model</h2><p>Ex) Are you free tomorrow?</p>
<p><img src="/images/image-20210217110021239.png" alt="image-20210217110021239"></p>
<p>서로 paramter를 share하지 않는 2개의 별개의 RNN model을 (보통 LSTM) 쓴다. 각각의 RNN을 Decoder, Encoder로 사용한다.</p>
<p>Encoder의 마지막단의 output을 vertorize 시켜준후 decoder의 input에는 SOS token, hidden state에는 encoder의 output을 넣어준다.</p></div><a class="article-more button is-small is-size-7" href="/2021/02/17/2021-02-15-Boostcamp18.1/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-15T15:00:00.000Z" title="2021. 2. 16. 오전 12:00:00">2021-02-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-12T04:42:18.877Z" title="2021. 7. 12. 오후 1:42:18">2021-07-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Boostcamp/">Boostcamp</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/16/2021-02-15-Boostcamp16.1/">RNN심화1</a></h1><div class="content"><br/>

<h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><p>서로다른 time step에서 들어오는 입력 데이터를 처리할때, 매번 반복되는 동일한 rnn module을 호출한다.<img src="/images/image-20210216103443317.png" alt="image-20210216103443317"></p>
<p><img src="/images/image-20210216103929384.png" alt="image-20210216103929384"></p>
<p>각 단어별로 품사를 예측해야 되는 경우 -&gt; 매 time step마다 y를 output으로</p>
<p>어떠한 문장의 긍부정을 판별하는 경우 -&gt; 최종 time step의 y만이 output으로</p>
<p>모든 time step에서 같은 parameter W를 공유한다</p></div><a class="article-more button is-small is-size-7" href="/2021/02/16/2021-02-15-Boostcamp16.1/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-13T15:00:00.000Z" title="2021. 2. 14. 오전 12:00:00">2021-02-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2021-07-12T05:44:24.421Z" title="2021. 7. 12. 오후 2:44:24">2021-07-12</time></span><span class="level-item"><a class="link-muted" href="/categories/PaperReview/">PaperReview</a></span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/02/14/2021-02-14-GPT/">Improving Language Understanding by Generative Pre-Training</a></h1><div class="content"><br/>

<p>이번에는 openai에서 발표한 논문인 GPT를 review해보겠다</p>
<p>GPT3는 이전에 review한 transformer구조를 활용하여 Language understanding을 효과적으로 만들었다.</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><br/>

<p>자연어를 이해는 text추론, 질문에 대한 대답, 의미의 유사성 평가, 문서분류등을 포함하고 있다. 라벨링 되지 않은 text들을 매우 넘처나지만, 특정 task의 학습을 위해 labed된 text들은 매우 적기때문에 좋은 모델을 학습시키는것은 매우 힘들다.  Language 모델을 unlabled된 text로 <em>generative pretrain</em>을 한이후 각각의 task에 맞게 fine-tunning을 하였다.  이러한 많은 unlabed text를 사용하여 학습하였다. 이전의 연구와는 달리,필요한 task에 fine-tuning하여 응용하는 것이 매우 효과적이다.</p></div><a class="article-more button is-small is-size-7" href="/2021/02/14/2021-02-14-GPT/#more">Read more</a></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/page/0/">Previous</a></div><div class="pagination-next"><a href="/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li><li><a class="pagination-link" href="/page/4/">4</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/profile.png" alt="Won Cho"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Won Cho</p><p class="is-size-6 is-block">결정장애 ESFP의 험난한 일지</p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">38</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">6</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">19</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="/" target="_self" rel="noopener">Home</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/jo-member"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Instagram" href="https://www.instagram.com/jo__member/"><i class="fab fa-instagram"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Boostcamp/"><span class="level-start"><span class="level-item">Boostcamp</span></span><span class="level-end"><span class="level-item tag">26</span></span></a></li><li><a class="level is-mobile" href="/categories/Competition/"><span class="level-start"><span class="level-item">Competition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Mathmatics-for-ML/"><span class="level-start"><span class="level-item">Mathmatics_for_ML</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/PaperReview/"><span class="level-start"><span class="level-item">PaperReview</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/blog/"><span class="level-start"><span class="level-item">blog</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-12T03:09:10.000Z">2021-07-12</time></p><p class="title"><a href="/2021/07/12/VQA/">VQA (Visual Question Answering)</a></p><p class="categories"><a href="/categories/Competition/">Competition</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-25T11:52:06.000Z">2021-04-25</time></p><p class="title"><a href="/2021/04/25/Pstage3-Image-Segmentation-Detection/">Pstage3_Image_Segmentation_Detection</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-04-22T06:29:38.000Z">2021-04-22</time></p><p class="title"><a href="/2021/04/22/Pstage2-KLUE/">Pstage2_KLUE</a></p><p class="categories"><a href="/categories/Boostcamp/">Boostcamp</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-03-07T15:00:00.000Z">2021-03-08</time></p><p class="title"><a href="/2021/03/08/2021-03-08-Boostcamp31.1/">Image Classification</a></p><p class="categories"><a href="/categories/Boostcamp/">Boostcamp</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-02-22T15:00:00.000Z">2021-02-23</time></p><p class="title"><a href="/2021/02/23/2021-02-23-Boostcamp22/">Graph2</a></p><p class="categories"><a href="/categories/Boostcamp/">Boostcamp</a></p></div></article></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Basic/"><span class="tag">Basic</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Book/"><span class="tag">Book</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Books/"><span class="tag">Books</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Competition/"><span class="tag">Competition</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN/"><span class="tag">GAN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPT/"><span class="tag">GPT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Graph/"><span class="tag">Graph</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Math/"><span class="tag">Math</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multimodal/"><span class="tag">Multimodal</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RNN/"><span class="tag">RNN</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Summary/"><span class="tag">Summary</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vision/"><span class="tag">Vision</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/boj/"><span class="tag">boj</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hugging-face/"><span class="tag">hugging_face</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ner/"><span class="tag">ner</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nlp/"><span class="tag">nlp</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Jo Member" height="28"></a><p class="is-size-7"><span>&copy; 2021 jo-member</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>