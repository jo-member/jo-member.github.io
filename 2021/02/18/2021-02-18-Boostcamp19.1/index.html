<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Transformer심화 - Jo Member</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Jo Member"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Jo Member"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Transformer  Self-Attentionex) I go home I에 대한 input vector가 hidden state처럼 역할을 하여서 I와 각각의 단어에 대한 내적을 한후 이에대한 softmax를 구하여 가중평균을 구한다. 이렇게 encoding vector값을 구하게 되면 결국 자기자신과 내적한 값이 큰값을 가져, 자기 자신에 대한 특성만"><meta property="og:type" content="blog"><meta property="og:title" content="Transformer심화"><meta property="og:url" content="https://jo-member.github.io/2021/02/18/2021-02-18-Boostcamp19.1/"><meta property="og:site_name" content="Jo Member"><meta property="og:description" content="Transformer  Self-Attentionex) I go home I에 대한 input vector가 hidden state처럼 역할을 하여서 I와 각각의 단어에 대한 내적을 한후 이에대한 softmax를 구하여 가중평균을 구한다. 이렇게 encoding vector값을 구하게 되면 결국 자기자신과 내적한 값이 큰값을 가져, 자기 자신에 대한 특성만"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://jo-member.github.io/images/image-20210218113022613.png"><meta property="og:image" content="https://jo-member.github.io/images/image-20210218115609302.png"><meta property="og:image" content="https://jo-member.github.io/images/image-20210218115717813.png"><meta property="og:image" content="https://jo-member.github.io/images/image-20210218120149327.png"><meta property="og:image" content="https://jo-member.github.io/images/image-20210218122035821.png"><meta property="og:image" content="https://jo-member.github.io/images/image-20210218122412734.png"><meta property="og:image" content="https://jo-member.github.io/images/image-20210218135058123.png"><meta property="article:published_time" content="2021-02-17T15:00:00.000Z"><meta property="article:modified_time" content="2021-07-12T04:43:07.198Z"><meta property="article:author" content="jo-member"><meta property="article:tag" content="Transformer"><meta property="article:tag" content="NLP"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/images/image-20210218113022613.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://jo-member.github.io/2021/02/18/2021-02-18-Boostcamp19.1/"},"headline":"Transformer심화","image":["https://jo-member.github.io/images/image-20210218113022613.png","https://jo-member.github.io/images/image-20210218115609302.png","https://jo-member.github.io/images/image-20210218115717813.png","https://jo-member.github.io/images/image-20210218120149327.png","https://jo-member.github.io/images/image-20210218122035821.png","https://jo-member.github.io/images/image-20210218122412734.png","https://jo-member.github.io/images/image-20210218135058123.png"],"datePublished":"2021-02-17T15:00:00.000Z","dateModified":"2021-07-12T04:43:07.198Z","author":{"@type":"Person","name":"jo-member"},"description":"Transformer  Self-Attentionex) I go home I에 대한 input vector가 hidden state처럼 역할을 하여서 I와 각각의 단어에 대한 내적을 한후 이에대한 softmax를 구하여 가중평균을 구한다. 이렇게 encoding vector값을 구하게 되면 결국 자기자신과 내적한 값이 큰값을 가져, 자기 자신에 대한 특성만"}</script><link rel="canonical" href="https://jo-member.github.io/2021/02/18/2021-02-18-Boostcamp19.1/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/rss2.xml" title="Jo Member" type="application/rss+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Jo Member" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="external nofollow noopener noreferrer" title="Download on GitHub" href="https://github.com/jo-member"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-9-tablet is-9-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time datetime="2021-02-17T15:00:00.000Z" title="2021. 2. 18. 오전 12:00:00">2021-02-18</time></span><span class="level-item">Updated&nbsp;<time datetime="2021-07-12T04:43:07.198Z" title="2021. 7. 12. 오후 1:43:07">2021-07-12</time></span><span class="level-item"><a class="link-muted" href="/categories/Boostcamp/">Boostcamp</a></span></div></div><h1 class="title is-3 is-size-4-mobile">Transformer심화</h1><div class="content"><h1 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h1><br>

<h2 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h2><p>ex) I go home</p>
<p>I에 대한 input vector가 hidden state처럼 역할을 하여서</p>
<p>I와 각각의 단어에 대한 내적을 한후 이에대한 softmax를 구하여 가중평균을 구한다.</p>
<p>이렇게 encoding vector값을 구하게 되면 결국 자기자신과 내적한 값이 큰값을 가져, 자기 자신에 대한 특성만이 dominant하게 담길것이므로, 이를 해결해주기 위해 다른 architecture를 쓴다</p>
<p>각 vector들이 3가지의 역할을 하고있는 것이다. 동일한 set의 vector에서 출발했더라도 각혁할에 따라 vector가 서로다른형태로 변환할수있게해주는 linear transformation matrix가 있다.</p>
<p>한마디로 각각의 input이 서로다른 matrix에 적용이되어 각각이 key, quary,value가 된다는 의미이다.</p>
<p>I 라는 word가 서로다른 matrix에 따라 quart, key, value값이 만들어지고 쿼리는 1개이고 이 쿼리 벡터와 각각의 key vector와의 내적값을 구하고 결과를 softmax에 통과시켜 가중치를 구한후 , 이값과 value vector를 각각 곱해주어 이들의 가중평균으로 최종적인 vector를 구하다. 결국 이 vector가 feature들이 담긴 encoding vector이다.</p>
<p><img src="/images/image-20210218113022613.png" alt="image-20210218113022613"></p>
<p>이러하게 행렬연산으로 위의 과정을 한번에 처리할 수 있다.</p>
<span id="more"></span>

<h2 id="Multi-head-Attention"><a href="#Multi-head-Attention" class="headerlink" title="Multi-head Attention"></a>Multi-head Attention</h2><p><img src="/images/image-20210218115609302.png" alt="image-20210218115609302"></p>
<p>쿼리,key,value를 만들때 여러 set의 matrix를 적용하여 여러 attention을 수행한다. 이러한 서로다른 선형변환 matrix를 head라고 부른다. 동일한 sequence에서 특정한 quary에 대해서 여러측면으로 정보를 뽑아야하는 경우가 있다. </p>
<p><img src="/images/image-20210218115717813.png" alt="image-20210218115717813"></p>
<p><img src="/images/image-20210218120149327.png" alt="image-20210218120149327"></p>
<p>이후 하나의 선형변환 layer를 추가하여 우리가 원하는 shape의 output을 얻어낸다. 왜 이러한 shape으로 변환해야할까? for residual connection</p>
<p>Residual connection을 사용했다. 이는 CV에서 널리쓰이던 Resnet에서 사용한 residue개념을 활용하여, attention 결과의 encoded vector와 원래 입력 vector를 더한다. 이러한 과정을 통해 gradient vanishing과 학습의 속도를 해결하였다.</p>
<p>Layer Normalization</p>
<p>주어진 sample에 대해서 그값들의 평균을 0 분산을 1로 만들어준후 우리가 원하는 평균과 분산을 만들어주는 선형변환으로 이루어져있다.<img src="/images/image-20210218122035821.png" alt="image-20210218122035821"></p>
<p>표준화된 평균과 분산으로 만들어줌. 이후 affine transformation (ex : y = 2x+3)을 수행할 경우 평균은 3 분산은 4가 된다. 여기서의 2와 3은 NN이 optimize해야하는 paramter가 된다. 위의 transformer에도 이런식으로 적용이된다</p>
<p><img src="/images/image-20210218122412734.png" alt="image-20210218122412734"></p>
<p>affine transformation은 이제 parameter이라 학습하는? 왜성능이 올라갈까?</p>
<p>Transformer에서의 self attention은 순서의 정보를 담고있지 않기 때문에 추가적인 작업이 필요하다. 이 작업을 transformer은 postition encoding에 sinusodial function을 적용하였다.</p>
<p>Optimizer은 graident descent가 아닌 Adam을 사용하였다. Learning rate을 고정한 값을 사용하지 않고 학습중에 lr을 변경시켜주었다. </p>
<h2 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h2><p><sos>, 나는, 집에, 간다</sos></p>
<p>Masked Multi-Head Attention의 결과가가 얻어졌다면 이를 다시 multi-head attention에 넣어준다. 그데 이제 quary에만 이게 사용되고 encoding단의 encoded vector가 이제 key와 value값에 들어가게 된다. 이제 target language의 vocab size에 맞는 vector를 생성하는 linear transformation을 걸어준다. 그곳에 soft max를 취해서 다음 word를 찾아낸다. 이제 ground truth와의 softmax loss를 구해서 backpropagation으로 학습해 나간다.</p>
<p><strong>Masked Self Attention</strong></p>
<p>전체 sequence에 대한 정보를 허용하게 되면 첫번째 time step에서 SOS만이 주어졌는데 나는이라는 단어를 예측해야 하는데 나는이라는 값과 sos사이의 행렬곱값이 있기 때문에 이상황에는 이를 masking해주어야 한다.</p>
<p><img src="/images/image-20210218135058123.png" alt="image-20210218135058123"></p>
<p>이렇게 masking해준후 normalize를 해주게 된다. 가중평균의 합이 1이 되도록</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Transformer심화</p><p><a href="https://jo-member.github.io/2021/02/18/2021-02-18-Boostcamp19.1/">https://jo-member.github.io/2021/02/18/2021-02-18-Boostcamp19.1/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>jo-member</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2021-02-18</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2021-07-12</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icon" rel="external nofollow noopener noreferrer" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a><a class="icon" rel="external nofollow noopener noreferrer" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a><a class="icon" rel="external nofollow noopener noreferrer" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/Transformer/">Transformer</a><a class="link-muted mr-2" rel="tag" href="/tags/NLP/">NLP</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2021/02/22/2021-02-22-Boostcamp21.1/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Graph</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/02/17/2021-02-15-Boostcamp18.1/"><span class="level-item">Sequence to sequence with Attention</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://jo-member.github.io/2021/02/18/2021-02-18-Boostcamp19.1/';
            this.page.identifier = '2021/02/18/2021-02-18-Boostcamp19.1/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'jo-member' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-3-tablet is-3-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Algorithm/"><span class="level-start"><span class="level-item">Algorithm</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/categories/Boostcamp/"><span class="level-start"><span class="level-item">Boostcamp</span></span><span class="level-end"><span class="level-item tag">27</span></span></a></li><li><a class="level is-mobile" href="/categories/Competition/"><span class="level-start"><span class="level-item">Competition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Mathmatics-for-ML/"><span class="level-start"><span class="level-item">Mathmatics_for_ML</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/PaperReview/"><span class="level-start"><span class="level-item">PaperReview</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/blog/"><span class="level-start"><span class="level-item">blog</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time datetime="2021-07-12T05:42:40.000Z">2021-07-12</time></p><p class="title"><a href="/2021/07/12/vqa_paper1/">VQA: Visual Question Answering vs Competition Baseline</a></p><p class="categories"><a href="/categories/PaperReview/">PaperReview</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2021-07-12T03:09:10.000Z">2021-07-12</time></p><p class="title"><a href="/2021/07/12/VQA/">VQA (Visual Question Answering)</a></p><p class="categories"><a href="/categories/Competition/">Competition</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2021-04-25T11:52:06.000Z">2021-04-25</time></p><p class="title"><a href="/2021/04/25/Pstage3-Image-Segmentation-Detection/">Pstage3_Image_Segmentation_Detection</a></p><p class="categories"><a href="/categories/Boostcamp/">Boostcamp</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2021-04-22T06:29:38.000Z">2021-04-22</time></p><p class="title"><a href="/2021/04/22/Pstage2-KLUE/">Pstage2_KLUE</a></p><p class="categories"><a href="/categories/Boostcamp/">Boostcamp</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time datetime="2021-03-07T15:00:00.000Z">2021-03-08</time></p><p class="title"><a href="/2021/03/08/2021-03-08-Boostcamp31.1/">Image Classification</a></p><p class="categories"><a href="/categories/Boostcamp/">Boostcamp</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Jo Member" height="28"></a><p class="is-size-7"><span>&copy; 2021 jo-member</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="external nofollow noopener noreferrer">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="external nofollow noopener noreferrer">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>